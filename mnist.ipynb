{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/a9/b3cea4a97ffabd6639e71608814dbd08081e202e8ac9580250273c0541ff/torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4MB 49kB/s s eta 0:00:01    |██                              | 51.9MB 22.4MB/s eta 0:00:35     |██▋                             | 69.0MB 18.9MB/s eta 0:00:41     |███████                         | 181.4MB 13.6MB/s eta 0:00:48     |███████▎                        | 189.5MB 12.2MB/s eta 0:00:53     |████████████▏                   | 316.7MB 5.3MB/s eta 0:01:38     |████████████▍                   | 322.9MB 6.2MB/s eta 0:01:22     |█████████████████▏              | 445.4MB 3.9MB/s eta 0:01:39     |██████████████████▌             | 480.7MB 6.0MB/s eta 0:00:59     |███████████████████▍            | 503.0MB 6.1MB/s eta 0:00:54     |████████████████████████▎       | 629.6MB 7.5MB/s eta 0:00:27     |█████████████████████████████▌  | 767.0MB 14.7MB/s eta 0:00:05     |█████████████████████████████▋  | 769.3MB 14.7MB/s eta 0:00:05     |██████████████████████████████▎ | 788.1MB 12.2MB/s eta 0:00:04     |██████████████████████████████▍ | 790.4MB 12.2MB/s eta 0:00:04     |████████████████████████████████| 830.4MB 14.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/25/31f5d3c62b80aff0d95b9306e09487a29531a2a3d05cf767376bdc087c3a/torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1MB)\n",
      "\u001b[K     |████████████████████████████████| 22.1MB 15.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: torchaudio in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (7.0.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "  Found existing installation: torchvision 0.5.0\n",
      "    Uninstalling torchvision-0.5.0:\n",
      "      Successfully uninstalled torchvision-0.5.0\n",
      "Successfully installed torch-1.9.0 torchvision-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import L0LeNet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_construct(sparsity=(0.1,)*4) # reset the model sparsity per layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L0LeNet(\n",
       "  (convs): Sequential(\n",
       "    (conv1): L0Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), sparse_ratio=0.1)\n",
       "    (relu1): ReLU()\n",
       "    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): L0Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), sparse_ratio=0.1)\n",
       "    (relu2): ReLU()\n",
       "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (fc1): L0Dense(1024 -> 256, sparse_ratio=0.1)\n",
       "    (relu3): ReLU()\n",
       "    (fc2): L0Dense(256 -> 256, sparse_ratio=0.1)\n",
       "    (relu4): ReLU()\n",
       "    (fc3): L0Dense(256 -> 10, sparse_ratio=0.1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import mnist\n",
    "from models import L0LeNet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "from utils import AverageMeter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L0LeNet(\n",
       "  (convs): Sequential(\n",
       "    (conv1): L0Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), sparse_ratio=0.0)\n",
       "    (relu1): ReLU()\n",
       "    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): L0Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), sparse_ratio=0.0)\n",
       "    (relu2): ReLU()\n",
       "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (fc1): L0Dense(1024 -> 256, sparse_ratio=0.0)\n",
       "    (relu3): ReLU()\n",
       "    (fc2): L0Dense(256 -> 256, sparse_ratio=0.0)\n",
       "    (relu4): ReLU()\n",
       "    (fc3): L0Dense(256 -> 10, sparse_ratio=0.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, num_classes = mnist()\n",
    "\n",
    "model = L0LeNet(10, device=5, )\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to('cuda:5')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(model, loader, criterion, name='L0LeNet', isTrain=True, isConstrain=False, print_freq=100,\n",
    "              optimizer=None, epoch=0):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    total_softmax = []\n",
    "    total_labels = []\n",
    "    total_preds = []\n",
    "\n",
    "    model.train() if isTrain else model.eval()\n",
    "\n",
    "    for i, (X, y) in enumerate(loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        if torch.cuda.is_available():\n",
    "            X, y = X.to('cuda:5'), y.to('cuda:5')\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        losses.update(loss.data, X.size(0))\n",
    "\n",
    "        if isTrain:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if isConstrain:\n",
    "            layers = model.layers\n",
    "            for layer in layers:\n",
    "                layer.clamp_params()\n",
    "\n",
    "        # get metric\n",
    "        pred = F.softmax(pred)\n",
    "        _, p_data = pred.data.max(dim=1)\n",
    "        s_data, y_data = pred.data.cpu().detach().numpy(), y.data.cpu().detach().numpy()\n",
    "        p_data = p_data.cpu().detach().numpy()\n",
    "\n",
    "        total_softmax.append(s_data)\n",
    "        total_labels.append(y_data)\n",
    "        total_preds.append(p_data)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % print_freq == 0:\n",
    "            print(' Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                epoch, i, len(loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses))\n",
    "\n",
    "    total_softmax = reshape_resulting_array(total_softmax)\n",
    "    total_labels = np.array(total_labels).reshape(-1).squeeze()\n",
    "    total_preds = np.array(total_preds).reshape(-1).squeeze()\n",
    "\n",
    "    result = accuracy(total_labels, total_preds, total_softmax)\n",
    "\n",
    "    # if save_state:\n",
    "    state = {\n",
    "        'name': name,\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': deepcopy(model).cpu().state_dict(),\n",
    "        'results': result,\n",
    "        'loss': losses.avg.detach().cpu().numpy(),\n",
    "        'softmax_output': total_softmax,\n",
    "        'labels': total_labels,\n",
    "        'preds': total_preds\n",
    "    }\n",
    "    \n",
    "    if isTrain:\n",
    "        state['optimizer'] = deepcopy(optimizer).state_dict()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: [0][0/600]\tTime 0.424 (0.424)\tData 0.398 (0.398)\tLoss 15.3713 (15.3713)\t\n",
      " Epoch: [0][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.2563 (0.9385)\t\n",
      " Epoch: [0][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.2635 (0.5593)\t\n",
      " Epoch: [0][300/600]\tTime 0.005 (0.007)\tData 0.000 (0.002)\tLoss 0.0364 (0.4138)\t\n",
      " Epoch: [0][400/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0271 (0.3423)\t\n",
      " Epoch: [0][500/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0554 (0.2904)\t\n",
      " Epoch: [1][0/600]\tTime 0.354 (0.354)\tData 0.347 (0.347)\tLoss 0.0497 (0.0497)\t\n",
      " Epoch: [1][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0459 (0.0627)\t\n",
      " Epoch: [1][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0133 (0.0628)\t\n",
      " Epoch: [1][300/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0970 (0.0635)\t\n",
      " Epoch: [1][400/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0620 (0.0630)\t\n",
      " Epoch: [1][500/600]\tTime 0.004 (0.007)\tData 0.000 (0.001)\tLoss 0.0533 (0.0628)\t\n",
      " Epoch: [2][0/600]\tTime 0.378 (0.378)\tData 0.364 (0.364)\tLoss 0.0796 (0.0796)\t\n",
      " Epoch: [2][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0073 (0.0364)\t\n",
      " Epoch: [2][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0311 (0.0385)\t\n",
      " Epoch: [2][300/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0061 (0.0369)\t\n",
      " Epoch: [2][400/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0076 (0.0387)\t\n",
      " Epoch: [2][500/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0143 (0.0383)\t\n",
      " Epoch: [3][0/600]\tTime 0.361 (0.361)\tData 0.347 (0.347)\tLoss 0.0012 (0.0012)\t\n",
      " Epoch: [3][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0127 (0.0257)\t\n",
      " Epoch: [3][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0420 (0.0293)\t\n",
      " Epoch: [3][300/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0212 (0.0284)\t\n",
      " Epoch: [3][400/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0279 (0.0291)\t\n",
      " Epoch: [3][500/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0206 (0.0283)\t\n",
      " Epoch: [4][0/600]\tTime 0.362 (0.362)\tData 0.347 (0.347)\tLoss 0.0305 (0.0305)\t\n",
      " Epoch: [4][100/600]\tTime 0.005 (0.009)\tData 0.000 (0.004)\tLoss 0.0014 (0.0209)\t\n",
      " Epoch: [4][200/600]\tTime 0.004 (0.007)\tData 0.000 (0.002)\tLoss 0.0504 (0.0198)\t\n",
      " Epoch: [4][300/600]\tTime 0.003 (0.006)\tData 0.000 (0.001)\tLoss 0.0027 (0.0208)\t\n",
      " Epoch: [4][400/600]\tTime 0.003 (0.005)\tData 0.000 (0.001)\tLoss 0.0012 (0.0236)\t\n",
      " Epoch: [4][500/600]\tTime 0.007 (0.006)\tData 0.000 (0.001)\tLoss 0.0590 (0.0241)\t\n",
      " Epoch: [5][0/600]\tTime 0.352 (0.352)\tData 0.342 (0.342)\tLoss 0.0150 (0.0150)\t\n",
      " Epoch: [5][100/600]\tTime 0.006 (0.009)\tData 0.000 (0.004)\tLoss 0.0012 (0.0206)\t\n",
      " Epoch: [5][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0288 (0.0187)\t\n",
      " Epoch: [5][300/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0593 (0.0186)\t\n",
      " Epoch: [5][400/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0049 (0.0177)\t\n",
      " Epoch: [5][500/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0343 (0.0201)\t\n",
      " Epoch: [6][0/600]\tTime 0.368 (0.368)\tData 0.357 (0.357)\tLoss 0.0018 (0.0018)\t\n",
      " Epoch: [6][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0137 (0.0149)\t\n",
      " Epoch: [6][200/600]\tTime 0.005 (0.008)\tData 0.000 (0.002)\tLoss 0.0467 (0.0152)\t\n",
      " Epoch: [6][300/600]\tTime 0.007 (0.008)\tData 0.000 (0.001)\tLoss 0.0001 (0.0144)\t\n",
      " Epoch: [6][400/600]\tTime 0.004 (0.007)\tData 0.000 (0.001)\tLoss 0.1010 (0.0140)\t\n",
      " Epoch: [6][500/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0483 (0.0152)\t\n",
      " Epoch: [7][0/600]\tTime 0.353 (0.353)\tData 0.344 (0.344)\tLoss 0.0072 (0.0072)\t\n",
      " Epoch: [7][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0009 (0.0097)\t\n",
      " Epoch: [7][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0057 (0.0113)\t\n",
      " Epoch: [7][300/600]\tTime 0.004 (0.007)\tData 0.000 (0.001)\tLoss 0.0476 (0.0131)\t\n",
      " Epoch: [7][400/600]\tTime 0.003 (0.007)\tData 0.000 (0.001)\tLoss 0.0032 (0.0153)\t\n",
      " Epoch: [7][500/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0008 (0.0157)\t\n",
      " Epoch: [8][0/600]\tTime 0.355 (0.355)\tData 0.346 (0.346)\tLoss 0.0130 (0.0130)\t\n",
      " Epoch: [8][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0008 (0.0122)\t\n",
      " Epoch: [8][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0003 (0.0110)\t\n",
      " Epoch: [8][300/600]\tTime 0.006 (0.008)\tData 0.000 (0.001)\tLoss 0.0029 (0.0114)\t\n",
      " Epoch: [8][400/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0050 (0.0117)\t\n",
      " Epoch: [8][500/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0178 (0.0130)\t\n",
      " Epoch: [9][0/600]\tTime 0.374 (0.374)\tData 0.363 (0.363)\tLoss 0.0009 (0.0009)\t\n",
      " Epoch: [9][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0006 (0.0149)\t\n",
      " Epoch: [9][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0125 (0.0146)\t\n",
      " Epoch: [9][300/600]\tTime 0.005 (0.008)\tData 0.000 (0.001)\tLoss 0.0002 (0.0132)\t\n",
      " Epoch: [9][400/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0274 (0.0119)\t\n",
      " Epoch: [9][500/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0043 (0.0124)\t\n",
      " Epoch: [10][0/600]\tTime 0.355 (0.355)\tData 0.347 (0.347)\tLoss 0.0008 (0.0008)\t\n",
      " Epoch: [10][100/600]\tTime 0.006 (0.009)\tData 0.000 (0.004)\tLoss 0.0009 (0.0118)\t\n",
      " Epoch: [10][200/600]\tTime 0.004 (0.008)\tData 0.000 (0.002)\tLoss 0.0167 (0.0140)\t\n",
      " Epoch: [10][300/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0002 (0.0121)\t\n",
      " Epoch: [10][400/600]\tTime 0.005 (0.006)\tData 0.000 (0.001)\tLoss 0.0002 (0.0115)\t\n",
      " Epoch: [10][500/600]\tTime 0.004 (0.006)\tData 0.000 (0.001)\tLoss 0.0086 (0.0107)\t\n",
      " Epoch: [11][0/600]\tTime 0.362 (0.362)\tData 0.347 (0.347)\tLoss 0.0156 (0.0156)\t\n",
      " Epoch: [11][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0047 (0.0132)\t\n",
      " Epoch: [11][200/600]\tTime 0.007 (0.008)\tData 0.000 (0.002)\tLoss 0.0009 (0.0114)\t\n",
      " Epoch: [11][300/600]\tTime 0.004 (0.007)\tData 0.000 (0.001)\tLoss 0.0014 (0.0115)\t\n",
      " Epoch: [11][400/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0006 (0.0113)\t\n",
      " Epoch: [11][500/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0006 (0.0117)\t\n",
      " Epoch: [12][0/600]\tTime 0.363 (0.363)\tData 0.349 (0.349)\tLoss 0.0494 (0.0494)\t\n",
      " Epoch: [12][100/600]\tTime 0.007 (0.010)\tData 0.000 (0.004)\tLoss 0.0004 (0.0088)\t\n",
      " Epoch: [12][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0091 (0.0101)\t\n",
      " Epoch: [12][300/600]\tTime 0.006 (0.008)\tData 0.000 (0.001)\tLoss 0.0007 (0.0101)\t\n",
      " Epoch: [12][400/600]\tTime 0.004 (0.007)\tData 0.000 (0.001)\tLoss 0.0000 (0.0097)\t\n",
      " Epoch: [12][500/600]\tTime 0.005 (0.006)\tData 0.000 (0.001)\tLoss 0.0103 (0.0104)\t\n",
      " Epoch: [13][0/600]\tTime 0.370 (0.370)\tData 0.357 (0.357)\tLoss 0.0005 (0.0005)\t\n",
      " Epoch: [13][100/600]\tTime 0.007 (0.009)\tData 0.000 (0.004)\tLoss 0.0006 (0.0084)\t\n",
      " Epoch: [13][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0006 (0.0094)\t\n",
      " Epoch: [13][300/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0052 (0.0108)\t\n",
      " Epoch: [13][400/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0010 (0.0097)\t\n",
      " Epoch: [13][500/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0001 (0.0095)\t\n",
      " Epoch: [14][0/600]\tTime 0.358 (0.358)\tData 0.349 (0.349)\tLoss 0.0003 (0.0003)\t\n",
      " Epoch: [14][100/600]\tTime 0.007 (0.010)\tData 0.000 (0.004)\tLoss 0.0103 (0.0072)\t\n",
      " Epoch: [14][200/600]\tTime 0.007 (0.008)\tData 0.000 (0.002)\tLoss 0.0009 (0.0056)\t\n",
      " Epoch: [14][300/600]\tTime 0.007 (0.008)\tData 0.000 (0.001)\tLoss 0.0454 (0.0060)\t\n",
      " Epoch: [14][400/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0003 (0.0066)\t\n",
      " Epoch: [14][500/600]\tTime 0.004 (0.007)\tData 0.000 (0.001)\tLoss 0.0001 (0.0074)\t\n",
      " Epoch: [15][0/600]\tTime 0.353 (0.353)\tData 0.339 (0.339)\tLoss 0.0124 (0.0124)\t\n",
      " Epoch: [15][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0002 (0.0092)\t\n",
      " Epoch: [15][200/600]\tTime 0.006 (0.008)\tData 0.000 (0.002)\tLoss 0.0474 (0.0096)\t\n",
      " Epoch: [15][300/600]\tTime 0.007 (0.008)\tData 0.001 (0.001)\tLoss 0.0001 (0.0077)\t\n",
      " Epoch: [15][400/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0013 (0.0070)\t\n",
      " Epoch: [15][500/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0001 (0.0068)\t\n",
      " Epoch: [16][0/600]\tTime 0.377 (0.377)\tData 0.362 (0.362)\tLoss 0.0004 (0.0004)\t\n",
      " Epoch: [16][100/600]\tTime 0.007 (0.010)\tData 0.000 (0.004)\tLoss 0.0001 (0.0081)\t\n",
      " Epoch: [16][200/600]\tTime 0.006 (0.009)\tData 0.000 (0.002)\tLoss 0.0000 (0.0077)\t\n",
      " Epoch: [16][300/600]\tTime 0.006 (0.008)\tData 0.000 (0.001)\tLoss 0.0000 (0.0078)\t\n",
      " Epoch: [16][400/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0001 (0.0069)\t\n",
      " Epoch: [16][500/600]\tTime 0.008 (0.007)\tData 0.000 (0.001)\tLoss 0.0035 (0.0066)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: [17][0/600]\tTime 0.380 (0.380)\tData 0.366 (0.366)\tLoss 0.0109 (0.0109)\t\n",
      " Epoch: [17][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0069 (0.0073)\t\n",
      " Epoch: [17][200/600]\tTime 0.005 (0.008)\tData 0.000 (0.002)\tLoss 0.0682 (0.0068)\t\n",
      " Epoch: [17][300/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0075 (0.0066)\t\n",
      " Epoch: [17][400/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0058 (0.0065)\t\n",
      " Epoch: [17][500/600]\tTime 0.007 (0.007)\tData 0.000 (0.001)\tLoss 0.0006 (0.0073)\t\n",
      " Epoch: [18][0/600]\tTime 0.367 (0.367)\tData 0.356 (0.356)\tLoss 0.0151 (0.0151)\t\n",
      " Epoch: [18][100/600]\tTime 0.007 (0.010)\tData 0.000 (0.004)\tLoss 0.0082 (0.0061)\t\n",
      " Epoch: [18][200/600]\tTime 0.008 (0.008)\tData 0.000 (0.002)\tLoss 0.0043 (0.0071)\t\n",
      " Epoch: [18][300/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0223 (0.0067)\t\n",
      " Epoch: [18][400/600]\tTime 0.006 (0.007)\tData 0.000 (0.001)\tLoss 0.0004 (0.0078)\t\n",
      " Epoch: [18][500/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0004 (0.0079)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f9ecdb1f8c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: [19][0/600]\tTime 0.493 (0.493)\tData 0.481 (0.481)\tLoss 0.0001 (0.0001)\t\n",
      " Epoch: [19][100/600]\tTime 0.007 (0.011)\tData 0.000 (0.005)\tLoss 0.0064 (0.0036)\t\n",
      " Epoch: [19][200/600]\tTime 0.008 (0.009)\tData 0.000 (0.003)\tLoss 0.0227 (0.0049)\t\n",
      " Epoch: [19][300/600]\tTime 0.008 (0.008)\tData 0.000 (0.002)\tLoss 0.0128 (0.0049)\t\n",
      " Epoch: [19][400/600]\tTime 0.008 (0.008)\tData 0.000 (0.001)\tLoss 0.0290 (0.0052)\t\n",
      " Epoch: [19][500/600]\tTime 0.005 (0.007)\tData 0.000 (0.001)\tLoss 0.0594 (0.0064)\t\n",
      " Epoch: [20][0/600]\tTime 0.375 (0.375)\tData 0.362 (0.362)\tLoss 0.0127 (0.0127)\t\n",
      " Epoch: [20][100/600]\tTime 0.006 (0.010)\tData 0.000 (0.004)\tLoss 0.0003 (0.0044)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 499, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 729, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-26ddd3e96b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#     input_X = torch.autograd.Variable(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/local/JulianPro/personal/compression_stability/models/lenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_freq = 200\n",
    "l0 = False\n",
    "\n",
    "for epoch in range(100):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    end = time.time()\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        if torch.cuda.is_available():\n",
    "            X, y = X.to('cuda:5'), y.to('cuda:5')\n",
    "\n",
    "    #     input_X = torch.autograd.Variable(X)\n",
    "    #     input_X = torch.autograd.Variable(X)\n",
    "\n",
    "        out = model(X)\n",
    "\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        losses.update(loss.data, X.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if l0:\n",
    "            layers = model.layers\n",
    "            for layer in layers:\n",
    "                layer.clamp_params()\n",
    "                \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "                \n",
    "        if i % print_freq == 0:\n",
    "            print(' Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses))\n",
    "        \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'logs/{}/'.format('L0LeNet5')\n",
    "if os.path.exists(directory):\n",
    "    shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "else:\n",
    "    os.makedirs(directory)\n",
    "writer = SummaryWriter(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path='.'):\n",
    "    net = deepcopy(model)\n",
    "    state = net.cpu().state_dict()\n",
    "    torch.save(state, path)\n",
    "    \n",
    "def save_checkpoint(state, is_best, name, filename='checkpoint.pth.tar'):\n",
    "    \"\"\"Saves checkpoint to disk\"\"\"\n",
    "    directory = \"runs/%s/\" % name\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = directory + filename\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'runs/%s/' % name + 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTrain(name='l0Lenet5_pretrain'):\n",
    "    best_valid_loss = 999999\n",
    "    for epoch in range(EPOCH):\n",
    "        train_state = iteration(model, train_loader, criterion, isTrain=True, isConstrain=False, optimizer=optimizer, epoch=epoch)\n",
    "        valid_state = iteration(model, val_loader, criterion, isTrain=False, isConstrain=False, print_freq=10000, epoch=epoch)\n",
    "        \n",
    "        train_loss = train_state['loss']\n",
    "        valid_loss = valid_state['loss']\n",
    "        \n",
    "        if best_valid_loss > valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            isBest = True\n",
    "        \n",
    "        save_checkpoint(train_state, isBest, name + '/train', filename='checkpoint_train.pth.tar')\n",
    "        save_checkpoint(valid_state, isBest, name + '/valid', filename='checkpoint_valid.pth.tar')\n",
    "        \n",
    "        isBest = False\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_data, p_data, s_data):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    \n",
    "    f1 = f1_score(y_data, p_data, average='micro')\n",
    "    acc = accuracy_score(y_data, p_data)\n",
    "    auc = roc_auc_score(y_data, s_data, multi_class='ovo')\n",
    "    pre = precision_score(y_data, p_data, average='micro')\n",
    "    rec = recall_score(y_data, p_data, average='micro')\n",
    "    \n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'auc_score': auc,\n",
    "        'precision': pre,\n",
    "        'recall': rec\n",
    "    }\n",
    "\n",
    "\n",
    "def reshape_resulting_array(arr):\n",
    "    if type(arr) is not np.ndarray:\n",
    "        arr = np.array(arr)\n",
    "    return arr.reshape((-1, arr.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: [0][0/600]\tTime 0.422 (0.422)\tData 0.400 (0.400)\tLoss 0.0000 (0.0000)\t\n",
      " Epoch: [0][100/600]\tTime 0.002 (0.008)\tData 0.000 (0.005)\tLoss 0.0031 (0.0020)\t\n",
      " Epoch: [0][200/600]\tTime 0.003 (0.006)\tData 0.001 (0.004)\tLoss 0.0012 (0.0025)\t\n",
      " Epoch: [0][300/600]\tTime 0.006 (0.005)\tData 0.004 (0.003)\tLoss 0.0000 (0.0023)\t\n",
      " Epoch: [0][400/600]\tTime 0.010 (0.005)\tData 0.007 (0.002)\tLoss 0.0010 (0.0026)\t\n",
      " Epoch: [0][500/600]\tTime 0.003 (0.004)\tData 0.001 (0.002)\tLoss 0.0000 (0.0027)\t\n"
     ]
    }
   ],
   "source": [
    "state = iteration(model, train_loader, criterion, isTrain=False, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append(state['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(model, loader, criterion, isTrain=True, isConstrain=False, print_freq=100, optimizer=None, epoch=None):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    all_outs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.train() if isTrain else model.eval()\n",
    "\n",
    "    for i, (X, y) in enumerate(val_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        if torch.cuda.is_available():\n",
    "            X, y = X.to('cuda:5'), y.to('cuda:5')\n",
    "\n",
    "    #     input_X = torch.autograd.Variable(X)\n",
    "    #     input_X = torch.autograd.Variable(X)\n",
    "\n",
    "        out = model(X)\n",
    "\n",
    "        all_outs.append(out.detach().cpu().numpy())\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        losses.update(loss.data, X.size(0))\n",
    "        \n",
    "        if isTrain:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if isConstrain:\n",
    "            layers = model.layers\n",
    "            for layer in layers:\n",
    "                layer.clamp_params()\n",
    "                \n",
    "                \n",
    "        # get metric\n",
    "        pred = F.softmax(pred)\n",
    "        _, p_data = pred.data.max(dim=1)\n",
    "        s_data, y_data = pred.data.cpu().detach().numpy(), y.data.cpu().detach().numpy()\n",
    "        p_data = p_data.cpu().detach().numpy()        \n",
    "        \n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % print_freq == 0:\n",
    "            print(' Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: [20][0/600]\tTime 0.381 (0.381)\tData 0.374 (0.374)\tLoss 0.0000 (0.0000)\t\n",
      " Epoch: [20][100/600]\tTime 0.002 (0.008)\tData 0.000 (0.005)\tLoss 0.0020 (0.0035)\t\n",
      " Epoch: [20][200/600]\tTime 0.003 (0.005)\tData 0.001 (0.003)\tLoss 0.0000 (0.0027)\t\n",
      " Epoch: [20][300/600]\tTime 0.003 (0.005)\tData 0.001 (0.002)\tLoss 0.0139 (0.0025)\t\n",
      " Epoch: [20][400/600]\tTime 0.004 (0.004)\tData 0.000 (0.002)\tLoss 0.0004 (0.0026)\t\n",
      " Epoch: [20][500/600]\tTime 0.003 (0.004)\tData 0.000 (0.002)\tLoss 0.0004 (0.0026)\t\n"
     ]
    }
   ],
   "source": [
    "isConstrain = False\n",
    "isTrain=False\n",
    "\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "end = time.time()\n",
    "\n",
    "total_softmax = []\n",
    "total_labels = []\n",
    "total_preds = []\n",
    "\n",
    "model.train() if isTrain else model.eval()\n",
    "\n",
    "for i, (X, y) in enumerate(train_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "    if torch.cuda.is_available():\n",
    "        X, y = X.to('cuda:5'), y.to('cuda:5')\n",
    "\n",
    "#     input_X = torch.autograd.Variable(X)\n",
    "#     input_X = torch.autograd.Variable(X)\n",
    "\n",
    "    pred = model(X)\n",
    "\n",
    "#     all_outs.append(out.detach().cpu().numpy())\n",
    "#     all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "    losses.update(loss.data, X.size(0))\n",
    "\n",
    "    if isTrain:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if isConstrain:\n",
    "        layers = model.layers\n",
    "        for layer in layers:\n",
    "            layer.clamp_params()\n",
    "            \n",
    "    # get metric\n",
    "    pred = F.softmax(pred)\n",
    "    _, p_data = pred.data.max(dim=1)\n",
    "    s_data, y_data = pred.data.cpu().detach().numpy(), y.data.cpu().detach().numpy()\n",
    "    p_data = p_data.cpu().detach().numpy()\n",
    "    \n",
    "    total_softmax.append(s_data)\n",
    "    total_labels.append(y_data)\n",
    "    total_preds.append(p_data)\n",
    "\n",
    "    # measure elapsed time\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "    if i % print_freq == 0:\n",
    "        print(' Epoch: [{0}][{1}/{2}]\\t'\n",
    "              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "              'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "            epoch, i, len(train_loader), batch_time=batch_time,\n",
    "            data_time=data_time, loss=losses))\n",
    "\n",
    "#     if i == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_softmax = reshape_resulting_array(total_softmax)\n",
    "total_labels = np.array(total_labels).reshape(-1).squeeze()\n",
    "total_preds = np.array(total_preds).reshape(-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08898716, 0.09981051, 0.08910993, 0.09161435, 0.08738621,\n",
       "       0.08209218, 0.08894475, 0.09311083, 0.08767661, 0.089401  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_softmax.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = accuracy(total_labels, total_preds, total_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = accuracy(y_data, p_data, s_data)\n",
    "\n",
    "state = {\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': deepcopy(model).cpu().state_dict(),\n",
    "    'optimizer': deepcopy(optimizer).state_dict(),\n",
    "    'results': result\n",
    "}\n",
    "    \n",
    "# save_checkpoint(state, is_best)\n",
    "    \n",
    "if tensorboard:\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 21,\n",
       " 'state_dict': OrderedDict([('convs.conv1.weights',\n",
       "               tensor([[[[-0.5944, -0.1992, -0.1329, -0.2830, -0.0429],\n",
       "                         [ 0.1678,  0.1487,  0.0649,  0.1495,  0.2905],\n",
       "                         [ 0.3148, -0.0604,  0.0631,  0.1423,  0.1018],\n",
       "                         [ 0.2333,  0.1197, -0.0104, -0.1274, -0.0253],\n",
       "                         [-0.2159,  0.0177,  0.0766,  0.2574,  0.0923]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2670, -0.2141, -0.0954, -0.1356,  0.6302],\n",
       "                         [ 0.2010,  0.4518,  0.5208, -0.3772, -0.7675],\n",
       "                         [-0.0698, -0.1385,  0.4434, -0.0452,  0.4100],\n",
       "                         [-0.4461, -0.6572,  0.2481, -0.0333, -0.3654],\n",
       "                         [-0.1314, -0.4265, -0.8888, -0.3100,  0.0976]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0922, -0.0807,  0.2819, -0.3950, -0.1866],\n",
       "                         [ 0.0678, -0.1046, -0.1972,  0.0782,  0.4036],\n",
       "                         [ 0.1316, -0.2566,  0.3940,  0.1237, -0.2969],\n",
       "                         [ 0.0968,  0.1491, -0.4326,  0.4063, -0.2853],\n",
       "                         [-0.1187,  0.2589, -0.1506, -0.1223,  0.1437]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0071, -0.0795,  0.1636,  0.2795, -0.4120],\n",
       "                         [ 0.0059,  0.3091, -0.2065,  0.1019,  0.0713],\n",
       "                         [-0.0743,  0.0619, -0.1456,  0.0529, -0.2731],\n",
       "                         [-0.1215,  0.1908, -0.1722, -0.3053,  0.0304],\n",
       "                         [-0.8166,  0.3566,  0.4344, -0.1617,  0.2059]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2129, -0.4068, -0.0066,  0.3816, -0.2372],\n",
       "                         [ 0.2957,  0.1376, -0.4656, -0.3800,  0.2127],\n",
       "                         [-0.3814, -0.5381,  0.0413, -0.0921,  0.4384],\n",
       "                         [-0.4599, -0.1070,  0.0692, -0.0454,  0.0710],\n",
       "                         [-0.1557,  0.1129, -0.0114,  0.2981,  0.0697]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0064,  0.0533, -0.2401, -0.0291,  0.3890],\n",
       "                         [ 0.0016,  0.3687,  0.0566,  0.3220, -0.0445],\n",
       "                         [-0.2868,  0.0397, -0.1420,  0.0020, -0.0308],\n",
       "                         [-0.3520, -0.6071, -0.2035,  0.0942, -0.2463],\n",
       "                         [ 0.2296,  0.1820, -0.2927, -0.5193, -0.3162]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.7513, -0.1912, -0.1397,  0.2914, -0.0313],\n",
       "                         [-0.2479,  0.1723,  0.1925,  0.1355, -0.2374],\n",
       "                         [-0.1176,  0.0207,  0.0076, -0.0462, -0.3511],\n",
       "                         [-0.1762,  0.3167,  0.2377, -0.6295, -0.0386],\n",
       "                         [-0.1984, -0.1761, -0.4936,  0.2085,  0.3652]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.4184, -0.0168,  0.0397, -0.0428,  0.0394],\n",
       "                         [ 0.1312, -0.1828,  0.1559, -0.1577,  0.2076],\n",
       "                         [-0.2163,  0.4019, -0.6661,  0.2959,  0.1205],\n",
       "                         [ 0.0628,  0.2027, -0.2419,  0.1269, -0.0912],\n",
       "                         [ 0.1758, -0.2065, -0.3906,  0.2332, -0.1587]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0433, -0.6476,  0.0951,  0.1936,  0.0551],\n",
       "                         [-0.4725, -0.2897, -0.7993,  0.0710,  0.4196],\n",
       "                         [ 0.0718,  0.1651, -0.7048, -0.1763,  0.4664],\n",
       "                         [-0.1878, -0.2328, -0.4943, -0.1546, -0.1982],\n",
       "                         [-0.0294, -0.2384,  0.1033, -0.0679,  0.0923]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1107, -0.1836, -0.7724,  0.0997, -0.1836],\n",
       "                         [-0.0916,  0.4267, -0.3941, -0.5814,  0.2433],\n",
       "                         [ 0.1694,  0.1419,  0.0566, -0.5365, -0.4709],\n",
       "                         [-0.0231, -0.1778,  0.6985, -0.3844,  0.0766],\n",
       "                         [ 0.1357,  0.0368,  0.1604,  0.0542,  0.0480]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1834, -0.3423,  0.2629,  0.0676,  0.5214],\n",
       "                         [ 0.2271,  0.1532,  0.0257,  0.0225, -0.7002],\n",
       "                         [-0.2968, -0.2338,  0.0262, -0.1358,  0.3034],\n",
       "                         [-0.1864,  0.3416,  0.0159,  0.0043,  0.5807],\n",
       "                         [ 0.2741,  0.0665, -0.1119, -0.2528, -0.5722]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0647,  0.1077, -0.1275, -0.0829, -0.4861],\n",
       "                         [-0.5136, -0.1404, -0.3915, -0.6083,  0.4320],\n",
       "                         [ 0.3192, -0.1721,  0.0078,  0.3236, -0.2665],\n",
       "                         [ 0.0337,  0.3236, -0.0121, -0.4957,  0.4263],\n",
       "                         [-0.1970, -0.0546, -0.1175, -0.1666,  0.1752]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2122, -0.0087,  0.2271,  0.0117,  0.0819],\n",
       "                         [-0.1848,  0.1766,  0.4718, -0.2686,  0.1438],\n",
       "                         [-0.0258,  0.3807, -0.0228, -0.6277,  0.0611],\n",
       "                         [ 0.0411, -0.2100,  0.2578, -0.0715, -0.1391],\n",
       "                         [-0.0180,  0.3309, -0.1147, -0.7012, -0.3641]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0126, -0.2796,  0.3451,  0.1154, -0.6696],\n",
       "                         [-0.3927,  0.6252, -0.6768,  0.2945, -0.1693],\n",
       "                         [ 0.1818, -0.0768,  0.2630,  0.1308,  0.1364],\n",
       "                         [ 0.2979, -0.0037, -0.3655, -0.1887, -0.2330],\n",
       "                         [-0.3359, -0.2297,  0.2978,  0.1013,  0.0628]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1953,  0.4618, -0.3677, -0.2185, -0.4990],\n",
       "                         [-0.1103, -0.4442,  0.3476,  0.5839,  0.2102],\n",
       "                         [ 0.0743, -0.5866, -0.0593,  0.1741, -0.2413],\n",
       "                         [ 0.1416, -0.2284,  0.2103, -0.2426, -0.4677],\n",
       "                         [ 0.4153,  0.3739, -0.1253, -0.4657,  0.0977]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0410, -0.1346,  0.1798, -0.2815, -0.0924],\n",
       "                         [ 0.0590, -0.2170, -0.0880, -0.0592,  0.0762],\n",
       "                         [ 0.1598,  0.4646,  0.2374,  0.2168,  0.3721],\n",
       "                         [-0.2325, -0.2279,  0.0852, -0.0457,  0.1854],\n",
       "                         [ 0.0325, -0.3197, -0.2378, -0.4986, -0.2459]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1892,  0.0670, -0.0155, -0.0659, -0.0858],\n",
       "                         [ 0.2506,  0.2834, -0.7833, -0.3399, -0.0290],\n",
       "                         [-0.1116, -0.1618, -0.7011,  0.2537, -0.0541],\n",
       "                         [ 0.1619, -0.9073, -0.0496,  0.0974,  0.1480],\n",
       "                         [-0.6239, -0.3776,  0.4930,  0.0640, -0.1348]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1773, -0.4853, -0.1459,  0.2552,  0.0139],\n",
       "                         [-0.2668,  0.4868,  0.2065, -0.3218,  0.3325],\n",
       "                         [-0.0274,  0.6266, -0.3677, -0.2117, -0.0025],\n",
       "                         [-0.5085,  0.0105,  0.2523,  0.4623, -0.5126],\n",
       "                         [ 0.1103, -0.4554,  0.1828, -0.2744, -0.2354]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.3108, -0.1859, -0.2699, -0.0914,  0.1819],\n",
       "                         [ 0.0419,  0.3031, -0.2066, -0.2603,  0.0327],\n",
       "                         [ 0.2133, -0.1339, -0.6071,  0.2551, -0.1742],\n",
       "                         [ 0.0945, -0.1771,  0.1020, -0.3459,  0.2791],\n",
       "                         [-0.1685, -0.0367, -0.1583,  0.0574,  0.1796]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1247,  0.3702, -0.0540,  0.2048, -0.1808],\n",
       "                         [-0.5234, -0.2653,  0.1632,  0.3981,  0.2372],\n",
       "                         [-0.0073,  0.0300, -0.8224, -0.1751,  0.1178],\n",
       "                         [ 0.1026, -0.0902,  0.0609,  0.0836, -0.0759],\n",
       "                         [ 0.0297,  0.4438, -0.1001,  0.2298, -0.1280]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0592,  0.1861,  0.1710, -0.2460, -0.2231],\n",
       "                         [-0.0161, -0.2300,  0.0867, -0.1610, -0.1099],\n",
       "                         [-0.6511,  0.3505, -0.1495,  0.0408,  0.1721],\n",
       "                         [-0.2751, -0.3285,  0.1965,  0.5970, -0.1801],\n",
       "                         [-0.2559,  0.1541,  0.0640,  0.2581, -0.6823]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1099,  0.0759,  0.2168, -0.0670, -0.1653],\n",
       "                         [-0.1661, -0.0768,  0.2469, -0.2896,  0.5351],\n",
       "                         [-0.1791,  0.5460, -0.2107, -0.1714,  0.1412],\n",
       "                         [-0.0329,  0.1396, -0.1112,  0.0317, -0.2454],\n",
       "                         [-0.0680, -0.5379, -0.3173,  0.3418,  0.0175]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0641,  0.1995,  0.1816, -0.3334, -0.3063],\n",
       "                         [-0.0417, -0.6632, -0.6221, -0.1459, -0.3026],\n",
       "                         [-0.0354,  0.2962,  0.3115,  0.0979,  0.4422],\n",
       "                         [ 0.2027,  0.2978, -0.1227, -0.2887,  0.0604],\n",
       "                         [-0.0768, -0.2011, -0.5143,  0.0858, -0.4296]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1979,  0.2265, -0.3777,  0.0708, -0.0219],\n",
       "                         [-0.2918, -0.6162, -0.0546, -0.0323,  0.1143],\n",
       "                         [-0.1972,  0.0211,  0.2738, -0.3010,  0.1047],\n",
       "                         [-0.1900, -0.5108,  0.6952, -0.0023, -0.2318],\n",
       "                         [ 0.1836, -0.0632, -0.0232, -0.2221, -0.0684]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0911,  0.0895, -0.1602,  0.0112, -0.0270],\n",
       "                         [ 0.0822, -0.5255, -0.1344, -0.0570,  0.2145],\n",
       "                         [ 0.0711, -0.4464, -0.0508,  0.2269,  0.0807],\n",
       "                         [ 0.1694, -0.0515,  0.2427,  0.2096, -0.2012],\n",
       "                         [ 0.0534,  0.2131,  0.0787, -0.2437, -0.2838]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0483,  0.0808, -0.0068, -0.0132, -0.0414],\n",
       "                         [ 0.0018,  0.2676,  0.2260,  0.1226, -0.2510],\n",
       "                         [-0.2157, -0.3576,  0.4317,  0.1594, -0.0828],\n",
       "                         [-0.2605, -0.3596,  0.0255,  0.0073, -0.1818],\n",
       "                         [ 0.4560, -0.4172, -0.4418,  0.1752, -0.0062]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1192,  0.6116, -0.1106, -0.0585,  0.2985],\n",
       "                         [ 0.1052, -0.5526, -0.1183,  0.1720, -0.4083],\n",
       "                         [-0.1531, -0.1165, -0.2643, -0.6977, -0.0733],\n",
       "                         [-0.5346, -0.5834, -0.2958,  0.1889, -0.2023],\n",
       "                         [-0.6266,  0.4637,  0.0480,  0.3603,  0.1274]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.6549, -0.0594, -0.1413,  0.3967,  0.2838],\n",
       "                         [ 0.0205,  0.3012,  0.0833,  0.1770,  0.0574],\n",
       "                         [-0.5440, -0.0063,  0.1609, -0.2522, -0.3810],\n",
       "                         [-0.0055, -0.2595, -0.5614, -0.0355,  0.1552],\n",
       "                         [-0.2142, -0.0362, -0.1327,  0.1304, -0.0452]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2553, -0.0416,  0.1625,  0.3595, -0.1001],\n",
       "                         [-0.4361,  0.3216, -0.4435, -0.5483, -0.0486],\n",
       "                         [ 0.1568, -0.2296,  0.0094,  0.2982, -0.0780],\n",
       "                         [-0.0403,  0.1762,  0.0574, -0.1740,  0.1647],\n",
       "                         [ 0.3071, -0.4680,  0.0701,  0.1589, -0.1954]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1255, -0.1857, -0.1251,  0.1232,  0.1621],\n",
       "                         [-0.2022, -0.0133,  0.3180,  0.3155, -0.3966],\n",
       "                         [ 0.5582,  0.2556, -0.4289,  0.1979,  0.0839],\n",
       "                         [-0.1884, -0.0241, -0.6057, -0.3606, -0.2529],\n",
       "                         [-0.0097, -0.3247,  0.2236,  0.3399,  0.1775]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1239,  0.0894, -0.1914, -0.0985,  0.3297],\n",
       "                         [ 0.0629, -0.0616, -0.2889, -0.2724,  0.2000],\n",
       "                         [-0.4653, -0.2656,  0.7030, -0.7546, -0.4214],\n",
       "                         [-0.1636, -0.1901,  0.3632, -0.2670,  0.4767],\n",
       "                         [ 0.4886, -0.0055, -0.0962,  0.2925, -0.4141]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1688,  0.1684, -0.2523, -0.0282, -0.0321],\n",
       "                         [ 0.0621, -0.2531,  0.3261,  0.1120,  0.1368],\n",
       "                         [-0.2027, -0.0052,  0.3328, -0.1999, -0.7786],\n",
       "                         [ 0.0347,  0.0828, -0.6073,  0.0240, -0.6614],\n",
       "                         [-0.2390, -0.1091,  0.1173,  0.0524, -0.2843]]]])),\n",
       "              ('convs.conv1.bias',\n",
       "               tensor([-0.2890, -0.0423, -0.2600, -0.1884, -0.2058,  0.0486, -0.1206, -0.2255,\n",
       "                       -0.1050, -0.0039, -0.2761, -0.0526, -0.2170, -0.1789, -0.1909, -0.1627,\n",
       "                       -0.0219, -0.1336, -0.1917, -0.2877, -0.1931, -0.2940, -0.0208, -0.1328,\n",
       "                       -0.1964, -0.0840, -0.0453, -0.1052, -0.2387, -0.2219, -0.2493, -0.0417])),\n",
       "              ('convs.conv2.weights',\n",
       "               tensor([[[[-3.4004e-02,  1.4043e-01, -5.7137e-02,  9.7897e-02, -4.2452e-02],\n",
       "                         [-2.7853e-02, -4.9048e-02, -1.5950e-02, -4.3300e-02, -8.6322e-02],\n",
       "                         [ 3.0834e-02, -3.3961e-02, -8.1535e-02,  4.4573e-02, -1.3126e-02],\n",
       "                         [ 2.4834e-02, -3.3610e-03, -5.2513e-02,  1.5182e-02,  1.4391e-02],\n",
       "                         [-6.0697e-02, -5.9009e-02,  2.7378e-02, -6.8803e-02,  4.0611e-02]],\n",
       "               \n",
       "                        [[-2.1032e-02,  6.8292e-02, -6.8912e-02, -7.4892e-02, -6.7803e-02],\n",
       "                         [-4.6332e-02, -3.9555e-02, -1.0355e-01, -1.1271e-01,  1.6810e-02],\n",
       "                         [-2.3382e-02,  2.3296e-02,  2.5556e-02, -4.4468e-02,  9.6728e-02],\n",
       "                         [-2.3205e-02,  1.6019e-02,  1.1977e-03,  5.8699e-02,  7.6811e-03],\n",
       "                         [ 5.8440e-02,  8.9917e-03, -1.0483e-01,  3.3741e-02,  2.7005e-03]],\n",
       "               \n",
       "                        [[-4.3283e-02,  4.0688e-02, -3.2515e-02,  4.5044e-03, -1.4263e-02],\n",
       "                         [ 2.6189e-02, -1.7571e-03,  8.2036e-02, -1.8460e-02,  4.0333e-02],\n",
       "                         [-2.5612e-02, -8.8628e-02, -5.7095e-02, -1.3416e-02,  4.5277e-02],\n",
       "                         [ 1.5407e-02, -1.2940e-02, -2.5007e-02,  3.8511e-03, -4.7463e-02],\n",
       "                         [-1.0310e-01,  4.6166e-02, -3.5566e-02, -5.4089e-02, -1.5795e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.8329e-02, -2.3459e-02, -6.0763e-03,  2.2158e-02, -1.1248e-01],\n",
       "                         [ 3.8210e-03,  1.2626e-02, -1.2041e-02, -9.6425e-02,  3.2230e-02],\n",
       "                         [-9.9717e-02, -1.6940e-02, -5.5372e-02,  2.0348e-02,  1.2610e-02],\n",
       "                         [ 5.2866e-02,  1.1933e-02,  2.0965e-02, -2.5502e-02, -3.0908e-03],\n",
       "                         [-3.6507e-02,  3.0595e-02,  4.9412e-02, -2.4156e-02,  1.5817e-02]],\n",
       "               \n",
       "                        [[-9.3702e-02,  4.5235e-02,  5.0294e-02,  1.6700e-02,  3.7494e-02],\n",
       "                         [ 1.2787e-01, -1.1054e-01,  4.8135e-02,  1.0577e-01, -1.4738e-03],\n",
       "                         [ 1.4908e-02, -2.5108e-02, -1.4335e-02,  2.6129e-02,  2.8904e-02],\n",
       "                         [ 4.2059e-02,  6.6878e-03, -1.1911e-02, -7.2891e-02, -1.0321e-02],\n",
       "                         [ 2.3637e-02,  8.2142e-02,  4.5732e-02,  2.3729e-02, -2.2598e-02]],\n",
       "               \n",
       "                        [[-2.8680e-02,  1.0354e-02,  1.2998e-02,  4.3706e-03,  3.4896e-03],\n",
       "                         [-4.4085e-02,  7.9125e-02, -3.1057e-02,  2.8844e-02, -3.5744e-02],\n",
       "                         [-1.2022e-01,  5.8011e-03, -2.8027e-02, -2.7400e-02,  3.6877e-02],\n",
       "                         [ 4.4064e-02,  1.7275e-02,  8.5672e-03, -6.2776e-02,  1.3228e-02],\n",
       "                         [ 6.7207e-03, -3.5125e-02, -5.3713e-03,  7.4300e-03, -7.5564e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.2023e-02, -9.4256e-02,  3.8521e-02,  2.2760e-02, -6.7960e-02],\n",
       "                         [-3.1031e-02, -1.9692e-01, -9.0613e-02, -2.0082e-02,  4.0444e-02],\n",
       "                         [-7.1990e-02, -1.3317e-02,  7.3457e-02,  5.3056e-02,  5.5761e-02],\n",
       "                         [-8.0117e-02,  1.2832e-01, -4.5835e-02,  4.9519e-03, -1.3286e-01],\n",
       "                         [-5.7204e-02, -1.0227e-02,  7.1600e-02, -2.6735e-02,  5.4004e-03]],\n",
       "               \n",
       "                        [[-1.4665e-01, -5.0219e-02, -9.9418e-02, -3.0655e-02,  2.8992e-02],\n",
       "                         [ 2.9026e-02, -1.0288e-01, -2.1375e-02, -6.6546e-02, -1.6793e-01],\n",
       "                         [ 2.2010e-01,  9.5176e-02, -7.5095e-02, -1.5421e-01, -2.8410e-01],\n",
       "                         [-1.8477e-02,  1.2277e-01, -7.5819e-02, -2.4323e-01,  6.1159e-02],\n",
       "                         [ 1.6927e-01, -1.7812e-01, -2.5289e-01, -1.5325e-01,  1.4978e-02]],\n",
       "               \n",
       "                        [[-3.8282e-02,  1.6934e-02, -6.9453e-02,  8.6308e-03,  1.3519e-02],\n",
       "                         [-4.4584e-02, -7.4336e-02,  6.1703e-02,  3.3066e-02, -8.2325e-03],\n",
       "                         [-5.7477e-02, -1.1466e-01, -4.8508e-02, -8.6184e-02,  6.9801e-02],\n",
       "                         [ 4.9651e-03, -4.4491e-02, -6.2084e-02, -2.9024e-02,  4.4365e-02],\n",
       "                         [-5.5408e-03, -1.9429e-01,  1.0648e-01,  8.7079e-02,  5.0231e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.5020e-01, -1.3885e-01,  1.2890e-01,  9.5716e-02,  6.0193e-02],\n",
       "                         [-7.1931e-02,  1.9965e-03, -6.5371e-02,  9.4585e-02,  9.8423e-02],\n",
       "                         [-1.2127e-01,  4.8060e-03,  6.6120e-02,  1.2995e-02,  2.2986e-02],\n",
       "                         [ 1.4758e-01,  1.5988e-02,  7.2531e-02, -1.7290e-01, -2.6751e-02],\n",
       "                         [ 6.6798e-02, -1.0006e-01, -1.1099e-01, -1.8916e-02,  1.8324e-01]],\n",
       "               \n",
       "                        [[-4.8740e-02, -1.3341e-01, -2.1895e-02,  3.7875e-02,  1.0730e-01],\n",
       "                         [ 1.1052e-01, -2.7143e-02,  2.3929e-02,  8.6772e-02, -7.9732e-02],\n",
       "                         [-1.0643e-01,  6.4899e-02, -1.2556e-01, -9.6482e-02, -7.3353e-02],\n",
       "                         [ 5.3592e-02,  3.6551e-02,  9.7746e-02, -5.0240e-02,  2.4251e-02],\n",
       "                         [ 7.7973e-03, -2.2379e-02, -1.9111e-01, -2.5596e-02,  2.9515e-02]],\n",
       "               \n",
       "                        [[-1.5961e-01, -7.7476e-03,  8.1302e-02,  3.5579e-03,  1.5337e-02],\n",
       "                         [-1.1618e-01,  7.1237e-02, -3.4908e-02, -2.9589e-02, -1.2725e-01],\n",
       "                         [ 7.7030e-02,  7.9107e-02, -1.3587e-01, -2.1865e-01, -1.8110e-01],\n",
       "                         [ 4.7923e-02,  3.2553e-02, -4.7548e-02, -7.4956e-02, -7.3352e-02],\n",
       "                         [ 3.1885e-02, -3.2405e-03,  2.7561e-02,  1.0891e-01, -7.6646e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.1248e-02,  3.0549e-02,  1.2820e-01,  4.2948e-02,  6.1555e-02],\n",
       "                         [-4.6135e-02,  1.0728e-01,  2.5931e-03,  4.6587e-02,  5.5805e-02],\n",
       "                         [ 9.4894e-02, -7.0275e-03, -5.2711e-02,  1.2671e-02,  3.7381e-02],\n",
       "                         [-2.0073e-02, -9.7685e-02, -1.2557e-01, -1.3183e-01,  9.9789e-03],\n",
       "                         [ 2.9982e-02, -1.3894e-01, -4.4619e-02, -9.0577e-02,  7.3599e-02]],\n",
       "               \n",
       "                        [[-6.0344e-02, -2.8147e-01, -2.6473e-01, -5.7779e-03,  1.7219e-01],\n",
       "                         [-1.2514e-01, -1.2626e-01, -1.6063e-01, -6.1256e-02,  1.1059e-02],\n",
       "                         [-7.5433e-02, -1.6499e-01, -1.2312e-01,  1.3540e-01,  7.9134e-02],\n",
       "                         [-1.1013e-01,  4.9043e-02,  2.2863e-02,  9.9115e-02, -7.9407e-02],\n",
       "                         [ 2.6120e-02,  9.2743e-02,  1.1582e-01,  2.9784e-02, -7.5458e-02]],\n",
       "               \n",
       "                        [[-3.3233e-02, -1.5588e-03,  4.1763e-02,  2.9241e-02, -1.6454e-02],\n",
       "                         [ 1.3845e-01,  4.6319e-02,  2.2484e-02, -6.2430e-02, -4.9607e-03],\n",
       "                         [ 4.2492e-02,  6.9923e-02,  5.4835e-02, -1.1120e-01,  6.1764e-02],\n",
       "                         [ 1.6685e-02, -8.2236e-03,  7.2130e-02,  2.3999e-02,  1.1102e-01],\n",
       "                         [-6.1934e-02, -5.0922e-02,  3.9607e-02,  3.8124e-02, -8.2016e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0622e-01,  3.7738e-02, -1.5174e-01,  3.4538e-02,  9.5908e-02],\n",
       "                         [-1.1089e-01, -1.2474e-01,  2.5982e-02, -1.6151e-01, -5.6995e-02],\n",
       "                         [ 2.8954e-02,  1.1897e-02, -1.6746e-01, -7.3915e-02, -1.0651e-01],\n",
       "                         [ 9.1497e-02,  5.1939e-02,  7.1556e-02, -1.1431e-01,  6.5827e-05],\n",
       "                         [ 8.7437e-02,  2.3115e-02,  1.1924e-01,  1.0217e-01,  7.8832e-02]],\n",
       "               \n",
       "                        [[-5.6162e-02, -2.2979e-01,  5.3828e-03, -1.2858e-01,  6.2466e-02],\n",
       "                         [-4.4656e-02,  9.3993e-03, -1.3421e-01, -8.6152e-02,  2.0292e-01],\n",
       "                         [-3.3580e-02, -1.7121e-01, -1.2103e-01,  1.0399e-01,  1.1265e-01],\n",
       "                         [ 1.2201e-01, -5.9931e-03, -8.7116e-03,  2.5075e-02, -1.0982e-01],\n",
       "                         [ 9.5497e-02,  8.3616e-02, -7.5047e-03,  2.6866e-02, -1.0373e-02]],\n",
       "               \n",
       "                        [[-3.7390e-02,  3.4526e-02,  3.7612e-02, -6.3580e-02,  1.3075e-01],\n",
       "                         [-2.6054e-02, -9.5447e-02,  3.5453e-02, -1.0869e-01,  6.0890e-02],\n",
       "                         [-9.9878e-02, -7.8989e-02,  7.9683e-02, -3.5183e-02, -1.4193e-02],\n",
       "                         [-8.2332e-02, -1.3027e-02,  6.5450e-02,  1.1370e-02, -1.8389e-02],\n",
       "                         [ 1.0457e-01,  1.3210e-01, -1.1691e-01, -2.5528e-02,  6.1490e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 5.4117e-03, -6.6204e-02, -3.6947e-02, -5.7999e-02, -3.5414e-02],\n",
       "                         [-1.6229e-01,  1.7211e-02, -5.3085e-02, -1.7328e-02, -1.5754e-01],\n",
       "                         [-1.0726e-01, -7.9038e-02, -6.6327e-02, -6.5928e-02, -8.5146e-02],\n",
       "                         [ 7.6598e-03, -1.1643e-01, -1.4954e-01, -2.1303e-02, -1.5787e-01],\n",
       "                         [ 1.2532e-02, -1.0675e-02, -1.3655e-01, -1.7730e-01, -8.1897e-02]],\n",
       "               \n",
       "                        [[ 1.1082e-01,  6.1833e-02, -9.1002e-02, -3.5788e-02, -9.2042e-02],\n",
       "                         [ 9.3220e-03, -5.2453e-02,  3.7543e-02, -2.4710e-03, -5.1748e-02],\n",
       "                         [-1.5859e-01, -1.4901e-01, -9.3292e-02,  3.8738e-02,  2.9160e-01],\n",
       "                         [-3.4064e-02, -1.6857e-01, -7.7804e-02, -1.0230e-01, -8.6100e-02],\n",
       "                         [-5.5959e-02,  8.7673e-03,  2.2466e-02, -7.5658e-02, -2.5032e-02]],\n",
       "               \n",
       "                        [[-4.0417e-02,  8.3519e-02,  7.9750e-03, -7.3471e-02, -9.2470e-02],\n",
       "                         [-7.1736e-02, -9.7783e-02,  4.9490e-02, -2.3645e-02,  1.3320e-01],\n",
       "                         [-1.5521e-01, -1.4575e-01, -3.7194e-02,  2.7744e-02, -7.4154e-02],\n",
       "                         [ 9.5847e-02, -6.6851e-02,  5.5026e-03,  5.3999e-02, -4.0841e-02],\n",
       "                         [-6.4918e-02, -7.7327e-02, -1.2034e-01, -2.8631e-02,  1.9485e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.8067e-02,  3.6781e-02, -3.9667e-02, -1.9232e-01,  5.9187e-04],\n",
       "                         [-2.0212e-01, -1.5934e-01, -3.8847e-02, -7.7750e-02, -3.1478e-02],\n",
       "                         [-1.6315e-01, -8.8789e-02, -4.2977e-03, -6.6634e-03, -9.4616e-02],\n",
       "                         [-9.0044e-02, -5.9441e-02, -8.9809e-02, -1.2368e-01, -9.1242e-02],\n",
       "                         [ 7.2318e-02, -1.2049e-01, -9.4337e-02, -2.1982e-01, -1.8092e-01]],\n",
       "               \n",
       "                        [[-8.3751e-02, -2.0946e-03,  9.3939e-02,  1.0093e-02, -2.9418e-01],\n",
       "                         [-1.0904e-01, -5.9370e-02, -8.2430e-02, -3.0269e-02, -1.4751e-01],\n",
       "                         [ 1.0914e-01,  2.1691e-02, -4.7459e-02,  6.9589e-02,  6.6820e-02],\n",
       "                         [ 5.6615e-02,  5.9024e-02, -9.9558e-03, -1.2502e-01, -1.3962e-01],\n",
       "                         [ 1.0234e-01,  2.4883e-02, -2.1524e-01, -7.5700e-02, -4.9152e-02]],\n",
       "               \n",
       "                        [[ 6.6287e-02, -1.1856e-03, -8.8468e-02, -2.6610e-03, -8.7621e-02],\n",
       "                         [ 8.5169e-02, -2.0904e-02, -8.4577e-02, -6.0520e-02, -9.3174e-03],\n",
       "                         [-2.1432e-01, -1.6907e-01, -7.9795e-02,  3.1064e-02,  1.6539e-01],\n",
       "                         [-2.8219e-02, -4.7984e-02,  8.6890e-03,  2.9769e-03, -1.8116e-02],\n",
       "                         [-1.2013e-01, -1.3927e-01, -5.5300e-02,  4.0244e-02, -1.6891e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.3831e-02, -5.6563e-02,  1.7534e-03, -7.6592e-02,  6.2345e-02],\n",
       "                         [ 4.3443e-03, -9.0434e-02,  9.9518e-02,  4.5412e-02, -5.0260e-02],\n",
       "                         [ 2.3992e-02, -2.3775e-02,  5.9878e-02,  3.7330e-02, -3.1080e-02],\n",
       "                         [-1.8162e-02, -3.5652e-02, -3.0438e-02,  5.1334e-02,  6.6617e-02],\n",
       "                         [-9.7219e-03,  3.8932e-02,  1.0197e-01, -6.6945e-03,  3.3381e-02]],\n",
       "               \n",
       "                        [[-3.3109e-03,  1.7056e-02,  6.0889e-02, -1.0987e-01, -5.7986e-02],\n",
       "                         [-2.1645e-02, -2.5194e-02, -3.3100e-02,  4.6169e-03, -4.1664e-02],\n",
       "                         [-4.8919e-02, -7.4992e-03,  1.2751e-02, -4.6162e-03,  6.5039e-03],\n",
       "                         [-5.4589e-03, -3.3648e-02, -1.6121e-02,  2.2571e-02,  2.2453e-02],\n",
       "                         [ 6.2029e-02,  1.0049e-01, -2.8770e-02, -6.3176e-02,  6.4621e-02]],\n",
       "               \n",
       "                        [[-2.2086e-02,  4.2515e-02, -2.2864e-02, -1.6831e-02,  1.0721e-02],\n",
       "                         [ 6.7992e-02,  5.9108e-02, -4.2164e-02, -1.2587e-02,  7.3215e-02],\n",
       "                         [ 2.2967e-02, -5.2398e-02, -1.4034e-02,  1.5157e-02, -3.1263e-02],\n",
       "                         [ 8.6637e-02, -1.4383e-02, -1.3090e-02, -1.8029e-02, -7.8432e-02],\n",
       "                         [-1.8834e-02, -1.6238e-02, -5.2375e-02,  8.6994e-03, -6.0611e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.9310e-02,  5.7343e-03, -1.0563e-02, -2.0562e-03, -2.1707e-02],\n",
       "                         [-1.9459e-02,  7.9136e-02,  5.2901e-02, -8.3918e-02, -5.4755e-02],\n",
       "                         [-2.7406e-02,  3.4449e-02, -4.9950e-02,  6.7188e-02,  1.0776e-01],\n",
       "                         [-6.9486e-02, -5.9985e-02,  3.0708e-02, -6.9453e-02,  5.5068e-03],\n",
       "                         [-3.7658e-02, -4.9718e-02,  4.5107e-02,  1.3245e-02, -3.6206e-02]],\n",
       "               \n",
       "                        [[-2.0187e-02, -2.1179e-02, -1.7311e-02, -3.9240e-02,  1.5226e-02],\n",
       "                         [ 2.1197e-03, -2.2580e-02, -6.3336e-02,  1.6399e-02, -6.7903e-02],\n",
       "                         [ 2.7546e-02, -1.9695e-02,  1.1153e-02, -1.1456e-01, -2.9107e-02],\n",
       "                         [-6.3356e-02,  9.4576e-02, -3.0651e-02,  4.4247e-02, -1.3401e-01],\n",
       "                         [-5.2095e-02, -2.0270e-02,  1.8121e-02,  5.9563e-02,  3.9766e-02]],\n",
       "               \n",
       "                        [[ 6.5754e-02, -8.9021e-03,  1.4944e-01, -6.7717e-02, -6.7142e-02],\n",
       "                         [-8.3833e-03,  2.7489e-04, -1.4069e-02, -3.7094e-02,  4.8855e-04],\n",
       "                         [-4.2176e-02,  1.7843e-02, -7.7540e-02,  1.0367e-02,  5.3939e-02],\n",
       "                         [-1.0161e-01,  4.8189e-02, -6.0445e-02,  2.3132e-02, -6.7866e-02],\n",
       "                         [-3.7113e-03,  1.3194e-02, -2.0648e-02, -2.8080e-02, -5.7221e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.5499e-02, -1.1970e-01,  1.3986e-02, -2.0162e-01,  1.1692e-02],\n",
       "                         [-1.2827e-01, -1.5909e-01, -1.0482e-01, -1.1947e-01, -2.6579e-02],\n",
       "                         [-9.4956e-02, -8.1517e-02, -2.2195e-01, -1.0781e-01,  3.1355e-02],\n",
       "                         [ 9.6400e-03, -2.0776e-01, -2.4462e-01,  4.8277e-02,  9.5874e-03],\n",
       "                         [-8.7929e-02, -2.0658e-01, -1.4156e-01,  8.3112e-02,  2.0918e-02]],\n",
       "               \n",
       "                        [[ 1.0093e-01,  5.2917e-02, -5.1404e-02, -1.6006e-01, -1.3422e-01],\n",
       "                         [ 3.8597e-02,  2.5550e-03,  2.5961e-02, -1.4672e-01, -7.8240e-02],\n",
       "                         [ 2.2062e-01, -4.2835e-02, -6.5889e-02,  8.2575e-02, -2.0578e-01],\n",
       "                         [-7.5855e-02, -1.1354e-01,  1.4116e-01,  1.1200e-02, -1.6848e-01],\n",
       "                         [-1.0065e-01,  2.4055e-01,  3.2185e-02, -1.6463e-01, -8.2793e-02]],\n",
       "               \n",
       "                        [[-9.7270e-03,  2.8017e-02, -3.8782e-02, -1.2439e-01, -5.4970e-02],\n",
       "                         [ 1.4922e-01,  5.8496e-02, -1.6407e-01, -1.7057e-01, -1.3450e-01],\n",
       "                         [ 1.4617e-03, -6.8935e-02,  5.6887e-03,  4.8247e-02,  7.9752e-02],\n",
       "                         [-3.3162e-02, -1.4263e-01, -2.1299e-01, -1.7391e-01,  9.0445e-03],\n",
       "                         [-1.6406e-01, -2.0407e-01, -2.5689e-01,  9.5237e-02, -6.4999e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.1833e-02, -3.7233e-02,  4.7273e-03, -8.1901e-02, -1.3511e-01],\n",
       "                         [ 9.3729e-03,  1.1846e-01, -1.4320e-01, -6.6418e-02, -3.6178e-03],\n",
       "                         [-1.0586e-01, -5.2698e-02, -6.8021e-02, -2.2276e-01,  2.3775e-02],\n",
       "                         [-1.3976e-01, -1.7714e-01, -1.1735e-02, -1.2568e-02,  1.2525e-03],\n",
       "                         [-4.2728e-02, -7.5647e-02, -3.8398e-02, -1.5343e-01, -8.8081e-02]],\n",
       "               \n",
       "                        [[-2.1929e-02,  8.2099e-02,  4.6843e-02, -7.6609e-02, -1.3365e-01],\n",
       "                         [-3.2115e-02,  7.0239e-02,  1.0740e-01, -1.2158e-01, -1.1679e-02],\n",
       "                         [ 5.5614e-03, -8.5275e-02,  2.5453e-02,  3.8839e-02, -1.1667e-01],\n",
       "                         [-1.3561e-02, -1.2571e-01, -2.6497e-01, -1.5053e-01, -1.0683e-02],\n",
       "                         [ 7.8350e-02, -3.6537e-02, -1.0779e-01,  7.0832e-02,  3.5088e-02]],\n",
       "               \n",
       "                        [[ 6.2726e-02,  6.9161e-02,  1.7291e-02, -1.4502e-01,  3.2059e-02],\n",
       "                         [ 1.1367e-01,  1.8253e-01,  1.6200e-01, -1.6892e-01, -2.1203e-01],\n",
       "                         [ 2.1393e-01, -3.7588e-02,  4.3429e-02,  9.9094e-02, -4.3247e-02],\n",
       "                         [-4.2878e-02, -4.0347e-02,  1.1506e-01,  8.0707e-02, -8.9730e-02],\n",
       "                         [-4.3773e-02, -6.9757e-02,  6.6036e-02, -1.0904e-02,  6.8772e-02]]]])),\n",
       "              ('convs.conv2.bias',\n",
       "               tensor([-4.5504e+08, -9.3663e-02, -4.3561e-02, -2.0428e-02, -3.0812e+07,\n",
       "                       -6.4926e-02, -3.1392e+07, -5.1905e-02, -4.6889e+08, -3.9716e-02,\n",
       "                       -4.1977e+08, -9.8515e-02, -4.7596e+08, -3.9983e-02, -4.3249e+08,\n",
       "                       -9.3404e-02, -1.4527e+08, -1.1992e-01, -5.4048e+07, -2.1471e-02,\n",
       "                       -1.3740e+08, -1.2185e-01, -3.7228e+07, -4.5113e-02, -4.1132e+08,\n",
       "                       -7.5535e-02, -3.6198e-02, -6.5076e-02, -4.9085e-02, -8.1849e-02,\n",
       "                       -4.7570e+08,  4.6451e-03, -4.0709e-02,  2.0556e-02, -9.7430e-02,\n",
       "                       -7.3555e-03, -5.3737e-02, -6.8431e-02, -2.5875e+08, -7.9909e-02,\n",
       "                       -4.6988e+08, -8.9095e-03,  4.2193e-02, -7.4134e-02, -2.6628e+08,\n",
       "                       -6.7329e-02, -5.2424e-02, -1.0021e-01, -4.7759e+08, -3.8798e-02,\n",
       "                       -4.7579e+08, -7.5504e-02, -3.8539e-02, -2.9129e-02, -4.5039e+08,\n",
       "                       -4.6267e-03, -2.2409e-01, -9.5654e-02, -9.8355e-03, -7.7818e-02,\n",
       "                        1.0038e-02,  4.1743e-02, -1.3759e+08,  2.9047e-02])),\n",
       "              ('fcs.fc1.weights',\n",
       "               tensor([[ 0.0450, -0.0396, -0.0135,  ...,  0.0650, -0.1237, -0.0005],\n",
       "                       [-0.1112,  0.0086, -0.0522,  ..., -0.1432,  0.0018, -0.0485],\n",
       "                       [ 0.0798,  0.0444, -0.1176,  ...,  0.0070, -0.0886,  0.0093],\n",
       "                       ...,\n",
       "                       [ 0.0064, -0.2584,  0.3315,  ...,  0.0964, -0.0780, -0.1031],\n",
       "                       [ 0.1225, -0.1247,  0.0997,  ...,  0.1385,  0.1018, -0.0231],\n",
       "                       [ 0.2101,  0.2801, -0.1007,  ...,  0.0978,  0.0603,  0.1170]])),\n",
       "              ('fcs.fc1.bias',\n",
       "               tensor([-1.3725e-02, -5.4835e-02, -1.0145e-03,  4.4958e-02, -3.1270e+02,\n",
       "                       -3.1046e-02, -1.6126e+09,  4.5893e-03, -3.3182e-02, -2.1971e-02,\n",
       "                       -5.5872e-02, -2.7817e-02, -3.1270e+02, -4.6626e-02, -1.6126e+09,\n",
       "                       -4.6884e-02, -8.1844e-02,  4.1299e-03,  4.0902e-02, -8.7885e-02,\n",
       "                       -3.1270e+02,  1.7525e-02, -1.6126e+09, -4.8888e-02, -4.9920e-02,\n",
       "                       -7.7827e-03, -5.4063e-02, -2.3759e-02, -3.1270e+02,  2.4778e-02,\n",
       "                       -1.6126e+09, -5.7097e-02, -5.3052e-02, -3.8285e-02, -2.1356e-02,\n",
       "                       -3.1439e-02, -3.1270e+02, -5.3225e-02, -1.6126e+09,  1.0673e-02,\n",
       "                       -6.3382e-02, -6.5139e-03, -5.7486e-02, -9.2088e-03, -3.1287e+02,\n",
       "                       -2.0962e-02, -2.6473e+01, -2.0631e-02,  1.4070e-02, -2.1369e-02,\n",
       "                       -8.2185e-03, -6.9052e-02, -3.1270e+02, -1.0450e-02, -1.6126e+09,\n",
       "                       -3.1195e-02, -4.6713e-02, -2.4762e-02, -6.8314e-02, -3.3650e-02,\n",
       "                       -3.1270e+02, -7.2642e-02, -1.6126e+09, -7.0237e-03,  1.3420e-02,\n",
       "                       -1.1813e-02, -4.0752e-02, -3.7955e-02, -3.1270e+02, -8.5266e-02,\n",
       "                       -1.6126e+09, -4.6634e-02, -5.1485e-02, -4.0916e-02, -3.5751e-02,\n",
       "                       -2.1340e-02, -3.1270e+02, -4.9410e-02, -1.6126e+09, -5.4716e-02,\n",
       "                       -8.1056e-04,  1.7410e-02, -1.0806e-02,  3.4096e-03, -3.1270e+02,\n",
       "                        2.3006e-02, -1.6126e+09, -4.1538e-02,  2.5944e-02, -5.6140e-02,\n",
       "                       -1.8489e-02, -1.8641e-02, -3.1270e+02, -7.1986e-02, -1.6126e+09,\n",
       "                       -3.6125e-02, -7.2745e-02, -8.0672e-02,  5.2003e-03, -4.0075e-02,\n",
       "                       -3.1270e+02, -6.3229e-02, -1.6126e+09, -8.7257e-03, -2.4335e-02,\n",
       "                       -3.7597e-02, -2.6926e-02,  7.2734e-03, -3.1270e+02, -7.5004e-02,\n",
       "                       -1.6126e+09, -7.8038e-03, -8.6884e-02, -4.3187e-02, -5.3806e-02,\n",
       "                        2.6217e-03, -3.1270e+02,  8.9373e-03, -1.6126e+09, -8.4316e-03,\n",
       "                       -4.0445e-02, -4.0844e-02, -7.0407e-03, -3.9971e-02, -3.1270e+02,\n",
       "                       -3.1502e-02, -1.6126e+09, -4.6492e-02, -5.5556e-02, -3.3112e-02,\n",
       "                       -3.3750e-02, -7.9938e-02, -3.1270e+02, -1.1053e-01, -1.6126e+09,\n",
       "                        5.5524e-03, -4.3781e-02, -3.9673e-02, -2.8666e-02, -4.8576e-02,\n",
       "                       -3.1270e+02, -8.9459e-03, -1.6126e+09, -4.5554e-03, -3.7287e-02,\n",
       "                       -1.7892e-02, -4.4149e-02, -4.5061e-02, -3.1270e+02, -3.4254e-02,\n",
       "                       -1.6126e+09, -5.9960e-03, -7.5860e-02, -5.7473e-02, -2.9015e-02,\n",
       "                       -5.5120e-02, -3.1270e+02, -7.0072e-02, -1.6126e+09, -5.3402e-02,\n",
       "                       -5.2720e-02, -1.6313e-02, -1.9587e-02, -1.0517e-01, -3.1307e+02,\n",
       "                       -5.6918e-04, -3.1295e+02, -2.9888e-02,  1.2314e-02, -6.8041e-03,\n",
       "                        2.7580e-03,  8.9066e-04, -3.1307e+02, -2.0999e-02, -1.6126e+09,\n",
       "                       -7.3258e-02, -7.7950e-02, -2.3407e-02, -5.7231e-02,  2.7708e-02,\n",
       "                       -3.1307e+02, -4.0709e-02, -1.6126e+09, -1.6774e-02, -1.2228e-01,\n",
       "                       -5.2572e-02, -1.9035e-02, -1.5414e-02, -3.1307e+02, -1.5668e-02,\n",
       "                       -1.6126e+09, -4.3943e-02, -8.0270e-02,  3.4924e-03,  3.6394e-03,\n",
       "                        2.3580e-02, -3.1307e+02,  7.7934e-03, -1.6126e+09, -9.3027e-03,\n",
       "                       -2.7181e-02, -6.1219e-02, -1.8271e-02, -2.9012e-02, -3.1307e+02,\n",
       "                        3.5581e-05, -1.6126e+09,  5.3087e-03, -1.2979e-02, -5.6065e-02,\n",
       "                       -5.8774e-03, -1.5736e-02, -3.1290e+02, -3.2542e-02, -2.6167e+01,\n",
       "                       -2.0333e-02, -3.4427e-02, -5.3563e-02,  5.3599e-02, -2.3969e-02,\n",
       "                       -3.1290e+02, -7.2971e-03, -2.7257e+01, -1.7943e-02, -6.0974e-03,\n",
       "                       -2.3240e-04, -3.6518e-02, -3.7146e-02, -3.1289e+02, -8.4639e-02,\n",
       "                       -2.7663e+01, -6.9283e-02, -1.2164e-02, -2.1654e-02, -6.4671e-02,\n",
       "                       -4.0101e-02, -3.1307e+02, -2.1380e-02, -1.6126e+09, -3.5382e-02,\n",
       "                       -5.8462e-02, -2.9364e-02, -3.1663e-02, -5.6744e-02, -3.1307e+02,\n",
       "                        2.3227e-02, -1.6126e+09, -4.2049e-02, -8.4922e-02,  7.6577e-02,\n",
       "                       -7.4472e-03, -5.8473e-02, -3.1307e+02, -6.8112e-02, -1.6126e+09,\n",
       "                       -4.6001e-02])),\n",
       "              ('fcs.fc2.weights',\n",
       "               tensor([[ 0.1149, -0.1904,  0.0122,  ...,  0.0227,  0.1372, -0.1683],\n",
       "                       [ 0.0341, -0.0457,  0.0040,  ..., -0.0573, -0.0041, -0.1466],\n",
       "                       [ 0.0747,  0.1800,  0.1055,  ...,  0.0602,  0.1074, -0.0614],\n",
       "                       ...,\n",
       "                       [-0.0009, -0.0942, -0.0412,  ..., -0.0405, -0.0651, -0.0178],\n",
       "                       [ 0.1062,  0.0031, -0.0376,  ...,  0.0502, -0.0226, -0.0125],\n",
       "                       [-0.1237,  0.0460,  0.0751,  ..., -0.0974,  0.1185, -0.1352]])),\n",
       "              ('fcs.fc2.bias',\n",
       "               tensor([-1.6128e+09, -7.1967e-02, -1.6128e+09, -2.2619e-02, -1.4768e+02,\n",
       "                        1.2644e-03, -1.4768e+02, -6.3004e-02,  2.9834e-01,  3.8077e-01,\n",
       "                        2.8906e-01, -3.1523e-02,  2.1299e-02,  2.9828e-01,  2.0601e-01,\n",
       "                        3.7956e-01,  2.0225e-01, -8.3801e-02, -1.8675e-01, -2.6715e-03,\n",
       "                       -4.8326e-02,  2.4648e-02,  1.2572e-01,  2.9510e-01,  2.1793e-01,\n",
       "                       -2.7034e-01, -3.0147e-01, -3.0571e-02, -1.6376e-01,  6.6675e-01,\n",
       "                        9.6766e-02,  3.6127e-01,  3.8022e-01, -5.0366e-01, -6.8868e-01,\n",
       "                       -1.5527e-01, -3.1909e-01,  2.3752e-01, -2.6087e-01,  4.2053e-01,\n",
       "                       -3.9455e-01, -6.1067e-01,  9.1855e-02, -1.6363e-01, -2.8383e-01,\n",
       "                       -1.7073e-01, -1.0921e-01, -7.6036e-01, -2.8137e-01,  9.6647e-02,\n",
       "                        1.1608e-01, -1.4298e-02,  4.3751e-01, -3.2997e-01, -4.6575e-02,\n",
       "                        1.1414e-01,  5.4749e-02, -4.6509e-02,  1.7283e-01,  6.5567e-01,\n",
       "                        2.2424e-01, -1.8189e-01,  5.1522e-01,  1.8606e-01, -1.2066e-01,\n",
       "                        6.4072e-02,  1.0235e-01, -4.2498e-01,  4.5044e-01, -2.6620e-01,\n",
       "                        1.4271e-03,  3.7891e-01, -8.1064e-02, -4.0362e-02,  1.9149e-01,\n",
       "                        3.3490e-03, -7.4168e-02,  1.8709e-01,  2.7785e-01, -3.6148e-01,\n",
       "                        1.6927e-01,  4.6594e-01, -2.1556e-01,  1.1674e-01,  1.1803e-01,\n",
       "                       -6.0703e-03,  1.8582e-02, -1.6305e-01,  3.0912e-02, -2.6616e-01,\n",
       "                       -1.2322e-01,  1.9822e-01, -1.5042e-01, -2.3030e-01,  9.2548e-02,\n",
       "                       -7.2394e-01,  4.4872e-01,  5.3987e-01, -7.0968e-02,  2.4572e-01,\n",
       "                        1.5389e-01, -5.7492e-01, -7.5214e-02,  3.9198e-01, -1.8629e-01,\n",
       "                        2.3045e-01,  4.9312e-02, -4.0397e-01, -3.8091e-01,  2.8840e-01,\n",
       "                       -4.1012e-01, -3.6844e-01, -4.1933e-02, -3.3628e-02,  5.2504e-01,\n",
       "                       -4.9183e-01, -2.2114e-01, -5.0905e-02, -8.2610e-02,  1.2995e-01,\n",
       "                        1.2953e-01,  1.7485e-01,  3.3412e-02,  3.5573e-01,  4.1764e-02,\n",
       "                       -6.9770e-02,  4.3820e-02, -2.9264e-01, -1.1787e-01,  3.7491e-01,\n",
       "                        1.6453e-02,  2.7556e-01, -6.5868e-02,  2.7480e-01, -1.0377e-01,\n",
       "                       -2.0082e-01, -5.6825e-02, -3.3475e-01,  1.0748e-02, -1.4079e-01,\n",
       "                       -1.0943e-01, -3.4685e-01, -2.5476e-02,  3.3850e-01, -2.4711e-01,\n",
       "                        1.0918e-02,  1.6180e-02, -2.3201e-01, -2.7422e-01, -3.2702e-01,\n",
       "                       -8.2398e-01, -1.9220e-01, -1.3837e-01,  3.2370e-01, -8.1632e-02,\n",
       "                       -2.5567e-01,  2.1358e-01,  1.5816e-01,  4.6848e-02, -2.0165e-01,\n",
       "                       -1.3792e-01,  2.0134e-02, -5.8315e-02, -6.9983e-02, -2.6063e-01,\n",
       "                       -2.5327e-01,  3.7657e-01,  2.7727e-01, -5.2841e-01, -2.1949e-03,\n",
       "                       -1.9723e-01, -3.5128e-02, -4.1315e-01,  2.2932e-01,  4.1099e-01,\n",
       "                       -2.6717e-01, -2.9813e-02,  2.9296e-02, -1.0286e-01, -3.1012e-02,\n",
       "                        1.9771e-01, -1.9057e-01,  1.4653e-01, -1.0845e-01,  2.9002e-01,\n",
       "                       -1.5781e-01,  4.8301e-01, -5.5862e-01,  3.9087e-01,  2.5842e-01,\n",
       "                        1.8684e-01,  2.8446e-01, -8.9445e-02,  1.9411e-01,  5.1489e-02,\n",
       "                        2.8605e-01, -1.0556e-01, -3.4005e-01,  3.0058e-01, -1.5536e-01,\n",
       "                       -6.0579e-04, -4.1267e-01,  2.6438e-01,  9.6989e-02, -3.7007e-02,\n",
       "                       -4.5777e-01, -1.8752e-01, -6.9261e-01, -4.2651e-02,  3.0979e-01,\n",
       "                        1.1782e-01,  5.3720e-01, -5.5097e-01, -2.3117e-01,  4.5069e-01,\n",
       "                       -3.9672e-01, -2.3696e-01, -4.3056e-01, -1.5449e-01, -2.3443e-01,\n",
       "                       -2.9534e-01, -4.4940e-01,  1.4839e-01,  2.2278e-02,  1.3456e-02,\n",
       "                       -4.8443e-02, -5.2464e-02, -5.6820e-01,  5.1881e-03, -4.8314e-01,\n",
       "                       -2.9524e-02,  3.3399e-01, -2.4535e-01, -1.4830e-01,  4.4514e-01,\n",
       "                       -5.0569e-03, -3.1284e-02, -1.0455e-01, -2.7312e-01, -3.4794e-01,\n",
       "                       -1.2535e-01, -3.0791e-01,  5.4697e-01, -4.6696e-01,  1.0185e-01,\n",
       "                        1.0567e-01, -1.6361e-02,  1.0004e-01, -2.5259e-03,  7.0368e-02,\n",
       "                       -2.9608e-01, -4.6026e-01,  2.7530e-01,  8.2898e-02,  6.8795e-01,\n",
       "                        2.8384e-01])),\n",
       "              ('fcs.fc3.weights',\n",
       "               tensor([[ 0.0543, -0.1763, -0.1098,  ..., -0.3264, -0.5128,  0.3294],\n",
       "                       [-0.1527,  0.4678, -0.6372,  ..., -0.1874, -0.6664, -0.3431],\n",
       "                       [-0.0928, -0.3526,  0.1788,  ...,  0.2576,  0.1425,  0.7211],\n",
       "                       ...,\n",
       "                       [-0.2704, -0.1854,  0.1605,  ..., -0.1369,  0.3936,  0.3523],\n",
       "                       [ 0.3148,  0.9669, -0.3738,  ..., -0.3689, -0.1984, -0.5335],\n",
       "                       [-0.0342, -0.2998,  1.0123,  ..., -0.0059,  0.1894,  0.6414]])),\n",
       "              ('fcs.fc3.bias',\n",
       "               tensor([-0.1736, -0.2731,  0.0842, -0.1424, -0.3252,  0.1048,  0.1080, -0.2028,\n",
       "                       -0.0707, -0.2191]))]),\n",
       " 'optimizer': {'state': {0: {'step': 12120,\n",
       "    'exp_avg': tensor([[[[-3.3392e-04, -1.0313e-03, -1.3269e-03, -5.9829e-04, -1.1411e-03],\n",
       "              [-3.8723e-04, -1.0483e-03, -8.2168e-04, -4.7594e-04, -1.1907e-03],\n",
       "              [-7.9356e-04, -8.2280e-04, -3.3665e-04, -4.5269e-04, -1.8679e-04],\n",
       "              [ 9.4550e-04, -1.3067e-04,  5.7715e-04,  1.5033e-04,  9.5135e-05],\n",
       "              [ 4.9250e-04, -4.5672e-05, -2.9178e-05,  4.6156e-04,  4.9366e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.0786e-04,  7.4085e-04,  9.4287e-04,  8.7558e-04,  9.8962e-04],\n",
       "              [ 2.6035e-04,  9.7134e-04,  1.3453e-03,  1.1136e-03,  1.1715e-03],\n",
       "              [-1.5148e-04,  3.2746e-04,  6.8182e-04,  6.5685e-04,  7.1603e-04],\n",
       "              [ 2.6450e-06,  1.6138e-04,  2.6954e-04,  2.4990e-04,  4.5961e-04],\n",
       "              [ 1.9857e-05,  1.5035e-06, -1.8037e-05,  8.8930e-05,  1.1054e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.0335e-03, -3.4427e-04, -2.3741e-04, -3.9575e-04, -7.0454e-04],\n",
       "              [-7.1313e-04, -2.3513e-04, -1.8564e-04, -4.6110e-04, -2.7708e-04],\n",
       "              [-6.2946e-04,  2.4959e-04,  2.4386e-04,  1.5963e-04,  4.8299e-04],\n",
       "              [-3.0427e-04,  2.3112e-04,  4.4244e-04,  6.6395e-04,  4.5533e-04],\n",
       "              [ 1.8121e-04,  9.9215e-05,  3.0375e-04,  2.1189e-04,  3.1662e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.1838e-04,  8.4581e-04,  1.8245e-03,  6.4919e-04, -4.5421e-04],\n",
       "              [-2.0982e-04,  3.0142e-04,  9.1103e-04,  5.2122e-04, -5.5854e-04],\n",
       "              [ 2.0399e-05,  2.6095e-04,  5.3241e-04,  4.1506e-04,  6.4368e-05],\n",
       "              [ 2.4175e-04, -1.4443e-04,  4.0075e-04,  1.2810e-03,  1.5047e-03],\n",
       "              [-4.0765e-05,  3.9305e-04,  1.5075e-03,  2.5990e-03,  2.5154e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.7866e-04,  4.7928e-04,  4.4644e-04, -9.0868e-04, -1.7215e-03],\n",
       "              [ 2.0637e-04,  4.6607e-05, -2.7272e-05, -1.1575e-03, -2.5216e-03],\n",
       "              [-3.0515e-04, -1.2721e-04, -3.4710e-04, -1.7469e-03, -3.0466e-03],\n",
       "              [-3.2954e-04, -4.8418e-04, -1.5131e-03, -3.2393e-03, -4.2143e-03],\n",
       "              [-1.1502e-03, -1.5630e-03, -3.3591e-03, -4.2071e-03, -4.2321e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.0995e-04,  1.7293e-03,  1.4084e-03,  7.9746e-04,  4.0009e-04],\n",
       "              [ 5.5754e-04,  1.2159e-03,  1.3619e-03,  4.5487e-04, -2.0550e-05],\n",
       "              [-5.0577e-05,  7.3677e-05, -6.4620e-05, -3.7307e-04, -3.9315e-04],\n",
       "              [ 1.6769e-04, -6.8503e-06, -2.3693e-05, -1.0546e-04, -1.0155e-04],\n",
       "              [ 1.2121e-03,  5.0787e-04,  6.6222e-05,  6.9893e-06,  3.4760e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.7381e-05, -1.9182e-04, -5.0097e-04, -4.0772e-04, -3.9061e-04],\n",
       "              [-2.9100e-06,  9.9374e-05, -2.1497e-05, -5.0242e-04, -3.6964e-04],\n",
       "              [ 1.9644e-04,  2.0603e-04,  1.5077e-04, -3.0584e-04, -3.8759e-05],\n",
       "              [ 6.8814e-05,  2.7509e-05, -4.2239e-06,  2.6478e-04,  9.3814e-04],\n",
       "              [ 2.0431e-04,  1.6579e-04,  2.3890e-04,  4.4310e-04,  7.3367e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.5249e-05,  2.0573e-04,  4.7643e-04,  6.5421e-04,  6.5132e-05],\n",
       "              [-1.7289e-05, -8.0044e-06,  3.0073e-04,  3.1748e-05, -8.7531e-04],\n",
       "              [-2.7480e-04, -5.9015e-05, -2.1453e-04, -8.0654e-04, -1.3070e-03],\n",
       "              [-3.5062e-04, -1.3229e-04, -3.2293e-04, -1.0176e-03, -1.0194e-03],\n",
       "              [-6.0788e-05,  9.0609e-05, -1.5741e-04, -7.7614e-04, -1.1520e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.9553e-05, -7.9067e-05,  4.7825e-05,  3.8150e-04,  5.2528e-05],\n",
       "              [-5.0706e-04, -2.8824e-05,  1.0631e-04, -3.4535e-04, -1.9184e-03],\n",
       "              [-1.1978e-03, -3.5575e-04,  6.1854e-05, -8.4485e-04, -2.0466e-03],\n",
       "              [-4.8952e-04,  3.7308e-06, -2.6904e-04, -1.4306e-03, -2.0221e-03],\n",
       "              [ 6.2698e-05,  1.9655e-04, -3.7694e-04, -1.3928e-03, -1.9409e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.7185e-03,  8.3095e-04,  1.8832e-04,  1.6241e-04,  1.4373e-04],\n",
       "              [ 1.5315e-03,  7.9719e-04,  2.3119e-04,  3.3658e-05,  4.6155e-05],\n",
       "              [ 1.5231e-03,  7.7704e-04,  1.2657e-04,  2.5302e-04,  4.9062e-04],\n",
       "              [ 1.0245e-03,  1.1972e-04, -8.1232e-04, -5.6629e-05, -4.0637e-05],\n",
       "              [ 9.6016e-04, -9.2556e-04, -1.9373e-03, -7.5291e-04,  1.1091e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-7.2275e-04, -3.4466e-04, -5.9460e-04, -5.0724e-04, -9.7009e-05],\n",
       "              [-6.4759e-04, -4.4191e-04, -3.0895e-04,  4.5245e-04,  1.0955e-04],\n",
       "              [-2.7439e-04, -6.1735e-04, -1.9157e-04, -4.9868e-04, -1.0763e-04],\n",
       "              [-2.9284e-05, -4.1751e-04, -8.8671e-04, -4.6133e-04, -3.0545e-04],\n",
       "              [-4.4837e-04, -4.5224e-04, -3.7066e-04, -5.4429e-04, -1.7590e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.8646e-05,  1.8903e-04, -1.9762e-05, -1.2576e-04, -1.1377e-04],\n",
       "              [-1.8629e-05,  2.8088e-05, -8.2245e-06, -9.3971e-05, -2.9437e-04],\n",
       "              [-3.1973e-04, -5.3940e-04, -5.5364e-04, -5.8724e-04, -6.9282e-04],\n",
       "              [-1.2625e-03, -1.2254e-03, -7.7962e-04, -1.1810e-03, -2.1250e-03],\n",
       "              [-7.2157e-04, -6.0501e-04, -6.5298e-04, -2.6271e-03, -2.3474e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.6516e-04, -3.9576e-04, -1.0082e-03, -1.2723e-03, -8.2681e-04],\n",
       "              [ 2.7890e-04, -3.2517e-04, -9.7126e-04, -9.9402e-04, -5.4053e-04],\n",
       "              [ 3.9388e-04, -1.3900e-04, -6.1616e-04, -5.4507e-04, -2.7308e-04],\n",
       "              [ 1.3290e-05, -2.9013e-04, -3.7387e-04, -2.2021e-04, -1.7109e-04],\n",
       "              [-1.2321e-04, -2.7316e-04, -3.9807e-04, -1.8776e-04,  3.4278e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.5982e-05, -4.5414e-04,  2.6329e-04,  6.1361e-04,  6.1317e-05],\n",
       "              [ 3.8227e-05, -1.9378e-04,  1.0238e-04,  1.9855e-04,  7.0511e-05],\n",
       "              [ 1.5241e-04,  1.7311e-06,  5.2748e-05,  1.5000e-04,  1.3849e-04],\n",
       "              [-9.4419e-05, -1.2528e-06,  1.7418e-04,  2.9076e-04,  5.6723e-04],\n",
       "              [ 1.0925e-05,  1.0586e-04,  3.2537e-04,  7.4876e-04,  1.0028e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-7.0287e-04, -3.8471e-04, -2.3575e-04,  4.5078e-04,  4.4842e-04],\n",
       "              [-4.6749e-04, -4.1278e-05, -1.4637e-05,  4.8603e-04,  4.9844e-04],\n",
       "              [-2.9167e-04,  2.8388e-04,  1.6533e-04,  1.1661e-04, -1.8202e-04],\n",
       "              [ 2.0679e-04,  8.5645e-04,  5.9366e-04,  3.1141e-05, -1.0897e-04],\n",
       "              [ 2.0845e-05,  2.9255e-04,  7.4635e-04,  3.0321e-04, -2.6061e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 6.5266e-04,  4.5289e-04,  9.4112e-06, -5.6429e-05, -2.9337e-04],\n",
       "              [ 1.3326e-03,  1.2040e-03,  9.1803e-04,  4.6355e-04, -4.5233e-04],\n",
       "              [ 8.7398e-04,  1.1121e-03,  5.5413e-04,  2.8017e-04, -6.9456e-05],\n",
       "              [-3.2377e-04, -1.1944e-03, -1.0398e-03, -4.6222e-04, -8.4533e-04],\n",
       "              [-4.3247e-04, -1.0094e-03, -5.0007e-04, -2.9043e-05, -1.6895e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-9.1167e-04, -8.2964e-04, -6.2640e-04, -9.0381e-04,  4.8941e-05],\n",
       "              [-5.6094e-04, -1.0574e-03, -3.1673e-04,  2.7416e-04,  9.8686e-04],\n",
       "              [-9.2305e-04, -4.5494e-04, -2.4259e-05,  6.0347e-04,  1.0690e-03],\n",
       "              [-3.5505e-04, -1.1599e-04, -5.9892e-04, -1.2557e-03, -1.6136e-03],\n",
       "              [-5.6913e-04, -1.3109e-03, -3.3957e-03, -3.9585e-03, -3.3144e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.5901e-04, -6.8174e-04,  2.1916e-04,  6.4098e-04,  2.8004e-04],\n",
       "              [-7.6795e-04, -6.3792e-04,  4.8093e-04,  4.6059e-04, -6.2871e-04],\n",
       "              [-6.5382e-04,  1.8801e-04,  8.4906e-04,  2.2674e-04, -7.5411e-04],\n",
       "              [-5.8213e-04,  1.0319e-04,  1.6639e-05, -2.9038e-04, -3.5696e-05],\n",
       "              [-5.4025e-04,  4.4697e-04,  1.4470e-04, -1.6326e-04, -9.1733e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.1756e-03,  1.0303e-03, -1.9320e-05, -4.2152e-04, -1.4644e-03],\n",
       "              [ 1.8144e-03,  6.8053e-04, -6.9842e-05, -6.3913e-04, -1.4898e-03],\n",
       "              [ 1.7262e-03,  4.9672e-04, -1.4160e-05, -8.4005e-04, -1.3837e-03],\n",
       "              [ 1.5836e-03,  6.5601e-04,  2.0505e-04, -7.6636e-04, -1.8384e-03],\n",
       "              [ 1.4765e-03,  1.0949e-03,  2.2729e-04, -1.4485e-03, -2.2471e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.1087e-04, -6.8001e-04, -7.0078e-04, -1.4074e-03, -2.3013e-03],\n",
       "              [-1.7462e-04, -3.1797e-04, -7.0049e-04, -2.0391e-03, -3.1088e-03],\n",
       "              [ 8.0422e-05,  2.6206e-05, -3.7703e-04, -1.6195e-03, -2.1089e-03],\n",
       "              [ 1.7624e-03,  1.9697e-03,  1.6357e-03,  7.4908e-04,  7.4680e-05],\n",
       "              [ 3.3995e-03,  3.6046e-03,  2.5487e-03,  1.2850e-03,  3.1317e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.2813e-04,  7.2973e-05,  2.0762e-04,  3.1138e-06,  1.7937e-04],\n",
       "              [ 2.2628e-05,  2.1195e-04,  5.4422e-04,  1.3801e-04,  4.6501e-04],\n",
       "              [ 1.1722e-04,  4.2354e-04,  2.4957e-04,  3.7397e-04,  8.1264e-04],\n",
       "              [ 3.1625e-04,  9.9914e-06, -3.7050e-04,  1.8283e-04,  5.1163e-04],\n",
       "              [ 3.8007e-04, -2.6528e-04, -3.8779e-04, -1.5680e-04,  4.1374e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 6.2578e-05, -2.7196e-04, -4.8489e-04,  5.5463e-05,  1.0172e-04],\n",
       "              [ 1.3709e-04, -2.7953e-05,  5.6541e-05,  3.5174e-04, -1.3101e-04],\n",
       "              [ 1.7613e-04, -8.1286e-06, -3.1342e-04, -4.1239e-04, -4.7850e-04],\n",
       "              [-2.1475e-04, -3.5412e-04, -3.6044e-04, -5.5543e-04, -2.8672e-04],\n",
       "              [-1.0730e-04, -8.6966e-05, -4.1764e-05, -2.1871e-04, -1.7350e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-7.1466e-04, -7.3740e-04, -3.3886e-04,  1.6038e-04,  5.5511e-05],\n",
       "              [ 3.9885e-04,  1.0723e-03,  1.8788e-04,  2.2652e-04, -1.6846e-04],\n",
       "              [-7.8516e-05,  7.0211e-04, -1.6940e-04, -4.5754e-04, -8.5315e-04],\n",
       "              [-1.3594e-03, -8.9681e-04, -1.2357e-03, -1.0166e-03, -8.1676e-04],\n",
       "              [-1.2584e-03, -6.1225e-04, -2.4382e-04, -3.4920e-04, -1.0564e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.0265e-04,  4.1194e-04,  2.2061e-04,  4.9325e-04,  8.3152e-04],\n",
       "              [ 2.9955e-05, -4.8028e-05,  3.8666e-05,  3.1132e-04,  5.4084e-04],\n",
       "              [ 9.3363e-06,  5.2323e-05,  1.1118e-04,  3.1399e-04,  2.3560e-04],\n",
       "              [-5.4668e-05,  9.5789e-05,  9.2372e-06,  5.0835e-05,  2.0818e-04],\n",
       "              [ 1.1191e-04,  3.3748e-05, -2.2803e-04, -3.3262e-06,  4.4764e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.8193e-04,  3.0939e-04,  2.6908e-04,  7.0405e-05, -1.6504e-04],\n",
       "              [-5.9196e-04,  4.2297e-04,  3.9874e-04,  7.3808e-04,  1.2842e-03],\n",
       "              [ 2.1974e-04,  1.9097e-03,  2.4563e-03,  3.3521e-03,  3.4673e-03],\n",
       "              [ 1.6968e-03,  3.0657e-03,  3.2598e-03,  3.4332e-03,  2.9578e-03],\n",
       "              [ 1.7902e-03,  1.2423e-03,  1.2986e-03,  7.6518e-04,  6.9389e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.2552e-04,  8.2846e-04,  1.0202e-03,  7.9836e-04,  8.0606e-04],\n",
       "              [-2.8195e-04,  7.8749e-04,  6.7614e-04,  8.7831e-04,  6.8733e-04],\n",
       "              [-2.8506e-04,  1.5485e-04,  1.5463e-04,  6.1041e-04,  1.2132e-03],\n",
       "              [-1.6116e-04,  1.2490e-05,  2.1979e-04,  5.9142e-04,  1.1736e-03],\n",
       "              [-2.4037e-04,  7.5284e-05,  7.5521e-05,  9.9331e-04,  8.8954e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.6109e-04,  4.3895e-04,  2.6819e-04,  3.4619e-04,  4.5741e-04],\n",
       "              [-6.2662e-04, -2.7802e-05,  2.8743e-05,  9.4150e-05,  6.1796e-04],\n",
       "              [-3.6216e-04,  5.4790e-05,  5.8107e-05,  2.1883e-04,  1.0454e-03],\n",
       "              [ 2.1565e-05,  4.6786e-05,  2.8757e-04,  1.0458e-03,  1.8472e-03],\n",
       "              [ 3.4851e-04,  1.6015e-04,  7.6040e-04,  1.0315e-03,  1.4963e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.4036e-06,  6.6282e-05,  6.0152e-04,  4.3362e-04,  1.0973e-04],\n",
       "              [ 5.2100e-04,  6.0289e-04,  7.0493e-04,  2.6086e-04, -1.8712e-04],\n",
       "              [ 6.7435e-04,  5.0636e-04,  3.6192e-04,  7.6771e-05,  1.6637e-04],\n",
       "              [ 2.9143e-04,  8.9047e-05,  3.4123e-04,  5.9089e-04,  1.8267e-03],\n",
       "              [ 1.3952e-05,  1.1020e-04,  5.9565e-04,  2.2519e-03,  3.0022e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.0870e-03,  1.0254e-03,  6.5425e-04,  3.0454e-04,  3.2954e-04],\n",
       "              [ 1.2891e-03,  1.2080e-03,  1.6712e-04,  4.1078e-04,  2.9107e-04],\n",
       "              [ 1.5061e-03,  1.0562e-03,  3.9743e-04,  7.5337e-04,  7.4053e-04],\n",
       "              [ 1.6547e-03,  1.0968e-03,  7.0668e-04,  4.8128e-04,  3.3811e-04],\n",
       "              [ 1.5832e-03,  6.7361e-04,  3.9502e-04,  2.7992e-04,  5.4798e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.0086e-04,  5.5024e-04,  1.0059e-03,  1.7174e-03,  1.5490e-03],\n",
       "              [ 1.8322e-03,  2.3597e-03,  2.4082e-03,  1.7931e-03,  1.3665e-03],\n",
       "              [ 1.2909e-03,  1.5052e-03,  8.9298e-04,  8.5108e-05,  4.9895e-04],\n",
       "              [ 4.6245e-04,  5.9696e-05,  6.8664e-05, -2.9582e-04,  5.8243e-04],\n",
       "              [ 3.0790e-04, -1.3739e-04,  1.8535e-04,  4.4767e-04,  1.1657e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-5.4004e-04, -6.4769e-04, -2.0492e-04, -8.5154e-05, -1.2046e-04],\n",
       "              [-4.1064e-04, -5.5905e-04, -2.2656e-04, -2.4663e-05, -5.0687e-07],\n",
       "              [-3.3122e-04, -6.8206e-04, -5.9576e-04, -2.5819e-04, -1.0727e-04],\n",
       "              [-6.4119e-04, -6.7649e-04, -8.6774e-04, -3.6529e-04, -2.1343e-04],\n",
       "              [-1.0874e-03, -1.0047e-03, -4.8245e-04, -7.2900e-05,  8.5049e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.1199e-04,  8.1269e-04,  8.0355e-04,  6.8888e-04,  1.0313e-03],\n",
       "              [ 2.9588e-04,  5.3026e-04,  8.2676e-04,  9.6744e-04,  1.0323e-03],\n",
       "              [-2.1640e-04,  2.9945e-04,  5.3405e-04,  7.1080e-04,  1.3593e-04],\n",
       "              [-8.7391e-05,  6.2650e-05,  3.7573e-04,  4.6036e-04, -1.3037e-07],\n",
       "              [-2.8631e-05,  9.3722e-05,  4.8991e-04,  5.5162e-04,  1.5609e-05]]]],\n",
       "           device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([[[[5.5864e-05, 7.1369e-05, 8.7524e-05, 1.0424e-04, 1.4051e-04],\n",
       "              [1.2442e-04, 1.3917e-04, 1.3475e-04, 1.5083e-04, 1.6413e-04],\n",
       "              [2.2235e-04, 2.1022e-04, 1.8240e-04, 1.7374e-04, 1.7046e-04],\n",
       "              [2.2377e-04, 2.2120e-04, 1.8648e-04, 1.8470e-04, 1.6075e-04],\n",
       "              [1.5145e-04, 1.6400e-04, 1.8564e-04, 2.0560e-04, 1.6569e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[1.0722e-04, 1.1892e-04, 1.2438e-04, 1.1818e-04, 1.2280e-04],\n",
       "              [1.9766e-04, 1.9881e-04, 1.4878e-04, 8.4441e-05, 6.6177e-05],\n",
       "              [1.2699e-04, 7.8392e-05, 8.4198e-05, 7.2575e-05, 7.7781e-05],\n",
       "              [1.5520e-05, 5.2504e-06, 2.0945e-05, 3.7806e-05, 5.0527e-05],\n",
       "              [2.7856e-06, 4.9951e-07, 2.0138e-06, 1.4957e-05, 7.6464e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[5.6239e-05, 4.7839e-05, 3.5377e-05, 1.8129e-05, 2.0477e-05],\n",
       "              [5.8370e-05, 4.1082e-05, 3.2905e-05, 3.7113e-05, 3.9913e-05],\n",
       "              [6.0659e-05, 4.0836e-05, 4.4802e-05, 4.5790e-05, 2.8406e-05],\n",
       "              [6.2058e-05, 5.1017e-05, 3.4255e-05, 3.0921e-05, 1.8701e-05],\n",
       "              [6.2906e-05, 5.6843e-05, 2.8361e-05, 2.0710e-05, 2.4265e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[6.6552e-05, 9.6246e-05, 1.2122e-04, 8.5461e-05, 2.7246e-05],\n",
       "              [7.4795e-05, 1.0632e-04, 1.0231e-04, 6.8943e-05, 2.8776e-05],\n",
       "              [5.2150e-05, 8.1471e-05, 9.0842e-05, 4.8091e-05, 2.5303e-05],\n",
       "              [2.3785e-05, 8.2956e-05, 9.8799e-05, 4.5778e-05, 4.2269e-05],\n",
       "              [1.1525e-05, 9.5431e-05, 1.2563e-04, 7.3585e-05, 7.3460e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[9.3920e-05, 5.2726e-05, 5.4584e-05, 1.0298e-04, 1.6620e-04],\n",
       "              [5.6587e-05, 2.2763e-05, 1.6886e-05, 7.7030e-05, 2.4982e-04],\n",
       "              [4.5814e-06, 1.7339e-06, 2.0578e-05, 1.1480e-04, 3.2961e-04],\n",
       "              [3.5502e-06, 1.4050e-05, 7.2958e-05, 2.1048e-04, 3.2453e-04],\n",
       "              [3.7557e-05, 8.4376e-05, 1.6771e-04, 3.0954e-04, 3.1563e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[2.5539e-04, 2.1338e-04, 1.7572e-04, 2.4806e-04, 3.5111e-04],\n",
       "              [1.7743e-04, 1.7746e-04, 1.6929e-04, 2.2266e-04, 2.4661e-04],\n",
       "              [5.6977e-05, 4.9471e-05, 5.5355e-05, 7.9329e-05, 1.0007e-04],\n",
       "              [2.4627e-05, 1.2208e-05, 2.0296e-05, 2.1019e-05, 3.7713e-05],\n",
       "              [8.4417e-05, 4.0667e-05, 1.2840e-05, 3.8586e-06, 1.8639e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[6.3342e-07, 2.0670e-05, 8.8650e-05, 1.2544e-04, 1.0028e-04],\n",
       "              [1.1739e-05, 6.2697e-05, 1.2208e-04, 9.7124e-05, 5.1279e-05],\n",
       "              [4.3241e-05, 9.3037e-05, 9.9115e-05, 4.3224e-05, 2.6019e-05],\n",
       "              [5.9498e-05, 8.5228e-05, 6.1039e-05, 2.9324e-05, 6.0381e-05],\n",
       "              [5.1576e-05, 5.2135e-05, 3.9158e-05, 6.6208e-05, 1.5549e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[5.8158e-06, 2.0244e-05, 2.8555e-05, 3.0088e-05, 4.7939e-05],\n",
       "              [1.6595e-05, 2.9192e-05, 3.0297e-05, 3.4750e-05, 5.7209e-05],\n",
       "              [2.9049e-05, 3.6265e-05, 1.7600e-05, 3.6337e-05, 5.5517e-05],\n",
       "              [3.8720e-05, 2.8261e-05, 1.0307e-05, 3.7099e-05, 4.9190e-05],\n",
       "              [3.4978e-05, 1.3218e-05, 9.1894e-06, 3.8099e-05, 4.1695e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[4.9396e-06, 3.0074e-06, 2.1482e-05, 1.1028e-04, 2.3993e-04],\n",
       "              [5.1990e-07, 3.4702e-08, 2.1216e-06, 7.0334e-05, 2.9831e-04],\n",
       "              [1.2021e-06, 2.2691e-07, 6.1497e-07, 6.5093e-05, 3.3397e-04],\n",
       "              [1.7015e-06, 4.1024e-07, 3.9713e-06, 1.0971e-04, 2.9075e-04],\n",
       "              [4.5748e-06, 4.6038e-06, 3.3043e-05, 1.5514e-04, 2.5656e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[1.5508e-04, 1.0304e-04, 1.1625e-05, 3.1346e-06, 5.9930e-06],\n",
       "              [2.2823e-04, 1.6780e-04, 2.5868e-05, 2.1611e-06, 7.8289e-06],\n",
       "              [2.9431e-04, 2.2567e-04, 7.6927e-05, 1.3589e-05, 1.4718e-05],\n",
       "              [2.9221e-04, 2.6563e-04, 1.8740e-04, 9.8186e-05, 1.2414e-04],\n",
       "              [2.9178e-04, 2.7239e-04, 2.6353e-04, 2.3697e-04, 2.5852e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[2.3482e-05, 3.3825e-05, 7.3038e-05, 9.1008e-05, 8.1539e-05],\n",
       "              [2.9444e-05, 4.9400e-05, 8.3701e-05, 7.3759e-05, 4.8898e-05],\n",
       "              [3.1759e-05, 6.6570e-05, 8.6741e-05, 6.0227e-05, 6.0406e-05],\n",
       "              [5.1355e-05, 9.3998e-05, 7.9296e-05, 5.3456e-05, 5.7069e-05],\n",
       "              [7.4450e-05, 9.4515e-05, 5.9017e-05, 3.1313e-05, 2.4430e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[7.1515e-06, 2.6841e-06, 5.6136e-07, 7.1423e-07, 8.8672e-06],\n",
       "              [1.6901e-06, 5.0242e-07, 3.5906e-07, 1.8585e-06, 2.6826e-05],\n",
       "              [2.6636e-05, 1.5908e-05, 1.5871e-05, 2.0824e-05, 5.0586e-05],\n",
       "              [3.5858e-05, 3.3487e-05, 2.4455e-05, 2.6254e-05, 1.0893e-04],\n",
       "              [2.0136e-05, 1.9847e-05, 1.8690e-05, 4.8494e-05, 1.4901e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[1.1879e-04, 2.1794e-04, 2.8387e-04, 2.0662e-04, 1.3178e-04],\n",
       "              [1.7441e-04, 3.1137e-04, 2.8527e-04, 1.2596e-04, 7.9260e-05],\n",
       "              [2.3902e-04, 3.2593e-04, 1.8247e-04, 4.0944e-05, 2.5042e-05],\n",
       "              [2.7796e-04, 2.7861e-04, 1.2417e-04, 1.7812e-05, 7.6437e-06],\n",
       "              [3.0026e-04, 2.7968e-04, 8.8806e-05, 7.5761e-06, 6.6095e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[1.1716e-05, 2.3172e-05, 3.0949e-05, 1.6684e-05, 1.5461e-06],\n",
       "              [1.7317e-05, 2.9143e-05, 2.0666e-05, 1.9770e-05, 8.4831e-06],\n",
       "              [2.9810e-05, 2.6670e-05, 2.3866e-05, 2.2224e-05, 1.5961e-05],\n",
       "              [2.4169e-05, 1.5672e-05, 1.5489e-05, 1.5969e-05, 1.0562e-05],\n",
       "              [8.0937e-06, 9.1746e-06, 2.0520e-05, 2.3497e-05, 1.6135e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[3.4440e-05, 3.8644e-05, 4.0011e-05, 4.6681e-05, 3.2905e-05],\n",
       "              [3.2283e-05, 2.7544e-05, 6.1595e-05, 8.2737e-05, 5.5473e-05],\n",
       "              [4.2595e-05, 3.8188e-05, 7.9159e-05, 6.9987e-05, 3.0587e-05],\n",
       "              [7.4881e-05, 7.5418e-05, 8.0186e-05, 2.2113e-05, 4.6260e-06],\n",
       "              [1.1299e-04, 1.0749e-04, 4.7748e-05, 7.1744e-06, 6.0131e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[9.9335e-05, 1.0415e-04, 1.0566e-04, 8.8370e-05, 1.1388e-04],\n",
       "              [1.5028e-04, 1.6982e-04, 1.8903e-04, 2.1190e-04, 2.3791e-04],\n",
       "              [1.9643e-04, 2.6205e-04, 2.7121e-04, 2.7087e-04, 2.8728e-04],\n",
       "              [1.4311e-04, 1.3661e-04, 1.3045e-04, 1.2588e-04, 1.7917e-04],\n",
       "              [8.6505e-05, 4.5194e-05, 2.4507e-05, 2.7460e-05, 8.6998e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[3.7751e-04, 2.4342e-04, 1.0225e-04, 6.3879e-05, 1.3260e-04],\n",
       "              [2.9531e-04, 9.6934e-05, 8.2406e-06, 3.9215e-05, 1.7620e-04],\n",
       "              [1.5995e-04, 1.5714e-05, 4.1052e-06, 1.1486e-04, 2.5070e-04],\n",
       "              [6.4491e-05, 1.8006e-06, 4.4924e-05, 2.7303e-04, 3.2061e-04],\n",
       "              [2.4823e-05, 3.0046e-05, 2.4524e-04, 4.2863e-04, 3.3304e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[1.1836e-05, 2.0784e-05, 5.6261e-05, 7.8848e-05, 7.9953e-05],\n",
       "              [3.4680e-05, 7.0495e-05, 8.6213e-05, 6.9856e-05, 6.9972e-05],\n",
       "              [5.2330e-05, 8.6135e-05, 7.5045e-05, 5.7293e-05, 3.2616e-05],\n",
       "              [3.8370e-05, 6.4848e-05, 7.2804e-05, 4.9388e-05, 1.0080e-05],\n",
       "              [4.2342e-05, 5.0895e-05, 5.9674e-05, 3.0865e-05, 8.6550e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[1.6145e-04, 6.9177e-05, 1.8456e-05, 1.2850e-05, 3.8012e-05],\n",
       "              [1.3699e-04, 4.6057e-05, 4.3968e-06, 4.7865e-06, 3.7175e-05],\n",
       "              [9.5157e-05, 1.6257e-05, 7.9520e-07, 8.4971e-06, 5.4151e-05],\n",
       "              [5.6331e-05, 1.2753e-05, 5.1164e-06, 1.6574e-05, 1.2815e-04],\n",
       "              [4.1195e-05, 1.6418e-05, 1.6341e-05, 7.0587e-05, 2.0105e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[7.4630e-05, 9.7801e-05, 1.1109e-04, 1.1943e-04, 1.0400e-04],\n",
       "              [3.0188e-05, 4.2969e-05, 7.3572e-05, 1.1058e-04, 1.2147e-04],\n",
       "              [3.6042e-05, 4.0427e-05, 4.8294e-05, 1.0145e-04, 1.2240e-04],\n",
       "              [8.0160e-05, 7.3350e-05, 8.0385e-05, 1.1300e-04, 1.1014e-04],\n",
       "              [1.3626e-04, 1.6682e-04, 1.4304e-04, 1.3211e-04, 1.0488e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[3.2747e-05, 4.8549e-05, 5.4682e-05, 4.0937e-05, 4.0208e-05],\n",
       "              [1.5400e-05, 3.2679e-05, 5.6162e-05, 4.9108e-05, 5.5175e-05],\n",
       "              [3.6845e-06, 2.8056e-05, 6.7723e-05, 8.3417e-05, 7.8045e-05],\n",
       "              [3.4905e-06, 3.4456e-05, 1.0087e-04, 1.2716e-04, 7.1170e-05],\n",
       "              [1.9164e-05, 7.1494e-05, 1.4157e-04, 1.1644e-04, 4.2808e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[1.5708e-05, 2.7531e-05, 3.4206e-05, 2.6375e-05, 3.0109e-05],\n",
       "              [1.9072e-05, 3.1951e-05, 2.9609e-05, 2.3424e-05, 4.4591e-05],\n",
       "              [2.4532e-05, 3.2064e-05, 1.7458e-05, 1.7091e-05, 3.8024e-05],\n",
       "              [2.1852e-05, 1.3750e-05, 8.3299e-06, 2.0766e-05, 3.0280e-05],\n",
       "              [1.1955e-05, 2.7090e-06, 5.4920e-06, 2.5047e-05, 2.8480e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[9.4844e-05, 6.1973e-05, 1.9706e-05, 3.6875e-06, 6.4567e-06],\n",
       "              [7.9987e-05, 2.4356e-05, 8.1999e-06, 1.7048e-05, 3.8251e-05],\n",
       "              [1.3763e-04, 1.0050e-04, 8.9768e-05, 9.4782e-05, 1.2361e-04],\n",
       "              [1.8745e-04, 1.2573e-04, 7.8727e-05, 6.4561e-05, 8.0950e-05],\n",
       "              [1.2768e-04, 5.7341e-05, 2.1601e-05, 2.2460e-05, 1.9874e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[3.8504e-05, 1.4256e-05, 9.4752e-06, 4.1148e-05, 6.3647e-05],\n",
       "              [4.3176e-06, 1.4742e-06, 1.9900e-05, 6.9696e-05, 7.7859e-05],\n",
       "              [2.0377e-06, 8.6728e-06, 6.7369e-05, 8.7697e-05, 5.5663e-05],\n",
       "              [1.0664e-05, 3.5034e-05, 1.0353e-04, 7.3544e-05, 2.6384e-05],\n",
       "              [5.1662e-05, 6.9064e-05, 7.8467e-05, 4.0684e-05, 1.8457e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[1.0222e-04, 5.1771e-05, 3.9002e-05, 1.4490e-04, 2.1255e-04],\n",
       "              [8.6748e-05, 2.0961e-05, 6.5659e-05, 2.4043e-04, 2.6784e-04],\n",
       "              [9.4275e-05, 5.8852e-05, 2.1020e-04, 3.5027e-04, 2.4950e-04],\n",
       "              [1.6807e-04, 2.1760e-04, 3.9051e-04, 3.2860e-04, 1.3841e-04],\n",
       "              [2.3762e-04, 3.7318e-04, 3.8806e-04, 1.7884e-04, 6.3779e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[1.6380e-04, 1.8978e-04, 1.7342e-04, 1.4334e-04, 8.9882e-05],\n",
       "              [1.5678e-04, 1.6386e-04, 1.6973e-04, 1.3534e-04, 7.8616e-05],\n",
       "              [7.0622e-05, 5.9623e-05, 1.1731e-04, 1.1518e-04, 7.6543e-05],\n",
       "              [4.1656e-05, 2.4719e-05, 6.0899e-05, 9.0455e-05, 6.6685e-05],\n",
       "              [6.6314e-05, 1.6426e-05, 4.5373e-05, 9.1066e-05, 7.9227e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[2.0219e-04, 1.5696e-04, 8.8348e-05, 9.2778e-05, 1.4568e-04],\n",
       "              [7.3993e-05, 1.6763e-05, 1.2717e-05, 2.1007e-05, 4.4161e-05],\n",
       "              [1.2034e-05, 8.3262e-07, 1.0524e-06, 8.1247e-06, 7.6756e-05],\n",
       "              [1.8042e-06, 1.8565e-06, 1.2903e-05, 8.4575e-05, 2.0383e-04],\n",
       "              [1.5333e-05, 4.2581e-05, 1.1041e-04, 2.4543e-04, 3.1814e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[1.5447e-05, 4.0737e-05, 1.0159e-04, 2.1617e-04, 2.5506e-04],\n",
       "              [3.1499e-05, 7.2330e-05, 1.2482e-04, 1.6402e-04, 1.6422e-04],\n",
       "              [3.3332e-05, 4.9060e-05, 5.0781e-05, 6.5051e-05, 8.6685e-05],\n",
       "              [2.7327e-05, 1.5599e-05, 1.2025e-05, 5.8001e-05, 1.1095e-04],\n",
       "              [1.5318e-05, 7.7108e-06, 2.1242e-05, 9.6075e-05, 1.3719e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[5.7512e-05, 5.4990e-05, 4.5638e-05, 3.1967e-05, 2.1776e-05],\n",
       "              [4.1178e-05, 3.9397e-05, 1.2476e-05, 8.0243e-06, 1.4356e-05],\n",
       "              [4.6292e-05, 2.8210e-05, 1.6998e-05, 2.6741e-05, 2.9847e-05],\n",
       "              [5.1891e-05, 3.3237e-05, 3.5780e-05, 4.1860e-05, 3.8038e-05],\n",
       "              [5.0571e-05, 2.8129e-05, 3.8932e-05, 4.1551e-05, 3.0007e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[6.4103e-05, 9.5165e-05, 1.4230e-04, 1.6582e-04, 1.3323e-04],\n",
       "              [1.2054e-04, 1.6895e-04, 1.6333e-04, 1.3832e-04, 8.4548e-05],\n",
       "              [1.8751e-04, 1.4532e-04, 5.8176e-05, 6.3408e-05, 7.2558e-05],\n",
       "              [1.1351e-04, 4.5550e-05, 1.3215e-05, 4.9151e-05, 9.7802e-05],\n",
       "              [7.0246e-05, 3.4359e-05, 7.0047e-05, 1.7062e-04, 1.8169e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[6.4608e-05, 4.8143e-05, 3.3976e-05, 3.4981e-05, 5.8339e-05],\n",
       "              [3.1351e-05, 2.5494e-05, 2.3452e-05, 1.9301e-05, 3.7139e-05],\n",
       "              [1.2545e-05, 2.3761e-05, 4.0944e-05, 2.2446e-05, 2.7077e-05],\n",
       "              [3.1300e-05, 4.6883e-05, 5.8673e-05, 4.3815e-05, 4.8101e-05],\n",
       "              [8.8080e-05, 7.6715e-05, 6.6623e-05, 5.9453e-05, 4.3014e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[7.9039e-05, 4.8181e-05, 3.1213e-05, 2.8798e-05, 2.8053e-05],\n",
       "              [4.7135e-05, 2.7667e-05, 3.3387e-05, 2.5228e-05, 1.8144e-05],\n",
       "              [1.8462e-05, 1.7825e-05, 1.4977e-05, 3.9482e-06, 5.3847e-07],\n",
       "              [1.1561e-05, 7.2305e-06, 2.3103e-06, 1.1116e-06, 1.9295e-08],\n",
       "              [6.3900e-06, 3.7425e-06, 3.8293e-06, 2.3867e-06, 5.3127e-07]]]],\n",
       "           device='cuda:5')},\n",
       "   1: {'step': 12120,\n",
       "    'exp_avg': tensor([ 0.0008,  0.0015, -0.0005,  0.0020, -0.0038,  0.0015,  0.0004, -0.0011,\n",
       "            -0.0018,  0.0023, -0.0006, -0.0024, -0.0006,  0.0006, -0.0005,  0.0004,\n",
       "            -0.0042,  0.0003,  0.0001,  0.0019,  0.0002, -0.0004, -0.0036,  0.0010,\n",
       "             0.0015,  0.0012,  0.0006,  0.0022,  0.0015,  0.0015, -0.0007,  0.0004],\n",
       "           device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([3.6814e-04, 5.2423e-04, 1.1494e-04, 2.3593e-04, 5.7230e-04, 2.1980e-03,\n",
       "            2.9655e-04, 9.2675e-05, 5.1422e-04, 7.3148e-04, 1.7442e-04, 2.3828e-04,\n",
       "            5.3062e-04, 7.1346e-05, 1.8403e-04, 4.8498e-04, 1.2552e-03, 1.5807e-04,\n",
       "            4.0381e-04, 2.9125e-04, 1.8327e-04, 7.8577e-05, 4.9291e-04, 1.6909e-04,\n",
       "            6.2056e-04, 4.0520e-04, 8.3247e-04, 3.8430e-04, 1.2343e-04, 4.8745e-04,\n",
       "            1.8661e-04, 1.2321e-04], device='cuda:5')},\n",
       "   2: {'step': 12120,\n",
       "    'exp_avg': tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.9557e-05,  9.8524e-05,  1.0085e-04, -7.1355e-05,  6.2192e-05],\n",
       "              [-3.8873e-05, -2.7254e-04, -5.1616e-04, -4.5135e-04, -4.6251e-04],\n",
       "              [-5.3236e-04, -7.3045e-04, -7.2948e-04, -3.0050e-04, -1.1038e-04],\n",
       "              [-2.0077e-04, -3.4936e-04, -1.8861e-04,  4.5453e-05, -2.6626e-05],\n",
       "              [ 7.3251e-05, -3.7923e-05, -1.6045e-04, -1.9684e-04, -1.0479e-04]],\n",
       "    \n",
       "             [[ 8.4312e-06, -1.1250e-05, -2.5172e-06,  1.9546e-05,  2.8127e-05],\n",
       "              [ 2.4338e-05,  4.0261e-05,  6.3342e-05,  1.6004e-05, -1.0430e-04],\n",
       "              [-4.3887e-04, -3.1326e-04,  4.1097e-06,  1.6275e-06,  3.1781e-06],\n",
       "              [-1.7850e-04, -2.8081e-04, -2.8651e-04, -2.1140e-05,  1.8790e-05],\n",
       "              [-7.4122e-05, -1.0409e-04, -8.2320e-07,  2.6766e-05, -6.4617e-06]],\n",
       "    \n",
       "             [[-1.8928e-05,  1.1878e-05,  1.0693e-05,  3.8299e-05, -2.0239e-05],\n",
       "              [-3.9380e-05, -7.7352e-08,  1.2998e-06, -1.0623e-04, -1.8008e-05],\n",
       "              [-4.0012e-05, -9.9988e-05, -6.3380e-05, -4.3739e-05, -1.3399e-05],\n",
       "              [-3.7238e-05, -2.4674e-05,  8.3751e-07, -3.0119e-05, -1.5935e-04],\n",
       "              [-1.7631e-07,  1.0053e-05, -9.1212e-06, -9.3104e-05, -2.6799e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-8.2320e-06, -4.5227e-05, -1.9712e-04, -2.4652e-04,  7.4474e-05],\n",
       "              [-1.8811e-05, -2.8179e-05,  7.1468e-06,  1.4655e-05, -2.5449e-04],\n",
       "              [-1.1878e-04, -8.6195e-05, -2.4910e-04, -2.2339e-04, -4.6100e-05],\n",
       "              [-6.8780e-05, -2.5296e-04, -2.9531e-04, -2.6862e-07,  3.8480e-05],\n",
       "              [-1.4382e-04, -1.3764e-05,  6.3063e-05,  4.9221e-05, -7.1310e-05]],\n",
       "    \n",
       "             [[-3.1418e-05, -1.0298e-04,  3.4522e-06, -8.7262e-05, -1.7834e-04],\n",
       "              [-1.8273e-04, -6.9290e-05, -7.3791e-05, -1.5992e-04, -2.0153e-05],\n",
       "              [ 3.7673e-06,  3.7918e-05, -1.5165e-06,  1.1269e-05, -1.4853e-05],\n",
       "              [ 1.2672e-05,  6.8196e-05, -7.9425e-06, -2.2474e-05, -1.2722e-04],\n",
       "              [-2.4030e-04, -2.3626e-04, -3.7196e-05, -1.4972e-04, -7.2010e-05]],\n",
       "    \n",
       "             [[-9.1577e-07, -2.6525e-05,  2.2335e-05,  7.5526e-06, -1.1692e-05],\n",
       "              [ 1.0277e-06,  1.8335e-06,  2.0198e-06,  1.1577e-06,  6.2715e-06],\n",
       "              [-1.6599e-04,  9.3054e-07, -2.5350e-05,  4.0071e-07, -1.2789e-04],\n",
       "              [-2.1418e-04, -4.4947e-05, -7.1017e-06, -3.1861e-05, -4.4060e-06],\n",
       "              [-9.3634e-06, -3.0800e-05, -1.4157e-05,  6.9618e-06,  1.8061e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.3573e-05,  1.2226e-04,  1.8405e-05,  8.9505e-05,  1.0996e-04],\n",
       "              [ 1.4100e-04,  7.4566e-05, -4.4220e-05, -8.4633e-05, -7.1462e-05],\n",
       "              [ 1.9688e-04,  1.0383e-05, -1.0201e-05, -1.3401e-04, -1.6051e-04],\n",
       "              [ 7.9250e-05,  1.0203e-04,  4.7095e-05,  2.1098e-05,  7.0875e-05],\n",
       "              [ 8.1491e-05, -1.4003e-05,  6.0035e-05,  2.4956e-04,  2.8305e-04]],\n",
       "    \n",
       "             [[-1.4441e-05,  3.0690e-07,  4.4365e-06,  5.2075e-06,  2.0790e-04],\n",
       "              [ 2.6953e-06,  9.1498e-08, -8.9234e-06,  3.5552e-05, -3.5943e-05],\n",
       "              [-7.5404e-05, -4.4861e-05, -1.8739e-04, -9.7758e-05, -5.9096e-05],\n",
       "              [-1.0366e-04,  5.3158e-05, -7.3968e-06, -4.9772e-05, -6.2462e-05],\n",
       "              [ 5.0809e-05, -1.0540e-04,  2.8838e-05,  3.5763e-05,  1.0763e-04]],\n",
       "    \n",
       "             [[ 1.6643e-05,  2.1973e-05,  6.4713e-05,  7.1014e-05, -4.0085e-06],\n",
       "              [-1.4802e-05,  5.2401e-05,  8.7051e-05,  1.2564e-05, -1.2647e-05],\n",
       "              [-2.5522e-06,  8.6866e-05,  1.8381e-06, -9.4006e-06, -3.1023e-05],\n",
       "              [ 2.7076e-06, -2.3844e-07,  5.5285e-05,  1.4348e-06,  3.2785e-05],\n",
       "              [-2.9100e-06,  2.6018e-05,  2.1527e-05,  2.8266e-05,  1.0138e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.1043e-05,  5.0703e-06,  8.3536e-08,  8.9384e-05,  1.0825e-04],\n",
       "              [ 3.7187e-05, -5.5709e-05,  3.9310e-06, -6.8239e-05, -1.7644e-05],\n",
       "              [ 1.0791e-04, -4.4873e-05,  5.4710e-05,  9.5329e-06,  5.3257e-05],\n",
       "              [-2.2405e-05,  4.2939e-05,  1.4472e-06, -2.9005e-05, -4.1702e-05],\n",
       "              [ 1.0165e-04,  6.3073e-05, -3.6629e-06,  3.4514e-05,  1.7225e-04]],\n",
       "    \n",
       "             [[-3.0238e-06,  1.7775e-05,  1.6113e-05, -1.8392e-05, -7.3075e-06],\n",
       "              [-8.1504e-06,  3.5838e-05,  3.3009e-05, -1.8952e-05, -2.8807e-05],\n",
       "              [-2.2144e-09,  3.0123e-05, -1.5516e-05,  9.1064e-06,  7.9124e-05],\n",
       "              [ 1.3420e-05, -2.6586e-05,  4.7394e-06, -8.1456e-06, -4.0130e-07],\n",
       "              [ 4.6725e-05,  3.8760e-05, -2.1051e-05,  6.4725e-06,  1.8609e-05]],\n",
       "    \n",
       "             [[ 1.7918e-06,  2.4100e-07,  1.6643e-05,  1.6383e-05,  8.9072e-05],\n",
       "              [-8.9125e-06,  1.3024e-06,  2.0293e-07,  1.9468e-05,  4.8103e-05],\n",
       "              [-1.3737e-05, -2.3724e-05,  8.5156e-06,  1.2389e-05, -7.2953e-06],\n",
       "              [ 4.3694e-05, -2.7926e-05,  2.8464e-05, -4.3674e-05, -1.1554e-04],\n",
       "              [ 4.7240e-06,  5.7957e-06,  6.7628e-05,  7.5520e-05,  7.1172e-06]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-7.8429e-05,  1.5605e-07,  4.3667e-07,  2.8672e-13, -1.2091e-06],\n",
       "              [ 2.1501e-07, -8.3439e-13,  3.7674e-13, -2.0903e-09, -5.3459e-07],\n",
       "              [-1.8235e-05, -1.0668e-12,  7.1473e-12,  7.7253e-12, -2.6515e-08],\n",
       "              [-1.1486e-05, -2.0625e-07,  4.2370e-13, -3.9811e-12, -9.4845e-09],\n",
       "              [-9.0093e-06, -4.0271e-06,  7.1756e-11, -1.3559e-10,  2.0271e-05]],\n",
       "    \n",
       "             [[-1.5963e-04, -8.3060e-05,  1.5988e-06,  8.3119e-09, -1.6779e-07],\n",
       "              [ 1.4879e-06, -1.2230e-12,  5.5382e-12,  2.4275e-08, -1.2353e-06],\n",
       "              [-1.0729e-12, -1.9716e-12,  3.1266e-12,  4.5819e-08, -2.0816e-06],\n",
       "              [-1.2102e-07,  2.2956e-12, -1.0374e-11,  8.9487e-11, -5.2924e-08],\n",
       "              [-1.0584e-05, -4.6750e-06,  9.2715e-11, -9.0004e-12,  7.4354e-09]],\n",
       "    \n",
       "             [[ 1.0832e-07,  4.5992e-07, -3.2109e-13,  1.0087e-12,  2.9717e-11],\n",
       "              [-1.5218e-10,  1.4282e-12,  7.8045e-13, -1.0123e-12,  5.7351e-09],\n",
       "              [-7.0789e-06,  1.4026e-12, -2.8964e-13, -2.5125e-10, -1.0067e-08],\n",
       "              [-6.9086e-06, -3.5294e-07, -8.0482e-14, -2.0126e-12,  2.5776e-13],\n",
       "              [-2.1805e-06, -1.0013e-07, -5.6302e-13, -1.7767e-13,  1.6768e-11]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-9.9341e-05, -6.1361e-05,  7.0659e-07, -1.6313e-12, -2.2709e-08],\n",
       "              [-1.2255e-09,  2.6968e-13, -2.6981e-13, -5.9657e-12,  8.9278e-08],\n",
       "              [ 3.4681e-12, -7.5404e-12, -1.2337e-11, -7.7420e-12, -1.5109e-08],\n",
       "              [-1.8234e-07, -1.9749e-10,  1.1320e-11,  7.8288e-13, -8.8132e-12],\n",
       "              [-6.3710e-06, -4.8650e-06,  3.8704e-13,  1.3993e-09,  4.9186e-09]],\n",
       "    \n",
       "             [[ 8.0123e-08,  3.1197e-12,  1.5436e-12, -1.1598e-14,  1.2607e-09],\n",
       "              [-3.2720e-05, -1.4473e-12, -1.0303e-12,  2.6074e-09, -2.8873e-08],\n",
       "              [-3.2949e-06,  5.5026e-07, -4.0151e-12, -8.4298e-09, -2.2453e-07],\n",
       "              [-2.1142e-06, -2.7268e-06,  2.9683e-10, -1.1931e-13,  1.7672e-12],\n",
       "              [ 3.2189e-08,  5.2901e-08, -2.0519e-08, -3.0338e-12, -1.3026e-09]],\n",
       "    \n",
       "             [[-2.5242e-05, -3.7323e-05, -4.1675e-05, -1.6271e-05, -5.7126e-06],\n",
       "              [-3.6453e-05, -4.0215e-05,  6.0263e-07,  1.5974e-11, -1.5151e-08],\n",
       "              [-5.9439e-07, -4.9854e-12, -2.8760e-12, -2.2037e-09, -9.6977e-09],\n",
       "              [ 3.9750e-08,  2.6532e-13,  2.4462e-12, -2.3787e-12, -6.0204e-13],\n",
       "              [-1.5606e-05, -1.2948e-11,  3.1306e-11,  7.2088e-12,  1.8782e-12]]],\n",
       "    \n",
       "    \n",
       "            [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "    \n",
       "             [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "              [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.8657e-05,  8.6699e-05,  1.6904e-06, -3.0854e-05, -5.8713e-05],\n",
       "              [ 6.7076e-06, -1.1460e-06, -5.2298e-05, -1.2418e-05, -7.6475e-06],\n",
       "              [ 5.5424e-05,  4.6139e-06,  4.6668e-06,  4.7925e-05,  2.8689e-05],\n",
       "              [ 6.2465e-05,  4.0048e-05,  3.2803e-05,  6.2765e-05, -1.3705e-04],\n",
       "              [ 1.5155e-05, -1.7558e-05, -1.7593e-05, -1.5140e-04, -4.4069e-04]],\n",
       "    \n",
       "             [[ 1.0926e-04, -1.1908e-05,  4.3421e-05,  3.9150e-05,  2.1953e-05],\n",
       "              [-1.9160e-05, -8.0466e-05, -8.1143e-05, -5.1077e-05, -1.8389e-05],\n",
       "              [-4.6210e-05, -9.2329e-06,  3.9977e-06,  6.5836e-06, -1.0921e-06],\n",
       "              [-3.2291e-06,  2.1763e-05,  5.5112e-05,  9.4385e-07,  2.8105e-06],\n",
       "              [ 3.2526e-05,  1.8591e-05, -1.4648e-05, -7.0640e-06,  2.4079e-05]],\n",
       "    \n",
       "             [[ 1.5955e-06, -1.9707e-06, -1.7431e-05, -1.5369e-05,  1.1711e-07],\n",
       "              [ 1.4472e-06,  2.8580e-06, -2.2035e-05,  1.5557e-06, -2.0705e-08],\n",
       "              [ 8.6256e-06,  1.7877e-06, -1.8359e-07,  1.0391e-06,  9.3096e-07],\n",
       "              [ 4.6220e-05,  1.0853e-05,  1.3584e-06,  1.9874e-07,  8.1384e-06],\n",
       "              [ 1.7056e-05, -3.8179e-06,  1.4741e-06, -1.8023e-05, -5.3571e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.4333e-05, -1.5745e-05, -2.4853e-07, -8.6070e-06, -3.5319e-05],\n",
       "              [-1.0713e-04, -8.5425e-07, -3.8450e-05, -6.7210e-05,  2.3036e-05],\n",
       "              [ 2.0036e-05,  4.1306e-05,  7.3213e-06,  1.5673e-06, -4.0727e-05],\n",
       "              [ 5.9262e-05,  9.6358e-05,  3.3244e-05, -1.9409e-05, -5.7420e-05],\n",
       "              [ 8.0123e-05, -1.7977e-05, -5.9590e-05, -4.6013e-05, -3.5612e-05]],\n",
       "    \n",
       "             [[-1.7491e-07,  6.2433e-07,  3.0367e-05,  2.3184e-06, -1.1736e-06],\n",
       "              [-8.1690e-06,  2.2900e-07,  2.5704e-05,  4.8817e-06,  6.2324e-06],\n",
       "              [-6.3603e-06,  2.1806e-05,  1.8901e-05,  1.5003e-07,  1.7387e-06],\n",
       "              [-1.3141e-05, -1.0252e-06, -6.6015e-08, -8.4573e-06, -3.2606e-05],\n",
       "              [-4.2250e-06, -7.6905e-06,  2.0956e-06, -6.9712e-05, -2.3807e-05]],\n",
       "    \n",
       "             [[ 7.2258e-06,  3.4822e-05, -4.1855e-05, -2.4222e-05, -1.6754e-06],\n",
       "              [ 1.1988e-05, -8.6735e-05, -5.5066e-05, -8.0739e-06,  7.9539e-06],\n",
       "              [-4.7483e-05, -3.7880e-05,  7.0411e-06, -1.6064e-06, -1.8403e-08],\n",
       "              [-3.6253e-05,  4.3022e-06,  3.3015e-05,  3.1884e-06,  6.2440e-09],\n",
       "              [-3.9936e-06,  3.1043e-05,  1.0349e-05, -1.8054e-06, -1.9960e-06]]]],\n",
       "           device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
       "    \n",
       "    \n",
       "            [[[2.9889e-06, 3.8836e-06, 5.9472e-06, 9.0843e-06, 1.0554e-05],\n",
       "              [2.0904e-06, 2.6481e-06, 9.1016e-06, 2.0483e-05, 2.0146e-05],\n",
       "              [5.0141e-06, 9.8884e-06, 1.7387e-05, 1.9401e-05, 1.0321e-05],\n",
       "              [5.7848e-06, 7.2202e-06, 8.5883e-06, 8.5014e-06, 4.4753e-06],\n",
       "              [3.5887e-06, 8.3062e-06, 1.4363e-05, 1.1758e-05, 4.5360e-06]],\n",
       "    \n",
       "             [[1.1641e-06, 2.1104e-06, 1.9103e-06, 8.9702e-07, 2.8071e-07],\n",
       "              [1.3750e-06, 1.6554e-06, 2.7575e-06, 1.5260e-06, 3.6095e-07],\n",
       "              [2.8389e-06, 3.2685e-06, 4.2995e-06, 1.8097e-06, 4.7145e-07],\n",
       "              [2.5756e-06, 6.2875e-06, 3.2829e-06, 2.8823e-07, 4.5045e-07],\n",
       "              [4.6252e-06, 1.4514e-06, 4.4911e-07, 1.2697e-06, 2.5508e-06]],\n",
       "    \n",
       "             [[3.3008e-07, 3.3306e-07, 4.4654e-07, 5.3820e-07, 7.6782e-07],\n",
       "              [1.4081e-07, 2.0580e-07, 6.6764e-07, 9.7403e-07, 1.0769e-06],\n",
       "              [5.8587e-07, 9.4915e-07, 7.1512e-07, 5.7172e-07, 1.5372e-06],\n",
       "              [5.6431e-07, 2.7692e-07, 1.1498e-07, 6.1946e-07, 1.0851e-06],\n",
       "              [1.2406e-07, 2.0406e-07, 5.6619e-07, 6.8389e-07, 9.5611e-07]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[7.6122e-07, 1.3264e-06, 2.8320e-06, 3.1412e-06, 1.7201e-06],\n",
       "              [1.2235e-06, 1.2030e-06, 9.5940e-07, 2.5024e-06, 2.2363e-06],\n",
       "              [7.1512e-07, 1.7471e-06, 5.8663e-06, 5.4636e-06, 1.1667e-06],\n",
       "              [2.3582e-06, 5.7185e-06, 4.9934e-06, 1.0843e-06, 1.2849e-06],\n",
       "              [2.0620e-06, 1.9903e-06, 9.5592e-07, 2.9722e-06, 3.2283e-06]],\n",
       "    \n",
       "             [[3.4220e-07, 2.0517e-07, 3.5770e-07, 2.1434e-06, 2.7986e-06],\n",
       "              [5.0206e-07, 9.4707e-07, 1.1308e-06, 1.5933e-06, 1.1377e-06],\n",
       "              [5.5500e-07, 6.8998e-07, 4.3318e-07, 3.1115e-07, 8.5820e-07],\n",
       "              [4.1047e-07, 5.9630e-07, 1.0146e-06, 1.1823e-06, 1.3089e-06],\n",
       "              [5.1246e-07, 5.7829e-07, 6.7416e-07, 6.7875e-07, 5.0865e-07]],\n",
       "    \n",
       "             [[1.6226e-07, 1.7779e-07, 1.5101e-07, 5.4024e-08, 5.5933e-08],\n",
       "              [1.0403e-07, 2.5814e-07, 1.1607e-07, 3.7222e-08, 3.6520e-08],\n",
       "              [2.0424e-07, 2.2693e-07, 2.4478e-07, 5.2034e-08, 8.5387e-08],\n",
       "              [4.8184e-07, 4.6657e-07, 1.2554e-07, 7.7183e-08, 1.6120e-07],\n",
       "              [2.0541e-07, 1.2852e-07, 1.0270e-07, 1.4993e-07, 2.5442e-07]]],\n",
       "    \n",
       "    \n",
       "            [[[1.0156e-05, 1.5348e-05, 1.7571e-05, 1.5131e-05, 1.3340e-05],\n",
       "              [1.3626e-05, 2.3163e-05, 2.2446e-05, 1.6119e-05, 1.0710e-05],\n",
       "              [1.1351e-05, 1.1243e-05, 8.1246e-06, 9.9794e-06, 1.4170e-05],\n",
       "              [7.9321e-06, 5.0706e-06, 3.4928e-06, 6.7803e-06, 1.2788e-05],\n",
       "              [6.9085e-06, 3.3553e-06, 3.5780e-06, 4.9275e-06, 8.0769e-06]],\n",
       "    \n",
       "             [[1.2071e-06, 1.3167e-07, 1.0115e-07, 1.0835e-06, 3.5537e-06],\n",
       "              [1.9100e-06, 2.2204e-06, 1.8784e-06, 3.1658e-06, 1.6333e-06],\n",
       "              [2.0577e-06, 3.9811e-06, 5.6921e-06, 5.7784e-06, 4.6326e-06],\n",
       "              [3.2800e-06, 5.0371e-06, 5.7864e-06, 7.6976e-06, 5.9592e-06],\n",
       "              [3.8673e-06, 7.9466e-06, 5.3773e-06, 5.4255e-06, 4.6129e-06]],\n",
       "    \n",
       "             [[3.6262e-07, 4.4424e-07, 1.3139e-06, 1.4207e-06, 1.1989e-06],\n",
       "              [6.3985e-07, 8.5226e-07, 1.3105e-06, 1.0422e-06, 9.5057e-07],\n",
       "              [3.6336e-07, 6.5440e-07, 1.0666e-06, 1.2691e-06, 1.5690e-06],\n",
       "              [3.0811e-07, 4.3754e-07, 1.0675e-06, 1.0911e-06, 1.3783e-06],\n",
       "              [2.2327e-07, 3.7058e-07, 6.0037e-07, 8.2389e-07, 9.3403e-07]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[2.2656e-06, 1.8245e-06, 1.1397e-06, 3.5635e-06, 6.2385e-06],\n",
       "              [1.7694e-06, 9.8141e-07, 3.2703e-06, 4.4797e-06, 1.8601e-06],\n",
       "              [2.6241e-06, 1.5747e-06, 2.1687e-06, 1.3373e-06, 1.2751e-06],\n",
       "              [1.7360e-06, 1.7476e-06, 2.3903e-06, 2.4843e-06, 3.0250e-06],\n",
       "              [2.2838e-06, 2.2601e-06, 1.7940e-06, 1.7757e-06, 2.9038e-06]],\n",
       "    \n",
       "             [[8.2767e-07, 1.4640e-06, 2.1018e-06, 1.4717e-06, 1.0720e-06],\n",
       "              [3.2292e-07, 9.8816e-07, 6.7060e-07, 9.3754e-07, 2.4709e-06],\n",
       "              [6.1238e-07, 5.0575e-07, 6.0189e-07, 1.3428e-06, 1.6082e-06],\n",
       "              [1.0128e-06, 7.5405e-07, 8.9774e-07, 1.6636e-06, 1.0810e-06],\n",
       "              [7.7544e-07, 1.0211e-06, 1.5411e-06, 1.5532e-06, 1.3553e-06]],\n",
       "    \n",
       "             [[2.9159e-08, 1.5922e-08, 2.0918e-08, 1.5213e-07, 4.7895e-07],\n",
       "              [1.8916e-08, 1.7512e-08, 2.3668e-08, 1.9611e-07, 5.2773e-07],\n",
       "              [1.3917e-07, 3.3007e-07, 3.4439e-07, 6.1736e-07, 4.0755e-07],\n",
       "              [1.2811e-07, 1.9677e-07, 7.0361e-07, 1.0894e-06, 9.4508e-07],\n",
       "              [2.9392e-07, 5.8516e-07, 8.1024e-07, 7.5118e-07, 6.9175e-07]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[1.8914e-07, 3.7850e-08, 5.9256e-09, 1.5607e-09, 6.1860e-08],\n",
       "              [6.3126e-09, 7.8425e-10, 3.0880e-10, 8.5800e-10, 1.3559e-07],\n",
       "              [9.2101e-08, 6.2800e-10, 1.9001e-10, 3.0174e-09, 8.6202e-08],\n",
       "              [9.7226e-07, 6.8035e-08, 2.4084e-10, 1.6879e-10, 5.2048e-08],\n",
       "              [5.8635e-07, 3.2932e-07, 2.6071e-08, 2.1119e-09, 3.0334e-07]],\n",
       "    \n",
       "             [[3.5394e-07, 5.0747e-07, 3.4954e-07, 2.4681e-08, 6.7797e-08],\n",
       "              [8.1999e-08, 1.0824e-08, 5.7420e-09, 2.9213e-08, 1.5084e-07],\n",
       "              [9.8062e-10, 2.3762e-09, 2.2038e-09, 2.3829e-07, 4.0890e-07],\n",
       "              [1.3897e-08, 3.0182e-10, 3.3300e-11, 2.8575e-08, 1.4750e-07],\n",
       "              [3.3923e-07, 1.0273e-08, 1.3898e-09, 2.9037e-10, 6.4258e-09]],\n",
       "    \n",
       "             [[7.9516e-08, 1.5902e-08, 1.0970e-09, 9.3751e-10, 2.2075e-09],\n",
       "              [1.6759e-08, 1.1728e-09, 7.7481e-10, 3.7860e-10, 4.7211e-08],\n",
       "              [2.5133e-08, 8.8849e-10, 2.9242e-10, 1.5935e-09, 2.5835e-08],\n",
       "              [6.7172e-08, 5.2993e-09, 1.5982e-10, 1.2853e-10, 1.1470e-10],\n",
       "              [6.2735e-08, 4.8389e-08, 4.9531e-09, 8.9824e-11, 4.5186e-10]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[1.8620e-07, 1.0165e-07, 1.3195e-08, 8.9812e-10, 9.4827e-08],\n",
       "              [2.5166e-08, 9.7569e-11, 7.4873e-11, 5.0272e-11, 2.4181e-08],\n",
       "              [1.6239e-09, 8.9553e-11, 7.9307e-11, 5.6201e-11, 1.1725e-07],\n",
       "              [3.4779e-08, 1.6925e-09, 4.4282e-11, 8.0742e-11, 2.8749e-09],\n",
       "              [2.9301e-08, 1.2747e-08, 6.1315e-09, 1.5745e-08, 1.8431e-08]],\n",
       "    \n",
       "             [[1.1361e-08, 3.4619e-09, 1.3806e-09, 1.0449e-09, 4.0300e-09],\n",
       "              [6.9354e-08, 5.0794e-10, 3.0479e-10, 6.8635e-09, 1.5884e-08],\n",
       "              [1.9108e-07, 3.6040e-08, 7.0491e-11, 1.3744e-08, 3.0722e-08],\n",
       "              [1.4624e-07, 9.2945e-08, 8.2180e-09, 3.3831e-10, 2.0669e-09],\n",
       "              [4.0561e-07, 3.1356e-08, 2.9471e-08, 5.2375e-09, 7.0918e-09]],\n",
       "    \n",
       "             [[5.9052e-08, 1.9464e-07, 5.7726e-08, 2.0786e-08, 1.2209e-08],\n",
       "              [8.0555e-08, 3.0768e-08, 9.7731e-09, 4.6025e-10, 5.6116e-09],\n",
       "              [1.4263e-08, 2.7094e-09, 2.2480e-10, 3.9920e-09, 7.6784e-08],\n",
       "              [1.4733e-09, 9.5530e-11, 4.8205e-11, 1.9014e-11, 2.2322e-11],\n",
       "              [4.2217e-08, 8.3109e-10, 4.5728e-11, 5.6412e-11, 6.6620e-11]]],\n",
       "    \n",
       "    \n",
       "            [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "    \n",
       "             [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "              [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
       "    \n",
       "    \n",
       "            [[[4.3869e-06, 1.9474e-06, 1.0233e-06, 3.0810e-07, 1.1439e-06],\n",
       "              [2.2034e-06, 6.8541e-07, 7.8347e-07, 3.8446e-07, 3.6753e-06],\n",
       "              [1.9366e-06, 4.5058e-07, 7.3466e-08, 5.4024e-07, 7.0144e-06],\n",
       "              [2.4581e-06, 5.3014e-07, 4.8963e-08, 2.8631e-06, 9.3442e-06],\n",
       "              [2.5493e-06, 4.9351e-07, 8.2964e-07, 7.9482e-06, 1.0112e-05]],\n",
       "    \n",
       "             [[1.9223e-06, 3.2088e-06, 8.5451e-07, 4.9007e-07, 4.3670e-07],\n",
       "              [1.1215e-06, 1.7639e-06, 1.3336e-06, 5.9577e-07, 1.1205e-07],\n",
       "              [9.6768e-07, 3.3231e-07, 3.4775e-07, 5.7005e-07, 3.1344e-07],\n",
       "              [1.8735e-07, 6.8895e-08, 2.9001e-07, 1.4146e-07, 3.5468e-08],\n",
       "              [8.5118e-07, 3.4448e-07, 5.5455e-08, 1.1559e-07, 9.2773e-07]],\n",
       "    \n",
       "             [[3.7784e-07, 3.4313e-07, 1.7544e-07, 3.5563e-08, 2.0346e-08],\n",
       "              [2.4503e-07, 2.1908e-07, 7.5552e-08, 1.8888e-08, 4.2540e-08],\n",
       "              [1.1793e-07, 7.9264e-08, 4.3788e-08, 4.1350e-08, 5.2431e-08],\n",
       "              [1.0046e-07, 3.3395e-08, 3.6020e-08, 5.6144e-09, 2.1542e-07],\n",
       "              [1.0049e-07, 1.0330e-07, 2.0981e-08, 1.9347e-07, 3.6581e-07]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[1.8418e-06, 9.8715e-07, 4.9075e-07, 2.0428e-07, 3.5793e-07],\n",
       "              [9.4543e-07, 5.7791e-07, 4.7651e-07, 2.6564e-07, 6.6872e-07],\n",
       "              [3.0237e-07, 1.7071e-07, 2.9685e-08, 1.4231e-07, 8.6150e-07],\n",
       "              [1.9359e-07, 1.8995e-07, 1.7806e-07, 4.7961e-07, 4.2951e-07],\n",
       "              [6.9796e-07, 5.9272e-07, 3.3788e-07, 2.8553e-07, 1.0499e-06]],\n",
       "    \n",
       "             [[3.0144e-07, 6.3757e-07, 4.7403e-07, 1.9952e-07, 7.7198e-08],\n",
       "              [1.8195e-07, 1.6364e-07, 3.5178e-07, 1.9191e-08, 6.5848e-08],\n",
       "              [2.6033e-07, 7.0198e-08, 1.1760e-07, 9.0211e-09, 8.5933e-08],\n",
       "              [2.8074e-07, 8.8448e-08, 3.1086e-08, 4.9495e-08, 5.0672e-07],\n",
       "              [2.0383e-07, 1.5022e-07, 1.7757e-07, 3.7901e-07, 7.8725e-07]],\n",
       "    \n",
       "             [[1.0134e-07, 3.9451e-07, 4.0142e-07, 2.1407e-07, 3.0334e-08],\n",
       "              [2.8332e-07, 5.8248e-07, 3.1967e-07, 6.6209e-08, 1.0534e-08],\n",
       "              [2.8701e-07, 1.8666e-07, 2.0278e-07, 4.8317e-08, 2.5656e-08],\n",
       "              [1.7922e-07, 5.2136e-08, 1.3633e-07, 2.4670e-08, 2.1341e-09],\n",
       "              [8.0830e-08, 1.1055e-07, 1.1323e-07, 3.8182e-08, 5.5577e-08]]]],\n",
       "           device='cuda:5')},\n",
       "   3: {'step': 12120,\n",
       "    'exp_avg': tensor([ 0.0000e+00, -8.6344e-04,  3.5699e-04, -1.7973e-04,  0.0000e+00,\n",
       "             2.1994e-04,  0.0000e+00,  5.6522e-04,  0.0000e+00,  6.2050e-04,\n",
       "             0.0000e+00,  1.1005e-03,  0.0000e+00, -1.7734e-03,  0.0000e+00,\n",
       "             1.7806e-04,  0.0000e+00, -6.3114e-04,  0.0000e+00, -1.8932e-04,\n",
       "             0.0000e+00,  1.0538e-03,  0.0000e+00,  3.9941e-05,  0.0000e+00,\n",
       "             9.8996e-04,  8.4505e-05,  1.6013e-03, -1.3892e-03, -2.9049e-04,\n",
       "             0.0000e+00,  1.0953e-04,  6.4160e-04, -9.3792e-04,  1.0487e-04,\n",
       "             3.7733e-04, -7.7422e-05,  1.7609e-04,  0.0000e+00, -8.5905e-05,\n",
       "             0.0000e+00, -3.7129e-04,  3.4416e-04, -1.2259e-06,  0.0000e+00,\n",
       "            -7.1661e-04,  4.5843e-08, -2.1035e-04,  0.0000e+00,  4.9918e-05,\n",
       "             0.0000e+00, -1.2616e-03, -9.3660e-04,  1.9557e-03,  0.0000e+00,\n",
       "             8.3826e-04, -2.2287e-04,  1.8003e-03, -7.1548e-04, -6.6269e-04,\n",
       "            -1.4402e-03,  5.3270e-05,  0.0000e+00, -6.5137e-04], device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([0.0000e+00, 6.4095e-05, 8.8769e-05, 2.1727e-05, 0.0000e+00, 4.1438e-05,\n",
       "            0.0000e+00, 1.6153e-05, 0.0000e+00, 1.4670e-04, 0.0000e+00, 9.2750e-05,\n",
       "            0.0000e+00, 1.5946e-04, 0.0000e+00, 1.0523e-05, 0.0000e+00, 1.0179e-04,\n",
       "            0.0000e+00, 9.0460e-05, 0.0000e+00, 5.9818e-05, 0.0000e+00, 9.6501e-05,\n",
       "            0.0000e+00, 1.1999e-04, 3.8752e-05, 8.8510e-05, 1.9315e-04, 8.3457e-05,\n",
       "            0.0000e+00, 8.8917e-05, 1.7746e-04, 5.9840e-05, 1.3157e-04, 1.6657e-04,\n",
       "            9.2797e-05, 1.4394e-05, 0.0000e+00, 1.9328e-04, 0.0000e+00, 8.6530e-06,\n",
       "            1.7050e-05, 2.1785e-06, 0.0000e+00, 2.3097e-05, 2.3296e-06, 2.5502e-04,\n",
       "            0.0000e+00, 8.6609e-06, 0.0000e+00, 1.0753e-04, 5.6525e-05, 9.9524e-05,\n",
       "            0.0000e+00, 1.1157e-04, 6.4276e-05, 1.4904e-04, 1.9647e-05, 4.1635e-05,\n",
       "            1.9775e-04, 1.7671e-05, 0.0000e+00, 7.1373e-05], device='cuda:5')},\n",
       "   4: {'step': 12120,\n",
       "    'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 2.7831e-05,  3.4815e-06, -7.6300e-10,  ..., -1.3619e-05,\n",
       "              0.0000e+00, -6.2059e-15],\n",
       "            [-2.4340e-09,  4.7830e-08,  3.4575e-09,  ..., -3.6717e-09,\n",
       "              0.0000e+00, -2.1143e-12],\n",
       "            [ 1.1513e-06, -7.2299e-07,  2.9408e-06,  ..., -4.4667e-07,\n",
       "              0.0000e+00,  3.6029e-07]], device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            ...,\n",
       "            [4.2527e-08, 4.0199e-08, 3.8953e-08,  ..., 7.5629e-08, 0.0000e+00,\n",
       "             2.2181e-15],\n",
       "            [3.5667e-08, 6.1871e-08, 1.0956e-08,  ..., 1.4436e-09, 0.0000e+00,\n",
       "             5.3547e-10],\n",
       "            [4.3567e-07, 3.2339e-07, 1.7382e-07,  ..., 1.8393e-07, 0.0000e+00,\n",
       "             5.9990e-09]], device='cuda:5')},\n",
       "   5: {'step': 12120,\n",
       "    'exp_avg': tensor([-2.9065e-04,  2.4099e-04,  2.6198e-05,  7.3599e-05,  0.0000e+00,\n",
       "            -3.1120e-05,  0.0000e+00, -3.4639e-05, -3.4495e-07,  1.1349e-05,\n",
       "            -8.4971e-06, -1.1290e-04,  0.0000e+00,  2.4200e-05,  0.0000e+00,\n",
       "             2.1338e-06,  3.6948e-06,  5.0064e-05,  2.2560e-05, -3.6352e-04,\n",
       "             0.0000e+00,  1.3727e-04,  0.0000e+00,  4.5818e-05,  3.5445e-05,\n",
       "             1.6834e-04, -3.3866e-04, -1.6714e-04,  0.0000e+00, -3.1909e-04,\n",
       "             0.0000e+00,  1.0722e-04, -3.9994e-06, -1.8532e-07,  2.7983e-05,\n",
       "             2.6014e-05,  0.0000e+00, -3.1347e-05,  0.0000e+00, -7.2568e-05,\n",
       "             2.8551e-08,  1.2534e-04,  2.3508e-05, -5.1052e-04,  0.0000e+00,\n",
       "            -9.0024e-04,  0.0000e+00,  3.0236e-05,  9.0228e-05,  1.3800e-04,\n",
       "             1.2150e-04,  1.1389e-06,  0.0000e+00,  3.0382e-04,  0.0000e+00,\n",
       "            -1.3972e-05, -2.4679e-04, -1.5005e-06, -1.8738e-08,  8.4414e-06,\n",
       "             0.0000e+00,  5.5097e-06,  0.0000e+00,  3.6765e-05, -6.1715e-05,\n",
       "            -5.1790e-05,  8.4783e-07, -3.1638e-05,  0.0000e+00, -8.1710e-10,\n",
       "             0.0000e+00, -3.2232e-08, -1.3849e-05, -4.4595e-05, -3.3265e-04,\n",
       "             4.2753e-05,  0.0000e+00, -1.0752e-05,  0.0000e+00, -2.5318e-08,\n",
       "            -2.2109e-05,  1.0013e-03,  2.7817e-06, -2.9190e-04,  0.0000e+00,\n",
       "            -2.4493e-04,  0.0000e+00,  1.1799e-06,  3.8316e-04,  8.0351e-08,\n",
       "             6.2463e-07,  1.8561e-04,  0.0000e+00,  4.9178e-05,  0.0000e+00,\n",
       "             1.9732e-05,  1.7475e-04,  2.7129e-07, -5.1297e-05, -3.7369e-04,\n",
       "             0.0000e+00,  1.6787e-04,  0.0000e+00,  1.9449e-04,  8.2545e-04,\n",
       "            -7.4869e-06,  2.1346e-04, -2.5232e-04,  0.0000e+00, -9.1722e-06,\n",
       "             0.0000e+00, -5.1452e-06, -2.9696e-10, -2.5996e-04, -1.7293e-05,\n",
       "             2.2914e-07,  0.0000e+00,  5.1164e-04,  0.0000e+00, -3.3261e-04,\n",
       "            -1.8118e-14, -1.5891e-05, -1.0028e-04, -4.2631e-05,  0.0000e+00,\n",
       "            -1.2190e-05,  0.0000e+00, -6.3169e-05, -1.7945e-04,  4.1368e-06,\n",
       "             2.6808e-05, -5.7831e-08,  0.0000e+00,  6.4732e-05,  0.0000e+00,\n",
       "            -1.2227e-04, -2.8183e-08,  6.8818e-06, -3.5837e-06, -3.2447e-05,\n",
       "             0.0000e+00,  8.6634e-04,  0.0000e+00,  2.9593e-04, -2.4258e-05,\n",
       "             1.8358e-04,  2.8173e-05,  8.4608e-33,  0.0000e+00, -3.3269e-05,\n",
       "             0.0000e+00, -6.8674e-06,  2.8205e-15, -1.8403e-05,  2.8297e-07,\n",
       "             6.4689e-05,  0.0000e+00, -3.2047e-13,  0.0000e+00,  5.0843e-05,\n",
       "             1.2964e-22, -2.9817e-04, -1.3382e-04,  1.0697e-06,  0.0000e+00,\n",
       "            -1.6686e-04,  0.0000e+00, -1.3317e-05,  1.7053e-04, -5.4001e-06,\n",
       "             3.2183e-04,  2.8718e-05,  0.0000e+00, -3.4679e-04,  0.0000e+00,\n",
       "            -2.7472e-05,  2.6661e-05, -8.9815e-06, -2.5757e-04,  4.5674e-06,\n",
       "             0.0000e+00,  1.8407e-04,  0.0000e+00,  4.5505e-05,  9.9476e-07,\n",
       "            -3.4890e-06,  2.9613e-06, -8.7482e-06,  0.0000e+00,  5.3668e-05,\n",
       "             0.0000e+00,  6.1366e-06, -2.7628e-05, -1.3943e-04, -5.2647e-06,\n",
       "             2.7070e-05,  0.0000e+00, -2.9316e-04,  0.0000e+00, -1.2818e-05,\n",
       "             2.8248e-04,  1.1200e-04,  4.7157e-06, -3.7866e-05,  0.0000e+00,\n",
       "             1.5224e-06,  0.0000e+00,  5.9720e-04,  2.0842e-05, -7.3079e-37,\n",
       "             4.8787e-06,  1.1125e-04,  0.0000e+00, -2.4440e-05,  0.0000e+00,\n",
       "             6.5270e-05,  7.3467e-06, -6.9046e-08,  3.8245e-05, -3.8028e-04,\n",
       "             0.0000e+00,  5.3820e-06,  0.0000e+00,  2.5974e-04,  4.1852e-04,\n",
       "            -1.6143e-04, -2.0372e-04, -8.1736e-07,  0.0000e+00, -4.3954e-08,\n",
       "             0.0000e+00, -1.2366e-04, -2.3049e-04, -9.3108e-06, -1.3431e-06,\n",
       "             3.5311e-07,  0.0000e+00,  2.3166e-04,  0.0000e+00, -2.9828e-05,\n",
       "            -1.7313e-04, -1.3588e-06, -1.1338e-04, -8.1491e-08,  0.0000e+00,\n",
       "             9.3634e-05,  0.0000e+00,  3.8356e-05, -2.2987e-04, -1.0028e-04,\n",
       "             3.1580e-04, -9.3564e-05,  0.0000e+00, -2.4729e-05,  0.0000e+00,\n",
       "             2.0264e-06], device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([7.5908e-06, 8.8306e-06, 1.1269e-05, 3.7377e-06, 0.0000e+00, 3.7033e-07,\n",
       "            0.0000e+00, 4.8703e-06, 1.4737e-07, 7.5749e-06, 1.9411e-06, 3.0705e-06,\n",
       "            0.0000e+00, 2.1495e-06, 0.0000e+00, 1.2688e-06, 3.5309e-06, 2.9745e-06,\n",
       "            8.7304e-06, 5.3343e-06, 0.0000e+00, 7.5991e-06, 0.0000e+00, 5.3403e-06,\n",
       "            3.3574e-06, 1.6173e-06, 1.3156e-05, 3.9471e-06, 0.0000e+00, 1.3503e-05,\n",
       "            0.0000e+00, 1.5975e-06, 3.4477e-06, 4.7681e-07, 4.0798e-06, 1.5450e-06,\n",
       "            0.0000e+00, 7.9918e-07, 0.0000e+00, 6.4551e-06, 1.1952e-06, 1.2728e-06,\n",
       "            1.5395e-06, 6.3171e-06, 0.0000e+00, 6.2051e-06, 0.0000e+00, 1.7009e-06,\n",
       "            1.0180e-05, 2.4493e-06, 5.3968e-06, 1.4716e-06, 0.0000e+00, 1.2712e-05,\n",
       "            0.0000e+00, 2.2217e-06, 5.0643e-06, 7.4160e-07, 1.0080e-06, 4.8170e-06,\n",
       "            0.0000e+00, 3.3213e-06, 0.0000e+00, 7.3666e-06, 2.3827e-06, 2.5841e-06,\n",
       "            7.4035e-06, 5.3667e-06, 0.0000e+00, 7.1018e-08, 0.0000e+00, 3.7951e-08,\n",
       "            4.0627e-07, 3.7291e-06, 6.2673e-06, 1.0481e-05, 0.0000e+00, 1.7424e-06,\n",
       "            0.0000e+00, 1.2480e-06, 3.8931e-06, 1.4161e-05, 4.9126e-06, 3.8170e-06,\n",
       "            0.0000e+00, 5.1910e-06, 0.0000e+00, 4.3627e-07, 9.5762e-06, 1.0451e-06,\n",
       "            2.1359e-06, 2.4815e-06, 0.0000e+00, 2.4708e-06, 0.0000e+00, 2.2806e-06,\n",
       "            2.4336e-06, 2.4824e-08, 4.2130e-06, 2.5744e-06, 0.0000e+00, 3.9317e-06,\n",
       "            0.0000e+00, 8.9167e-06, 1.8072e-05, 3.8174e-06, 7.0466e-06, 2.8090e-06,\n",
       "            0.0000e+00, 7.1697e-10, 0.0000e+00, 4.4470e-06, 4.9325e-08, 1.4317e-05,\n",
       "            3.3853e-06, 6.3561e-06, 0.0000e+00, 6.0641e-06, 0.0000e+00, 3.2600e-06,\n",
       "            2.8758e-10, 2.8634e-06, 5.3177e-06, 4.8468e-06, 0.0000e+00, 7.1624e-07,\n",
       "            0.0000e+00, 2.1324e-06, 8.7162e-07, 1.2931e-06, 1.4185e-06, 2.5321e-07,\n",
       "            0.0000e+00, 2.2585e-06, 0.0000e+00, 4.9776e-06, 2.2531e-07, 2.8905e-06,\n",
       "            1.0878e-06, 6.8698e-06, 0.0000e+00, 1.9560e-05, 0.0000e+00, 1.0321e-05,\n",
       "            2.9127e-06, 2.1706e-06, 5.4791e-06, 1.2424e-11, 0.0000e+00, 3.1546e-06,\n",
       "            0.0000e+00, 1.2927e-06, 7.8844e-08, 5.1896e-06, 1.2093e-06, 2.6129e-06,\n",
       "            0.0000e+00, 1.9444e-07, 0.0000e+00, 1.7807e-06, 6.3704e-10, 5.3636e-06,\n",
       "            2.2314e-05, 5.3227e-09, 0.0000e+00, 1.9455e-05, 0.0000e+00, 5.7191e-07,\n",
       "            2.6900e-06, 5.4686e-06, 4.4616e-06, 5.1941e-06, 0.0000e+00, 9.4959e-06,\n",
       "            0.0000e+00, 7.8575e-07, 5.3815e-06, 3.4353e-06, 1.4193e-06, 2.5232e-06,\n",
       "            0.0000e+00, 3.3502e-06, 0.0000e+00, 2.1392e-06, 1.9510e-06, 7.1366e-06,\n",
       "            5.7773e-06, 9.0391e-06, 0.0000e+00, 6.1318e-06, 0.0000e+00, 2.8331e-06,\n",
       "            3.6332e-06, 3.4070e-06, 1.3515e-06, 3.8080e-06, 0.0000e+00, 2.0105e-06,\n",
       "            0.0000e+00, 4.4557e-06, 1.8770e-06, 8.0207e-07, 2.1139e-06, 7.6824e-06,\n",
       "            0.0000e+00, 1.2950e-05, 0.0000e+00, 4.2068e-06, 5.8968e-06, 5.8512e-10,\n",
       "            3.6100e-07, 5.1986e-06, 0.0000e+00, 2.8625e-06, 0.0000e+00, 4.2090e-06,\n",
       "            6.2836e-06, 1.9748e-06, 8.8658e-06, 2.4632e-06, 0.0000e+00, 1.8283e-06,\n",
       "            0.0000e+00, 5.5868e-06, 9.7348e-06, 1.1285e-05, 2.2017e-06, 1.9458e-06,\n",
       "            0.0000e+00, 4.1955e-06, 0.0000e+00, 6.7944e-06, 4.8863e-06, 3.2275e-06,\n",
       "            1.5859e-06, 5.7459e-07, 0.0000e+00, 6.3000e-06, 0.0000e+00, 4.5758e-06,\n",
       "            4.3544e-06, 6.2850e-06, 2.4005e-06, 1.0079e-06, 0.0000e+00, 5.3309e-06,\n",
       "            0.0000e+00, 2.1859e-06, 3.8518e-06, 1.0635e-05, 2.2828e-06, 3.3352e-06,\n",
       "            0.0000e+00, 2.5197e-06, 0.0000e+00, 2.3684e-07], device='cuda:5')},\n",
       "   6: {'step': 12120,\n",
       "    'exp_avg': tensor([[ 0.0000e+00, -3.3129e-10,  0.0000e+00,  ..., -1.1260e-22,\n",
       "             -7.4211e-05,  4.3607e-06],\n",
       "            [ 0.0000e+00,  2.2147e-07,  0.0000e+00,  ...,  3.3525e-37,\n",
       "             -6.6938e-06,  3.0857e-05],\n",
       "            [ 0.0000e+00, -9.8556e-09,  0.0000e+00,  ...,  5.6052e-45,\n",
       "              1.3672e-07, -5.6888e-08],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -5.2168e-22,  0.0000e+00,  ...,  5.6052e-45,\n",
       "              2.0643e-05, -3.6010e-08],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -4.0130e-07,  0.0000e+00,  ..., -2.4174e-15,\n",
       "             -1.6899e-08,  5.6924e-11]], device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([[0.0000e+00, 1.5079e-07, 0.0000e+00,  ..., 6.1216e-11, 6.4436e-06,\n",
       "             3.8739e-06],\n",
       "            [0.0000e+00, 1.0556e-07, 0.0000e+00,  ..., 3.5777e-11, 1.6608e-06,\n",
       "             4.1310e-06],\n",
       "            [0.0000e+00, 4.8012e-08, 0.0000e+00,  ..., 1.0510e-08, 1.2815e-06,\n",
       "             1.1232e-06],\n",
       "            ...,\n",
       "            [0.0000e+00, 1.4854e-08, 0.0000e+00,  ..., 2.4826e-10, 4.7858e-07,\n",
       "             8.7999e-07],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [0.0000e+00, 1.1357e-08, 0.0000e+00,  ..., 1.8342e-14, 8.9024e-08,\n",
       "             1.7207e-08]], device='cuda:5')},\n",
       "   7: {'step': 12120,\n",
       "    'exp_avg': tensor([ 0.0000e+00, -1.9470e-06,  0.0000e+00, -1.1305e-04,  0.0000e+00,\n",
       "             2.1793e-04,  0.0000e+00, -2.0429e-07,  1.0023e-04, -4.2566e-07,\n",
       "             1.1588e-11,  4.9315e-04, -4.4299e-06,  2.4285e-04, -4.6926e-05,\n",
       "            -3.6945e-04, -5.9199e-06, -9.1493e-08,  5.3034e-15,  1.2553e-08,\n",
       "             1.7047e-04, -1.7968e-06, -1.7557e-06, -6.3960e-06,  9.0348e-05,\n",
       "            -1.0294e-06, -1.9190e-11, -3.3123e-05,  5.0209e-05, -8.9182e-05,\n",
       "            -2.0170e-06,  2.1753e-04, -1.0490e-06, -9.4110e-08,  1.1400e-05,\n",
       "            -1.5916e-04,  4.2200e-07,  8.0329e-05,  1.6980e-05,  6.7513e-05,\n",
       "            -2.4492e-07,  2.7164e-07,  8.5063e-06, -1.6007e-04,  2.6032e-05,\n",
       "            -1.0905e-07,  1.9269e-04,  1.0316e-17, -2.9454e-07, -1.9707e-06,\n",
       "             5.1347e-09, -2.8005e-05, -8.9296e-05, -1.7977e-04, -9.1122e-05,\n",
       "             2.9622e-05, -7.6623e-05, -2.6986e-04,  9.1982e-05, -2.0722e-04,\n",
       "            -2.8615e-04, -1.8376e-04,  3.7709e-05,  1.4147e-05,  2.5440e-05,\n",
       "            -1.1105e-07, -2.4763e-07, -3.8109e-12,  6.5729e-06, -6.9666e-06,\n",
       "             1.4534e-05, -5.2472e-06, -9.4616e-11, -9.9649e-05, -2.8166e-04,\n",
       "            -1.8273e-06,  3.3587e-05, -1.1767e-04,  1.8120e-05, -3.2108e-05,\n",
       "             1.9302e-04,  6.9840e-05,  1.9708e-07,  1.3399e-06,  5.5310e-05,\n",
       "             3.7088e-04, -2.4236e-08, -1.3643e-06, -1.3610e-04,  3.5629e-06,\n",
       "            -1.6858e-04,  9.6351e-05, -2.6654e-05, -9.4335e-08,  1.8843e-04,\n",
       "            -8.3786e-25,  2.2368e-04,  4.2808e-04, -7.1011e-05,  1.1963e-04,\n",
       "             7.4101e-05,  2.5699e-05, -5.9105e-06,  2.7767e-05, -1.7928e-04,\n",
       "            -2.8708e-05, -9.5515e-05, -1.2636e-05, -2.1560e-04,  1.2685e-04,\n",
       "            -9.5567e-07,  6.2051e-05, -3.0297e-06, -1.1496e-05,  5.0313e-06,\n",
       "             2.4611e-05,  2.5322e-06, -1.1510e-06,  1.9461e-08,  2.6520e-04,\n",
       "            -2.4399e-04,  1.9994e-05, -4.7961e-05,  3.1374e-06, -3.3626e-05,\n",
       "             2.4530e-09, -3.5341e-05, -2.7103e-06, -2.4940e-05, -2.8163e-04,\n",
       "            -4.4564e-06,  4.4266e-06,  8.6828e-05,  2.8436e-05,  1.8062e-06,\n",
       "             2.1870e-04,  1.0569e-04,  6.3228e-06,  2.0036e-07,  9.4071e-14,\n",
       "            -1.1490e-04, -2.9680e-06, -1.1776e-05,  9.5336e-06,  1.6003e-04,\n",
       "             2.5581e-05, -4.6343e-05,  3.1178e-05,  6.8821e-07, -1.6992e-04,\n",
       "             1.7239e-05, -2.4476e-04,  3.5537e-10,  4.1690e-05, -3.6319e-07,\n",
       "            -7.1232e-08,  1.8607e-05, -1.0498e-05, -2.3472e-05, -1.3780e-04,\n",
       "             3.4210e-05, -1.6211e-04, -1.9344e-06,  2.9174e-04,  1.4727e-09,\n",
       "             4.7873e-05, -2.1046e-05, -1.2985e-05, -1.9860e-09,  1.1377e-07,\n",
       "            -5.1005e-07,  3.5431e-05,  4.6607e-07, -1.3065e-04, -9.2460e-05,\n",
       "             1.4784e-04, -9.5259e-05,  5.0075e-06, -2.4272e-06, -8.8053e-07,\n",
       "            -5.8537e-05, -1.3268e-04,  3.3562e-06,  1.2524e-05,  5.5068e-08,\n",
       "            -5.1283e-04, -2.3205e-04,  3.4055e-05,  2.6343e-05, -1.0192e-05,\n",
       "             1.0918e-04, -2.4351e-04, -6.3572e-05, -7.6806e-06, -2.1990e-05,\n",
       "            -7.1874e-05, -8.0281e-06,  2.1210e-05, -3.4655e-05,  2.5469e-10,\n",
       "             2.5048e-07,  5.5885e-05,  3.0604e-04,  1.0340e-05,  1.2326e-06,\n",
       "            -9.5365e-05, -5.6052e-45, -1.9959e-04, -5.4748e-06,  6.6097e-05,\n",
       "             9.1927e-06,  1.4022e-04,  4.7031e-07, -6.2200e-07, -5.4927e-05,\n",
       "            -3.4835e-18,  1.8874e-05,  4.4221e-05, -5.6577e-05, -1.7355e-05,\n",
       "            -1.9052e-05,  9.1415e-06, -3.0310e-04, -3.7730e-05, -5.0811e-06,\n",
       "            -4.0471e-06, -2.0791e-04, -3.7222e-06, -1.9444e-06,  5.3037e-07,\n",
       "            -9.4753e-06, -1.0116e-04,  3.1182e-05, -2.0899e-05, -1.4424e-04,\n",
       "            -2.0738e-08, -4.9842e-05,  1.8624e-04,  1.3384e-04,  6.9548e-08,\n",
       "            -4.8614e-05, -3.6394e-05,  8.6091e-05, -2.0930e-04,  3.8338e-06,\n",
       "            -5.8269e-05,  9.4081e-06, -3.6282e-05,  3.2891e-04, -4.4650e-05,\n",
       "             1.0207e-08, -4.8126e-06, -5.0944e-05, -3.6590e-14, -1.2076e-04,\n",
       "             1.8313e-05], device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([0.0000e+00, 1.5843e-06, 0.0000e+00, 2.3977e-06, 0.0000e+00, 1.5264e-06,\n",
       "            0.0000e+00, 8.6861e-08, 2.5329e-06, 8.4453e-07, 5.0067e-08, 6.5246e-06,\n",
       "            4.8439e-07, 5.6121e-06, 2.0173e-06, 2.7343e-06, 1.0197e-06, 4.3698e-08,\n",
       "            3.6739e-08, 3.5121e-08, 4.4486e-06, 2.3697e-07, 3.7891e-07, 6.8320e-07,\n",
       "            2.1394e-06, 5.9065e-07, 2.0171e-09, 1.0859e-06, 1.0334e-06, 2.2896e-06,\n",
       "            4.7633e-07, 3.8250e-06, 3.8631e-06, 5.8380e-08, 1.5895e-06, 3.2825e-06,\n",
       "            1.5591e-08, 3.1206e-06, 3.4517e-07, 2.3056e-06, 2.3172e-07, 1.3123e-07,\n",
       "            6.8535e-07, 3.9612e-06, 2.4163e-07, 2.2212e-08, 1.8873e-06, 2.0832e-09,\n",
       "            1.0748e-06, 2.5029e-06, 8.4127e-08, 2.6789e-07, 3.4819e-06, 2.8008e-07,\n",
       "            2.1815e-06, 6.5974e-07, 9.2669e-07, 4.4516e-06, 1.8826e-06, 2.9858e-06,\n",
       "            5.1552e-06, 1.0737e-06, 8.9080e-06, 5.8326e-07, 2.4747e-06, 2.7879e-07,\n",
       "            1.8367e-07, 3.3834e-11, 1.2559e-06, 4.1658e-06, 5.1827e-07, 4.0655e-06,\n",
       "            2.3609e-07, 1.4990e-06, 1.7634e-06, 6.4217e-07, 3.7828e-07, 1.6580e-06,\n",
       "            9.9015e-07, 6.2447e-07, 1.3288e-06, 1.4928e-06, 8.8376e-08, 5.7781e-07,\n",
       "            1.4984e-06, 9.5043e-06, 2.7699e-09, 3.4762e-07, 1.3801e-06, 1.4091e-06,\n",
       "            8.1988e-07, 1.5690e-06, 5.1917e-07, 5.3116e-07, 1.6191e-06, 3.9762e-17,\n",
       "            3.6224e-06, 8.4730e-06, 2.9611e-07, 2.0551e-06, 4.1734e-06, 9.2973e-07,\n",
       "            3.5655e-07, 1.9636e-06, 1.9961e-06, 5.4265e-07, 1.3149e-06, 3.7035e-07,\n",
       "            1.1775e-06, 1.6051e-06, 3.2361e-07, 5.4125e-07, 4.9145e-07, 4.8316e-06,\n",
       "            1.3985e-06, 2.2466e-07, 1.9827e-06, 1.6609e-08, 4.4502e-08, 6.7189e-06,\n",
       "            1.0888e-06, 1.5713e-07, 9.3166e-07, 1.7579e-06, 1.6536e-06, 2.9902e-08,\n",
       "            6.6579e-07, 2.6023e-06, 2.0132e-06, 2.0955e-06, 1.6567e-06, 1.0667e-06,\n",
       "            6.7880e-07, 2.0990e-06, 4.1558e-08, 2.3016e-06, 4.1814e-06, 7.9221e-07,\n",
       "            7.1037e-07, 9.6209e-10, 2.9791e-06, 1.4963e-06, 1.7627e-06, 2.4970e-06,\n",
       "            2.3277e-06, 8.2319e-07, 6.4302e-07, 1.5984e-06, 1.8348e-06, 2.4341e-06,\n",
       "            2.0360e-07, 4.8627e-07, 1.6871e-08, 5.5560e-06, 3.0965e-07, 3.3358e-07,\n",
       "            4.5021e-06, 2.4065e-06, 5.0373e-07, 2.4839e-07, 3.8128e-06, 2.4108e-06,\n",
       "            1.1891e-06, 7.2417e-06, 1.2266e-07, 3.3472e-06, 6.2551e-06, 3.1697e-06,\n",
       "            1.0707e-07, 2.8378e-08, 3.4085e-08, 2.3223e-06, 1.8197e-07, 2.5487e-06,\n",
       "            1.0014e-06, 2.3064e-06, 2.9695e-06, 1.9125e-06, 6.2807e-07, 1.7119e-07,\n",
       "            2.8117e-06, 4.7768e-06, 4.5307e-07, 2.9636e-07, 1.1362e-07, 5.8445e-06,\n",
       "            3.0395e-06, 9.5200e-07, 1.8217e-06, 1.0645e-06, 1.8143e-06, 4.0438e-06,\n",
       "            2.6464e-06, 1.2182e-06, 1.0985e-06, 5.9688e-06, 2.4111e-07, 7.5458e-07,\n",
       "            3.4949e-06, 3.4620e-08, 2.9743e-07, 8.2129e-07, 3.3672e-06, 3.6126e-07,\n",
       "            6.0454e-07, 1.2190e-06, 5.0172e-18, 4.1498e-07, 8.7320e-07, 9.4681e-07,\n",
       "            2.4999e-06, 1.8825e-06, 3.5389e-07, 5.1866e-07, 3.4442e-06, 2.5715e-10,\n",
       "            2.9100e-06, 1.6817e-06, 8.5007e-08, 2.3507e-06, 4.9192e-07, 1.1298e-06,\n",
       "            6.4690e-06, 2.3380e-06, 6.4739e-07, 1.3710e-06, 1.7290e-06, 3.7705e-06,\n",
       "            3.2951e-08, 7.8689e-07, 6.2012e-06, 1.0207e-06, 9.3595e-07, 3.9663e-06,\n",
       "            3.0507e-06, 2.3452e-07, 1.8478e-06, 1.5338e-06, 5.3749e-06, 5.5581e-08,\n",
       "            3.6153e-07, 9.9418e-07, 1.2248e-06, 1.9360e-06, 1.5240e-06, 5.6767e-07,\n",
       "            2.1216e-07, 2.3619e-06, 4.4813e-06, 2.7220e-06, 8.0227e-08, 9.7974e-07,\n",
       "            2.3006e-06, 2.3503e-08, 5.9997e-06, 1.2115e-05], device='cuda:5')},\n",
       "   8: {'step': 12120,\n",
       "    'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.0163e-06,  8.2389e-06,  8.3870e-10,  ..., -1.5939e-09,\n",
       "              7.2815e-08,  1.2415e-11],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 1.7761e-14,  3.1476e-20,  1.6119e-26,  ...,  2.4763e-28,\n",
       "              8.2768e-21,  5.8049e-22],\n",
       "            [ 1.9023e-06, -5.6733e-05, -2.2061e-07,  ...,  6.0375e-05,\n",
       "             -3.1608e-07, -1.5470e-05],\n",
       "            [ 1.5031e-06,  4.2784e-07,  4.1588e-05,  ..., -3.2717e-06,\n",
       "             -7.0095e-06,  3.6049e-07]], device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [2.0518e-07, 6.2291e-07, 6.3297e-09,  ..., 5.7081e-08, 1.2781e-07,\n",
       "             5.8721e-09],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            ...,\n",
       "            [9.5721e-09, 1.2079e-09, 8.9070e-11,  ..., 2.2796e-11, 1.8648e-09,\n",
       "             7.3304e-12],\n",
       "            [9.8888e-08, 1.9319e-06, 1.2072e-07,  ..., 3.4710e-07, 2.1109e-07,\n",
       "             8.0974e-07],\n",
       "            [1.9401e-06, 3.4481e-06, 5.5616e-06,  ..., 1.4273e-06, 3.1436e-06,\n",
       "             7.4087e-07]], device='cuda:5')},\n",
       "   9: {'step': 12120,\n",
       "    'exp_avg': tensor([ 4.2302e-06, -1.2233e-04,  2.4256e-05,  1.9330e-04, -2.7710e-04,\n",
       "            -2.0445e-04,  1.0330e-05, -7.8144e-05, -1.4588e-05,  4.6450e-04],\n",
       "           device='cuda:5'),\n",
       "    'exp_avg_sq': tensor([1.5033e-06, 3.5135e-06, 2.8763e-06, 2.4999e-06, 4.3444e-06, 3.4862e-06,\n",
       "            2.9491e-06, 3.7216e-06, 3.2569e-06, 5.1330e-06], device='cuda:5')}},\n",
       "  'param_groups': [{'lr': 0.001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]},\n",
       " 'results': {'f1': 0.99,\n",
       "  'accuracy': 0.99,\n",
       "  'auc_score': 1.0,\n",
       "  'precision': 0.99,\n",
       "  'recall': 0.99}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = (1,)\n",
    "maxk = max(topk)\n",
    "\n",
    "out.data.t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outs = np.array(all_outs).reshape(-1, 10)\n",
    "all_labels = np.array(all_labels).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2279, 0.4722, 0.2999],\n",
       "        [0.4725, 0.1987, 0.3288]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxk = max(topk)\n",
    "batch_size = target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8, 3, ..., 3, 4, 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxk = max((1,))\n",
    "\n",
    "_, pred = out.data.topk(maxk, 1, True, True)\n",
    "pred.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.eq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (100) at non-singleton dimension 1.  Target sizes: [100, 1].  Tensor sizes: [1, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b202ab74047f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (100) at non-singleton dimension 1.  Target sizes: [100, 1].  Tensor sizes: [1, 100]"
     ]
    }
   ],
   "source": [
    "correct = pred.eq(y.data.view(1, -1).expand_as(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35],\n",
       "         [ 1.6940e+35, -4.0876e+35,  1.5291e+35,  1.2766e+35, -1.1093e+35,\n",
       "           2.1263e+35,  1.5256e+35,  5.6608e+35,  9.3236e+33,  1.3016e+35]],\n",
       "        device='cuda:5'),\n",
       " tensor([4, 4, 7, 8, 8, 4, 7, 6, 3, 8, 9, 6, 5, 2, 1, 1, 7, 9, 5, 6, 3, 5, 6, 1,\n",
       "         5, 7, 4, 9, 1, 4, 5, 8, 4, 9, 7, 5, 7, 8, 3, 1, 2, 9, 4, 6, 3, 6, 7, 0,\n",
       "         5, 0, 0, 5, 2, 2, 1, 8, 3, 6, 2, 3, 6, 9, 5, 0, 7, 8, 1, 0, 5, 2, 9, 6,\n",
       "         0, 1, 9, 9, 4, 3, 6, 1, 7, 8, 0, 4, 9, 5, 9, 7, 3, 9, 1, 3, 9, 1, 2, 3,\n",
       "         6, 7, 2, 8], device='cuda:5'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.data, y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6398e+35, device='cuda:5', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "# parameters\n",
    "num_classes = 10\n",
    "input_size = (1, 28, 28)\n",
    "conv_dims = [32, 64]\n",
    "fc_dims = [256, 10]\n",
    "kernel_sizes = [5, 5]\n",
    "layer_sparsity = [0.3, 0.3, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L0LeNet(\n",
       "  (convs): Sequential(\n",
       "    (conv1): L0Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), sparse_ratio=0.0)\n",
       "    (relu1): ReLU()\n",
       "    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): L0Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), sparse_ratio=0.0)\n",
       "    (relu2): ReLU()\n",
       "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (fc1): L0Dense(1024 -> 256, sparse_ratio=0.0)\n",
       "    (relu3): ReLU()\n",
       "    (fc2): L0Dense(256 -> 256, sparse_ratio=0.0)\n",
       "    (relu4): ReLU()\n",
       "    (fc3): L0Dense(256 -> 10, sparse_ratio=0.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn((20, input_size[0], input_size[1], input_size[2]), device=device) # Input: (N, C_{in}, H_{in}, W_{in})\n",
    "out = model(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.9340e+28,  1.2130e+28, -1.0965e+28,  6.2782e+27,  1.4191e+28,\n",
       "         9.2325e+27, -9.3407e+27,  2.6250e+27,  9.4843e+27,  1.9932e+28],\n",
       "       device='cuda:5', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "# parameters\n",
    "num_classes = 10\n",
    "input_size = (1, 28, 28)\n",
    "conv_dims = [32, 64]\n",
    "fc_dims = [256, 10]\n",
    "kernel_sizes = [5, 5]\n",
    "layer_sparsity = [0.3, 0.3, 0.2, 0.2]\n",
    "\n",
    "device = 'cuda:5'\n",
    "\n",
    "isTrain = True\n",
    "\n",
    "# model structure\n",
    "convs = OrderedDict([\n",
    "    ('conv1', L0Conv2d(input_size[0], conv_dims[0], kernel_sizes[0], sparse_ratio=layer_sparsity[0], device=device)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('maxpool1',nn.MaxPool2d(2)),\n",
    "    ('conv2', L0Conv2d(conv_dims[0], conv_dims[1], kernel_sizes[1], sparse_ratio=layer_sparsity[1], device=device)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('maxpool2',nn.MaxPool2d(2)),\n",
    "])\n",
    "\n",
    "convs = nn.Sequential(convs)\n",
    "\n",
    "h_out = lambda: int(convs.conv2.h_out((convs.conv1.h_out(input_size[1]) / 2)) / 2)\n",
    "w_out = lambda: int(convs.conv2.w_out((convs.conv1.w_out(input_size[1]) / 2)) / 2)\n",
    "output_len = conv_dims[-1] * h_out() * w_out()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    convs = convs.to(device)\n",
    "\n",
    "fcs = OrderedDict([\n",
    "    ('fc1', L0Dense(output_len, fc_dims[0], sparse_ratio=layer_sparsity[2], device=device)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('fc2', L0Dense(fc_dims[0], fc_dims[1], sparse_ratio=layer_sparsity[3], device=device))\n",
    "])\n",
    "fcs = nn.Sequential(fcs)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    fcs = fcs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convs.conv1.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weights cuda:5\n",
      "conv1.bias cuda:5\n",
      "conv2.weights cuda:5\n",
      "conv2.bias cuda:5\n"
     ]
    }
   ],
   "source": [
    "for name,param in convs.named_parameters():\n",
    "    print(name, param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.profiler as profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ = torch.randn((20, input_size[0], input_size[1], input_size[2]), device=device) # Input: (N, C_{in}, H_{in}, W_{in})\n",
    "out = convs(input_)\n",
    "out = out.view(out.shape[0], -1)\n",
    "out = fcs(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn.modules import Module\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.utils import _pair as pair\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out = lambda h_in, padding, dilation, kernel_size, stride: np.floor((h_in + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1)/stride[0] + 1)\n",
    "w_out = lambda w_in, padding, dilation, kernel_size, stride: np.floor((w_in + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1)/stride[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "c_in = 1\n",
    "c_out = 16\n",
    "h_in = 28\n",
    "w_in = 28\n",
    "stride, padding, dilation = 1, pair(2), 1\n",
    "groups = 1\n",
    "kernel_size = pair(5)\n",
    "\n",
    "\n",
    "input_ = torch.randn((batch_size, c_in, h_in, w_in)) # Input: (N, C_{in}, H_{in}, W_{in})\n",
    "weights = Parameter(torch.Tensor(c_out, c_in // groups, *kernel_size))\n",
    "qz_loga = Parameter(torch.Tensor(c_out))\n",
    "bias = Parameter(torch.Tensor(c_out))\n",
    "\n",
    "\n",
    "\n",
    "out = F.conv2d(input_, weights, bias, stride, padding, dilation, groups)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_input_ = torch.randn((batch_size, 1024)) # Input: (N, C_{in}, H_{in}, W_{in})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1024])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_weights = Parameter(torch.Tensor(1024, 256))\n",
    "\n",
    "output = fc_input_.mm(fc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00, -1.3298e-41,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  1.3103e-40,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -1.4917e-41,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00, -2.5987e-40,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -8.9602e-41,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  1.5021e-40,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.add_(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3447e+08,\n",
       "         3.0732e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00], requires_grad=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.kaiming_normal_(weights, mode='fan_in')\n",
    "qz_loga.data.normal_(math.log(1 - 0.5) - math.log(0.5), 1e-2)\n",
    "\n",
    "floatTensor = torch.FloatTensor\n",
    "\n",
    "temparature = 2/3\n",
    "\n",
    "qz_loga = Parameter(torch.Tensor(c_out))\n",
    "\n",
    "qz_loga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 5, 5])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 0.9\n",
    "\n",
    "percentile = lambda weights, percent : weights.abs().view(-1).sort()[0][int((percent)*weights.abs().view(-1).shape[0])].detach().cpu().numpy().tolist()\n",
    "lamb = percentile(weights, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones(c_out, c_in // groups, *kernel_size)\n",
    "\n",
    "mask[torch.abs(weights) <= lamb] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = weights * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.data = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_a, limit_b, epsilon = -.1, 1.1, 1e-6\n",
    "\n",
    "def quantile_concrete(x):\n",
    "    y = F.sigmoid((torch.log(x) - torch.log(1-x) + qz_loga / temparature))\n",
    "    return y * (limit_b - limit_a) + limit_a\n",
    "    \n",
    "def get_eps(size):\n",
    "    eps = floatTensor(size).uniform_(epsilon, 1 - epsilon)\n",
    "    eps = Variable(eps)\n",
    "    return eps\n",
    "\n",
    "def sample_weights():\n",
    "    z = quantile_concrete(get_eps(floatTensor(c_out))).view(c_out, 1, 1, 1)\n",
    "    return F.hardtanh(z, min_val=0, max_val=1) * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = sample_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = quantile_concrete(get_eps(floatTensor(c_out))).view(c_out, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.2145e-02, -1.6856e-02,  2.5339e-03,  3.4270e-02,  1.3390e-02],\n",
       "          [-1.4876e-02,  2.2128e-03, -3.7560e-03, -1.9444e-02,  3.0503e-02],\n",
       "          [-1.4897e-02, -2.4890e-02, -1.5467e-02,  1.0234e-02, -1.4522e-02],\n",
       "          [ 7.1167e-03,  7.5601e-02, -4.8880e-02, -1.1894e-02, -5.5404e-02],\n",
       "          [-7.8016e-03, -1.4512e-02,  1.0577e-02,  3.4400e-02,  2.4251e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1988e-01, -1.5932e-01,  2.9719e-01, -5.7669e-01, -1.4538e-01],\n",
       "          [-1.4460e-01, -1.2509e-01, -1.0263e-01, -1.7746e-01,  1.5996e-01],\n",
       "          [ 1.9651e-01,  2.3964e-01, -8.7329e-02, -6.7641e-02, -3.8525e-02],\n",
       "          [-1.7603e-05,  1.3579e-01,  1.1784e-03, -3.8781e-02, -1.7390e-01],\n",
       "          [ 1.0882e-02,  2.3507e-01, -1.3571e-01,  8.4861e-02,  1.0216e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4764e-01,  1.9106e-01, -2.1197e-01,  2.6561e-01,  1.3764e-02],\n",
       "          [-3.5268e-02, -6.4513e-02, -4.0616e-02, -3.0495e-01,  6.5706e-01],\n",
       "          [-3.8560e-01, -4.1955e-01, -5.1063e-02,  2.3522e-01,  6.5172e-01],\n",
       "          [ 1.9201e-01, -1.9036e-02,  2.0766e-01,  3.6589e-01, -1.7018e-02],\n",
       "          [ 1.0617e-01,  4.7131e-01,  5.3112e-01,  4.0135e-01, -1.4012e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9257e-02, -1.7199e-01, -1.9008e-01,  4.5838e-03,  2.2563e-01],\n",
       "          [-1.7656e-02, -1.9062e-01, -2.3813e-01,  1.7170e-01,  3.8620e-03],\n",
       "          [ 6.7700e-04, -6.9228e-02,  7.0368e-02,  1.6240e-02,  1.3672e-01],\n",
       "          [-8.4934e-02,  6.9551e-02,  1.1948e-01,  8.5831e-02, -4.7584e-01],\n",
       "          [-2.7839e-01, -1.8268e-01,  2.6795e-02, -1.6977e-03,  1.2566e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.8591e-02,  1.7456e-01,  1.6018e-01,  7.1339e-02,  4.2645e-02],\n",
       "          [ 1.5045e-01,  4.5612e-02,  1.4990e-01, -7.7313e-02, -3.2217e-01],\n",
       "          [ 4.2207e-02, -1.9536e-01, -1.8717e-01, -1.5591e-01,  1.2950e-02],\n",
       "          [-3.3135e-03,  4.9168e-02, -2.3072e-02,  4.4834e-02, -2.3827e-01],\n",
       "          [ 9.0038e-02, -2.7092e-02,  2.3143e-01, -8.6606e-02,  4.4498e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8612e-02,  2.1045e-01,  6.0194e-02, -1.1883e-01, -1.7620e-01],\n",
       "          [-5.4005e-02, -1.6962e-01, -7.6261e-02,  9.3229e-02,  1.5781e-02],\n",
       "          [-9.1030e-03,  9.6511e-02, -1.1449e-02, -1.1775e-01,  7.7022e-03],\n",
       "          [ 5.7346e-02, -8.0860e-02,  2.7266e-02, -6.1707e-02,  1.6199e-01],\n",
       "          [-1.8153e-02,  2.0618e-01,  1.5400e-01, -1.0438e-01, -1.2825e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7107e-01,  2.8355e-01,  6.3702e-02, -1.5693e-02,  4.5430e-01],\n",
       "          [ 2.9396e-01, -2.4056e-01, -2.4756e-01, -4.9318e-01,  2.6189e-01],\n",
       "          [ 2.6619e-01, -2.8269e-01,  6.5895e-02,  6.2620e-01,  3.2305e-01],\n",
       "          [-1.3895e-02,  3.3185e-01, -4.3513e-01, -4.3759e-01, -3.1120e-01],\n",
       "          [-1.6067e-02,  2.5017e-01, -3.8403e-01, -2.4105e-01,  5.8478e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0643e-01,  2.4454e-02,  2.8191e-01, -8.8612e-02, -2.9598e-01],\n",
       "          [ 1.7661e-01,  1.4019e-01, -9.8306e-02, -6.9574e-01,  2.6365e-01],\n",
       "          [ 1.3060e-01, -1.3087e-01,  4.8147e-01, -9.7648e-02, -2.0502e-01],\n",
       "          [ 6.1548e-01,  2.7627e-01, -2.2289e-02,  1.6291e-01, -2.1063e-01],\n",
       "          [ 2.0865e-01,  3.0046e-03,  8.6495e-02, -2.4200e-01,  3.4703e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7505e-01, -3.0108e-02,  1.0308e-01,  1.3387e-01, -7.2132e-02],\n",
       "          [-2.2401e-01, -1.8140e-02,  2.0407e-01,  1.0883e-01,  5.3239e-02],\n",
       "          [-2.3894e-01, -1.4295e-01, -4.0012e-02,  3.0309e-01, -2.8622e-01],\n",
       "          [ 1.8657e-01,  4.5911e-01,  3.7460e-01, -1.6848e-01, -2.4292e-02],\n",
       "          [ 2.8462e-01, -2.2315e-01,  1.2445e-01, -2.6365e-01,  2.3670e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7753e-02,  5.1981e-03,  1.1135e-02,  2.0492e-03, -1.5453e-03],\n",
       "          [ 3.6837e-03,  2.4779e-02,  9.0510e-03, -3.4062e-02, -1.2864e-02],\n",
       "          [-3.7239e-03,  1.3774e-02,  3.8211e-02, -3.4598e-03, -3.9279e-02],\n",
       "          [ 1.4401e-02,  1.3830e-02, -1.3634e-02, -3.4416e-02, -1.1980e-02],\n",
       "          [ 2.8610e-03,  6.2677e-03, -7.1294e-05,  1.2720e-02, -7.6987e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6877e-02, -5.2569e-03, -1.0641e-02, -2.1682e-02, -2.6266e-02],\n",
       "          [ 3.8589e-02, -3.0182e-02, -7.1384e-03,  3.9606e-02, -1.5174e-02],\n",
       "          [ 8.0253e-03, -2.6769e-02,  2.7489e-02,  1.2835e-02, -1.0034e-02],\n",
       "          [ 3.0318e-03, -1.2475e-02, -6.4352e-03,  1.3069e-02,  6.8399e-03],\n",
       "          [ 3.3646e-03,  3.8865e-02, -1.5642e-03,  1.7349e-02, -1.3476e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.0031e-02,  1.3488e-03,  1.0652e-03,  9.8318e-04, -1.8854e-03],\n",
       "          [-1.5508e-03, -7.8801e-04, -4.7815e-03,  1.4240e-03, -5.1314e-03],\n",
       "          [ 3.6018e-04, -4.2762e-03, -1.9235e-03,  7.2213e-04,  2.6615e-03],\n",
       "          [-1.8489e-03, -5.8669e-03, -1.4526e-03, -1.7642e-03, -1.0764e-03],\n",
       "          [ 2.7670e-03, -2.6229e-03, -3.4748e-03, -1.2342e-04,  7.5890e-04]]],\n",
       "\n",
       "\n",
       "        [[[-4.5441e-02, -1.7918e-01, -9.4557e-03, -8.0730e-02, -2.0197e-03],\n",
       "          [ 1.6410e-02,  3.6819e-02,  2.2027e-01, -2.2079e-02, -8.0627e-02],\n",
       "          [-1.0489e-01, -1.1208e-01, -6.0614e-02,  9.1793e-02, -3.1953e-02],\n",
       "          [ 1.3494e-02,  2.9217e-01, -2.6541e-01, -7.6223e-02, -1.6790e-01],\n",
       "          [-3.0139e-02, -9.9679e-03,  3.9293e-02, -9.9572e-02,  3.7419e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.9084e-03, -1.6632e-01,  2.7354e-01, -2.6413e-01, -7.8866e-02],\n",
       "          [ 5.6271e-02,  2.2973e-01, -4.2184e-02, -1.3645e-01,  1.9866e-01],\n",
       "          [ 9.0718e-02, -3.6948e-01,  2.8930e-01, -1.6117e-01, -3.5429e-01],\n",
       "          [ 1.7645e-01,  1.1102e-01, -4.9424e-01,  2.0524e-01,  2.8525e-01],\n",
       "          [ 3.7612e-01,  2.6926e-01,  4.2581e-01,  2.2545e-01, -2.1760e-01]]],\n",
       "\n",
       "\n",
       "        [[[        nan,         nan,         nan,         nan,         nan],\n",
       "          [        nan,         nan,         nan,         nan,         nan],\n",
       "          [        nan,         nan,         nan,         nan,         nan],\n",
       "          [        nan,         nan,         nan,         nan,         nan],\n",
       "          [        nan,         nan,         nan,         nan,         nan]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9418e-01,  9.2463e-02,  4.2972e-01, -3.0977e-01,  1.2254e-01],\n",
       "          [ 1.6551e-01, -1.7298e-02, -9.9832e-02, -5.6908e-03, -7.3730e-02],\n",
       "          [-7.7210e-02,  6.3074e-02, -1.7468e-01, -2.7162e-02,  2.2435e-01],\n",
       "          [-5.3666e-02, -5.7566e-01,  2.5841e-01,  7.1677e-02,  1.6321e-02],\n",
       "          [ 1.7732e-01, -1.8258e-01, -8.4605e-01, -3.3640e-01,  2.5264e-01]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1117]]],\n",
       "\n",
       "\n",
       "        [[[0.5207]]],\n",
       "\n",
       "\n",
       "        [[[1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.6129]]],\n",
       "\n",
       "\n",
       "        [[[0.4604]]],\n",
       "\n",
       "\n",
       "        [[[0.4275]]],\n",
       "\n",
       "\n",
       "        [[[1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.9330]]],\n",
       "\n",
       "\n",
       "        [[[0.6005]]],\n",
       "\n",
       "\n",
       "        [[[0.0801]]],\n",
       "\n",
       "\n",
       "        [[[0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0168]]],\n",
       "\n",
       "\n",
       "        [[[0.3874]]],\n",
       "\n",
       "\n",
       "        [[[0.8673]]],\n",
       "\n",
       "\n",
       "        [[[1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.9763]]]], grad_fn=<HardtanhBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.hardtanh(z, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0., 0., -0., -0., 0.],\n",
       "         [-0., -0., 0., 0., 0.],\n",
       "         [-0., 0., -0., 0., 0.],\n",
       "         [0., -0., 0., -0., 0.],\n",
       "         [0., 0., 0., -0., -0.]]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "tensor(-0.0676, grad_fn=<SumBackward0>)\n",
      "tensor(-1.5943, grad_fn=<SumBackward0>)\n",
      "tensor(-0.8046, grad_fn=<SumBackward0>)\n",
      "tensor(0.0256, grad_fn=<SumBackward0>)\n",
      "tensor(0.0096, grad_fn=<SumBackward0>)\n",
      "tensor(0.2718, grad_fn=<SumBackward0>)\n",
      "tensor(0.5093, grad_fn=<SumBackward0>)\n",
      "tensor(1.3359, grad_fn=<SumBackward0>)\n",
      "tensor(-0.8409, grad_fn=<SumBackward0>)\n",
      "tensor(-0.6912, grad_fn=<SumBackward0>)\n",
      "tensor(-0.1197, grad_fn=<SumBackward0>)\n",
      "tensor(0.5211, grad_fn=<SumBackward0>)\n",
      "tensor(-0.0169, grad_fn=<SumBackward0>)\n",
      "tensor(0.7425, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for w in weight:\n",
    "    print(w.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(np.arange(-10, 10, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f54a5efb810>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, F.hardtanh(a, min_val=0, max_val=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L0Conv2d(Module):\n",
    "    \"\"\"Implementation of L0 regularization for the feature maps of a convolutional layer\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                 droprate_init=0.5, temperature=2. / 3., weight_decay=1., lamba=1., local_rep=False, **kwargs):\n",
    "        \"\"\"\n",
    "        :param in_channels: Number of input channels\n",
    "        :param out_channels: Number of output channels\n",
    "        :param kernel_size: Size of the kernel\n",
    "        :param stride: Stride for the convolution\n",
    "        :param padding: Padding for the convolution\n",
    "        :param dilation: Dilation factor for the convolution\n",
    "        :param groups: How many groups we will assume in the convolution\n",
    "        :param bias: Whether we will use a bias\n",
    "        :param droprate_init: Dropout rate that the L0 gates will be initialized to\n",
    "        :param temperature: Temperature of the concrete distribution\n",
    "        :param weight_decay: Strength of the L2 penalty\n",
    "        :param lamba: Strength of the L0 penalty\n",
    "        :param local_rep: Whether we will use a separate gate sample per element in the minibatch\n",
    "        \"\"\"\n",
    "        super(L0Conv2d, self).__init__()\n",
    "        assert in_channels % groups != 0, 'in_channels must be divisible by groups'\n",
    "        assert out_channels % groups != 0, 'out_channels must be divisible by groups'\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = pair(kernel_size)\n",
    "        self.stride = pair(stride)\n",
    "        self.padding = pair(padding)\n",
    "        self.dilation = pair(dilation)\n",
    "        self.output_padding = pair(0)\n",
    "        self.groups = groups\n",
    "        self.prior_prec = weight_decay\n",
    "        self.lamba = lamba\n",
    "        self.droprate_init = droprate_init if droprate_init != 0. else 0.5\n",
    "        self.temperature = temperature\n",
    "        self.floatTensor = torch.FloatTensor if not torch.cuda.is_available() else torch.cuda.FloatTensor\n",
    "        self.use_bias = False\n",
    "        \n",
    "        self.weights = Parameter(torch.Tensor(out_channels, in_channels // groups, *self.kernel_size))\n",
    "        self.qz_loga = Parameter(torch.Tensor(out_channels))\n",
    "        self.dim_z = out_channels\n",
    "        \n",
    "        self.input_shape = None\n",
    "        self.local_rep = local_rep\n",
    "\n",
    "        h_out = lambda h_in, padding, dilation, kernel_size, stride: np.floor(\n",
    "            (h_in + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) / stride[0] + 1)\n",
    "        w_out = lambda w_in, padding, dilation, kernel_size, stride: np.floor(\n",
    "            (w_in + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) / stride[1] + 1)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "            self.use_bias = True\n",
    "\n",
    "        self.reset_parameters()\n",
    "        print(self)\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 5, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), droprate_init=0.5, temperature=0.6666666666666666, prior_prec=1.0, lamba=1.0, local_rep=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:173: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "c = L0Conv2d(c_in, c_out, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L0Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), droprate_init=0.5, temperature=0.6666666666666666, prior_prec=1.0, lamba=1.0, local_rep=False)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
